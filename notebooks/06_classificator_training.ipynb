{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8ef39f9c",
      "metadata": {
        "id": "8ef39f9c"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "import joblib\n",
        "from typing import Tuple, Optional\n",
        "from datetime import datetime, timezone\n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9XKYeDbOYu_l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XKYeDbOYu_l",
        "outputId": "35bd746b-61f7-4fd4-ac54-44537eba2d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'magic_tagger' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "REPO_URL = \"https://github.com/eugeniavd/magic_tagger.git\"  # <-- EDIT if needed\n",
        "!git clone {REPO_URL}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "unR7iLZ9XTA7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "unR7iLZ9XTA7",
        "outputId": "1ea14f74-7c4a-426d-dbf4-fd6f90efaf43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: /Users/eugenia/Desktop/thesis/magic_tagger/data/processed/classify_data_normalized.csv\n",
            "Shape: (50, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>rights_status</th>\n",
              "      <th>content_description</th>\n",
              "      <th>set</th>\n",
              "      <th>sampling_version</th>\n",
              "      <th>type_count</th>\n",
              "      <th>collection</th>\n",
              "      <th>volume_no</th>\n",
              "      <th>source_ref</th>\n",
              "      <th>atu_labels_json</th>\n",
              "      <th>txt_path</th>\n",
              "      <th>text_raw</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>open</td>\n",
              "      <td>[Царевна-лягушка].</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>3</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene 1, 503/4 (1)</td>\n",
              "      <td>[\"402\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Тили были царь с царицей у не\\nбыло три сына. ...</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>open</td>\n",
              "      <td>[По пьяни мужик спорит, что сможет принести но...</td>\n",
              "      <td>coverage</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene 1, 515/6 (1)</td>\n",
              "      <td>[\"410\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Раз пяное, ребятище» подился.\\nчто можит в 12 ...</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>open</td>\n",
              "      <td>Снегурочка.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>3</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 105 (22)</td>\n",
              "      <td>[\"703*\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Сделали дети со снегу куклу.\\nВ одного старина...</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>open</td>\n",
              "      <td>Иван-дурак.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>4</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 137/41 (98)</td>\n",
              "      <td>[\"530\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Кил-был стажк. В яво бло\\nтра сегна. Миша, Гри...</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>open</td>\n",
              "      <td>Два брата.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>2</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 189/94 (1)</td>\n",
              "      <td>[\"735A\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Жили – брели два брата.\\nи посла смерти отца о...</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tale_id rights_status  \\\n",
              "0    era_vene_1_503_1          open   \n",
              "1    era_vene_1_515_1          open   \n",
              "2  era_vene_12_105_22          open   \n",
              "3  era_vene_12_137_98          open   \n",
              "4   era_vene_12_189_1          open   \n",
              "\n",
              "                                 content_description       set  \\\n",
              "0                                 [Царевна-лягушка].      core   \n",
              "1  [По пьяни мужик спорит, что сможет принести но...  coverage   \n",
              "2                                        Снегурочка.      core   \n",
              "3                                        Иван-дурак.      core   \n",
              "4                                         Два брата.      core   \n",
              "\n",
              "  sampling_version  type_count collection  volume_no  \\\n",
              "0      v1_20251230           3  ERA, Vene          1   \n",
              "1      v1_20251230           1  ERA, Vene          1   \n",
              "2      v1_20251230           3  ERA, Vene         12   \n",
              "3      v1_20251230           4  ERA, Vene         12   \n",
              "4      v1_20251230           2  ERA, Vene         12   \n",
              "\n",
              "                  source_ref atu_labels_json  \\\n",
              "0     ERA, Vene 1, 503/4 (1)         [\"402\"]   \n",
              "1     ERA, Vene 1, 515/6 (1)         [\"410\"]   \n",
              "2     ERA, Vene 12, 105 (22)        [\"703*\"]   \n",
              "3  ERA, Vene 12, 137/41 (98)         [\"530\"]   \n",
              "4   ERA, Vene 12, 189/94 (1)        [\"735A\"]   \n",
              "\n",
              "                                            txt_path  \\\n",
              "0  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "1  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "2  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "3  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "4  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "\n",
              "                                            text_raw  \\\n",
              "0  Тили были царь с царицей у не\\nбыло три сына. ...   \n",
              "1  Раз пяное, ребятище» подился.\\nчто можит в 12 ...   \n",
              "2  Сделали дети со снегу куклу.\\nВ одного старина...   \n",
              "3  Кил-был стажк. В яво бло\\nтра сегна. Миша, Гри...   \n",
              "4  Жили – брели два брата.\\nи посла смерти отца о...   \n",
              "\n",
              "                                        summary_norm  \\\n",
              "0                                   царевна-лягушка.   \n",
              "1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2                                        снегурочка.   \n",
              "3                                        иван-дурак.   \n",
              "4                                         два брата.   \n",
              "\n",
              "                                           text_norm  \n",
              "0  тили были царь с царицей у не было три сына. ц...  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...  \n",
              "4  жили — брели два брата. и посла смерти отца об...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PROJECT_ROOT = Path(\"/Users/eugenia/Desktop/thesis/magic_tagger\")\n",
        "\n",
        "csv_path = PROJECT_ROOT / \"data\" / \"processed\" / \"classify_data_normalized.csv\"\n",
        "\n",
        "# --- load ---\n",
        "df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
        "print(\"Loaded:\", csv_path)\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40phv8G3ZNyy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40phv8G3ZNyy",
        "outputId": "d78ded86-c277-4988-ac34-d9c2d3651de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique labels: 37\n",
            "Example: ['1000', '1060', '1168', '1174', '300', '300A', '301', '302C*', '302С*', '307', '313', '325', '327A', '331', '402', '410', '425C', '470', '480A', '480D*']\n"
          ]
        }
      ],
      "source": [
        "col = \"atu_labels_json\"\n",
        "\n",
        "def parse_labels(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    s = str(x).strip()\n",
        "    if not s:\n",
        "        return []\n",
        "    try:\n",
        "        v = json.loads(s)\n",
        "        if isinstance(v, list):\n",
        "            return [str(t).strip() for t in v if str(t).strip()]\n",
        "\n",
        "        return [str(v).strip()]\n",
        "    except Exception:\n",
        "\n",
        "        return [t.strip() for t in s.split(\",\") if t.strip()]\n",
        "\n",
        "df[\"labels\"] = df[col].apply(parse_labels)\n",
        "\n",
        "unique_labels = sorted({lab for labs in df[\"labels\"] for lab in labs})\n",
        "print(\"Unique labels:\", len(unique_labels))\n",
        "print(\"Example:\", unique_labels[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "siWCTWCSZ4j8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "siWCTWCSZ4j8",
        "outputId": "4642e561-26f2-4857-9a79-07989bff9227"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "707      6\n",
              "480D*    5\n",
              "402      3\n",
              "552      3\n",
              "703*     3\n",
              "530      3\n",
              "307      3\n",
              "650A     3\n",
              "480A     3\n",
              "301      2\n",
              "425C     2\n",
              "300      2\n",
              "410      2\n",
              "550      2\n",
              "700      2\n",
              "580      1\n",
              "735A     1\n",
              "556F*    1\n",
              "554      1\n",
              "302C*    1\n",
              "313      1\n",
              "1168     1\n",
              "1174     1\n",
              "331      1\n",
              "300A     1\n",
              "709      1\n",
              "530A     1\n",
              "302С*    1\n",
              "325      1\n",
              "1000     1\n",
              "1060     1\n",
              "511      1\n",
              "470      1\n",
              "849*     1\n",
              "706      1\n",
              "556А*    1\n",
              "327A     1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_counts = pd.Series([lab for labs in df[\"labels\"] for lab in labs]).value_counts()\n",
        "display(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "XXQtFVSz7LB3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XXQtFVSz7LB3",
        "outputId": "e6911b7f-243c-4d4f-c68e-ee8998811e17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "      <td>[402]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "      <td>[410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "      <td>[703*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "      <td>[530]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "      <td>[735A]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tale_id                                       summary_norm  \\\n",
              "0    era_vene_1_503_1                                   царевна-лягушка.   \n",
              "1    era_vene_1_515_1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2  era_vene_12_105_22                                        снегурочка.   \n",
              "3  era_vene_12_137_98                                        иван-дурак.   \n",
              "4   era_vene_12_189_1                                         два брата.   \n",
              "\n",
              "                                           text_norm  labels  \n",
              "0  тили были царь с царицей у не было три сына. ц...   [402]  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...   [410]  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  [703*]  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...   [530]  \n",
              "4  жили — брели два брата. и посла смерти отца об...  [735A]  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DROP_COLS = [\n",
        "    \"rights_status\",\n",
        "    \"content_description\",\n",
        "    \"sampling_version\",\n",
        "    \"type_count\",\n",
        "    \"collection\",\n",
        "    \"volume_no\",\n",
        "    \"source_ref\",\n",
        "    \"atu_labels_json\",\n",
        "    \"txt_path\",\n",
        "    \"text_raw\",\n",
        "    \"set\"\n",
        "]\n",
        "\n",
        "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns]).copy()\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gNh9Iy4_stoC",
      "metadata": {
        "id": "gNh9Iy4_stoC"
      },
      "source": [
        "### Multi-label encoding and parent-level labels for evaluation\n",
        "\n",
        "Because each tale in our corpus can be assigned to **one or more ATU types**, we treat ATU prediction as a **multi-label classification** task. We first convert the human-assigned label sets into a machine-learning friendly representation using `MultiLabelBinarizer`. This step builds a fixed label vocabulary from the training data and transforms each tale’s label list into a **multi-hot binary vector**. This representation is required by standard multi-label classifiers (e.g., One-vs-Rest logistic regression) and ensures a reproducible mapping between labels and output dimensions.\n",
        "\n",
        "In addition to the original ATU labels, we derive a **parent-level label set** for evaluation. ATU types frequently include suffixes or modifiers (e.g., `327A`, `480D*`), while the **leading numeric component** (e.g., `327`, `480`) captures a higher-level category that is often more stable under noisy HTR conditions and small-data regimes. We therefore extract the first 1–4 digits from each ATU label via a simple regular expression and assign the resulting parent codes as `labels_parent`. This enables evaluation at a coarser granularity (e.g., Parent-Hit@3), which better reflects the intended use of the system as a **decision-support tool**: even when the model fails to predict the exact subtype, correctly retrieving the parent class can still provide a meaningful shortlist for expert review.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "YghxJSvDifQ8",
      "metadata": {
        "id": "YghxJSvDifQ8"
      },
      "outputs": [],
      "source": [
        "RE_ATU_PARENT = re.compile(r\"^\\s*(?:ATU[_\\s-]*)?(\\d{1,4})\")\n",
        "\n",
        "def atu_parent(label: str) -> str:\n",
        "    if label is None:\n",
        "        return \"\"\n",
        "    s = str(label).strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    m = RE_ATU_PARENT.search(s)\n",
        "    return m.group(1) if m else \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "S3q6Z3QMIToR",
      "metadata": {
        "id": "S3q6Z3QMIToR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------\n",
        "# 2) Robust label utilities\n",
        "# -------------------------\n",
        "def is_missing(x) -> bool:\n",
        "    if x is None:\n",
        "        return True\n",
        "\n",
        "    # If x is array-like/container (list/tuple/ndarray/Series), treat as NOT-missing container.\n",
        "    # Missingness is handled elementwise later.\n",
        "    if isinstance(x, (list, tuple, set, dict, np.ndarray, pd.Series, pd.Index)):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        m = pd.isna(x)\n",
        "        # pd.isna(scalar) -> bool; pd.isna(array-like) -> array (handled above)\n",
        "        if isinstance(m, (bool, np.bool_)):\n",
        "            return bool(m)\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def to_parent_set(labels) -> list[str]:\n",
        "    \"\"\"\n",
        "    Convert a list of ATU labels to a sorted list of unique parent codes.\n",
        "    Robust to:\n",
        "      - labels=None / labels=NaN\n",
        "      - NaN elements inside the list\n",
        "      - empty/whitespace strings\n",
        "    \"\"\"\n",
        "    if is_missing(labels):\n",
        "        return []\n",
        "\n",
        "    out: set[str] = set()\n",
        "    for x in labels:\n",
        "        if is_missing(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        p = atu_parent(s)\n",
        "        if p:\n",
        "            out.add(p)\n",
        "\n",
        "    return sorted(out)\n",
        "\n",
        "def clean_label_list(labels) -> list[str]:\n",
        "    \"\"\"\n",
        "    Normalize and deduplicate a label list.\n",
        "    - Accepts None/NaN\n",
        "    - Accepts a single string -> [string]\n",
        "    - Accepts list-like -> list[str]\n",
        "    \"\"\"\n",
        "    if is_missing(labels):\n",
        "        return []\n",
        "    if isinstance(labels, str):\n",
        "        s = labels.strip()\n",
        "        return [s] if s else []\n",
        "\n",
        "    out: list[str] = []\n",
        "    for x in labels:\n",
        "        if is_missing(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "\n",
        "    # stable dedup\n",
        "    seen: set[str] = set()\n",
        "    dedup: list[str] = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Zps62bspIfZw",
      "metadata": {
        "id": "Zps62bspIfZw"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# 3) Parent-Hit@k from scores/proba (any match)\n",
        "# ---------------------------------------\n",
        "def parent_hit_at_k_from_proba(\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    proba: np.ndarray,\n",
        "    classes: np.ndarray,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Parent-Hit@k (any match):\n",
        "    success if at least one gold parent code appears among parent codes\n",
        "    of the model's top-k predicted labels.\n",
        "    \"\"\"\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be >= 1\")\n",
        "    if proba.shape[0] != len(y_true_parent_lists):\n",
        "        raise ValueError(\"n_samples mismatch between y_true_parent_lists and proba\")\n",
        "    if proba.shape[1] != len(classes):\n",
        "        raise ValueError(\"proba columns != classes length (alignment issue)\")\n",
        "\n",
        "    classes_parent = np.array([atu_parent(c) for c in classes], dtype=object)\n",
        "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "\n",
        "    hits: list[int] = []\n",
        "    for i, gold_parents in enumerate(y_true_parent_lists):\n",
        "        gold_set = set(gold_parents or [])\n",
        "        pred_parent_set = set(classes_parent[topk_idx[i]])\n",
        "        pred_parent_set.discard(\"\")  # defensive\n",
        "        hits.append(1 if (gold_set & pred_parent_set) else 0)\n",
        "\n",
        "    return float(np.mean(hits))\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# 4) Exact-Hit@k from scores/proba (any match)\n",
        "# -----------------------------------\n",
        "def exact_hit_at_k_from_proba(\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    proba: np.ndarray,\n",
        "    classes: np.ndarray,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Exact-Hit@k (any match):\n",
        "    success if at least one exact gold label appears among the model's top-k labels.\n",
        "    \"\"\"\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be >= 1\")\n",
        "    if proba.shape[0] != len(y_true_labels_lists):\n",
        "        raise ValueError(\"n_samples mismatch between y_true_labels_lists and proba\")\n",
        "    if proba.shape[1] != len(classes):\n",
        "        raise ValueError(\"proba columns != classes length (alignment issue)\")\n",
        "\n",
        "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "\n",
        "    hits: list[int] = []\n",
        "    for i, gold_labels in enumerate(y_true_labels_lists):\n",
        "        gold_set = set(clean_label_list(gold_labels))\n",
        "        pred_set = set(classes[topk_idx[i]])\n",
        "        hits.append(1 if (gold_set & pred_set) else 0)\n",
        "\n",
        "    return float(np.mean(hits))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8OPX8Et3IlQH",
      "metadata": {
        "id": "8OPX8Et3IlQH"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# 6) Model wrappers (scores adapter)\n",
        "# -----------------------------------------\n",
        "def _stack_proba_list(proba_list) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert list-of-arrays from some multilabel wrappers into (n_samples, n_classes).\n",
        "    Typical forms:\n",
        "      - each element is (n_samples, 2) -> take [:, 1]\n",
        "      - each element is (n_samples,)  -> use as-is\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for p in proba_list:\n",
        "        p = np.asarray(p)\n",
        "        if p.ndim == 2 and p.shape[1] == 2:\n",
        "            cols.append(p[:, 1])\n",
        "        elif p.ndim == 2 and p.shape[1] == 1:\n",
        "            cols.append(p[:, 0])\n",
        "        elif p.ndim == 1:\n",
        "            cols.append(p)\n",
        "        else:\n",
        "            # last-resort flatten\n",
        "            cols.append(p.reshape(-1))\n",
        "    return np.column_stack(cols)\n",
        "\n",
        "def _get_model_scores(model, X) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return a 2D array (n_samples, n_classes) used for top-k ranking.\n",
        "    Works with:\n",
        "      - predict_proba returning ndarray or list-of-arrays\n",
        "      - decision_function returning ndarray\n",
        "    \"\"\"\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        p = model.predict_proba(X)\n",
        "        if isinstance(p, list):\n",
        "            p = _stack_proba_list(p)\n",
        "        else:\n",
        "            p = np.asarray(p)\n",
        "\n",
        "        if p.ndim == 1:\n",
        "            p = p.reshape(-1, 1)\n",
        "        return p\n",
        "\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        s = model.decision_function(X)\n",
        "        s = np.asarray(s)\n",
        "        if s.ndim == 1:\n",
        "            s = s.reshape(-1, 1)\n",
        "        return s\n",
        "\n",
        "    raise AttributeError(\"Model must implement predict_proba or decision_function\")\n",
        "\n",
        "def parent_hit_at_k_model(\n",
        "    model,\n",
        "    X,\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    mlb,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    scores = _get_model_scores(model, X)\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "    return parent_hit_at_k_from_proba(y_true_parent_lists, scores, classes, k=k)\n",
        "\n",
        "def exact_hit_at_k_model(\n",
        "    model,\n",
        "    X,\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    mlb,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    scores = _get_model_scores(model, X)\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "    return exact_hit_at_k_from_proba(y_true_labels_lists, scores, classes, k=k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "B9-xje06IoSd",
      "metadata": {
        "id": "B9-xje06IoSd"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# 7) Safe X construction\n",
        "# -----------------------------------------\n",
        "def build_X(\n",
        "    df: pd.DataFrame,\n",
        "    text_cols: tuple[str, ...] = (\"summary_norm\", \"text_norm\"),\n",
        "    fillna: str = \"\",\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    One canonical X builder.\n",
        "\n",
        "    Returns a DataFrame with ONLY the requested text columns (in the given order).\n",
        "    This is compatible with ColumnTransformer that references columns by name.\n",
        "    Prevents leakage through id/metadata columns by construction.\n",
        "\n",
        "    Usage:\n",
        "      X_train = build_X(train_df)\n",
        "      X_test  = build_X(test_df)\n",
        "    \"\"\"\n",
        "    cols = [c for c in text_cols if c in df.columns]\n",
        "    if not cols:\n",
        "        raise ValueError(f\"None of text_cols {text_cols} found in df. Available: {list(df.columns)}\")\n",
        "\n",
        "    X = df[cols].copy()\n",
        "    # enforce string dtype for vectorizers; avoids pd.NA issues\n",
        "    for c in cols:\n",
        "        X[c] = X[c].fillna(fillna).astype(str)\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uoegw2BKuXVe",
      "metadata": {
        "id": "Uoegw2BKuXVe"
      },
      "source": [
        "### Stratified train/test split for multi-label data using parent ATU codes\n",
        "\n",
        "To evaluate the classifier on a held-out set while preserving label coverage, we implement a **custom stratified split** tailored to **multi-label** data. Standard stratification methods assume a single label per instance and do not directly support the setting where each tale can have **multiple ATU types**. This is especially problematic in our small corpus, where many labels are rare: a naive random split can easily place the only example of a label in the test set, leaving the model with **zero training examples** for that label.\n",
        "\n",
        "Our function `stratified_multilabel_split_by_parent()` performs an approximate stratification over `labels_parent` (coarser ATU parent codes), with the goal of constructing a test subset of size `test_size` while ensuring that the training set retains minimal coverage for the labels present.\n",
        "\n",
        "The procedure is as follows:\n",
        "\n",
        "1. **Target test size.** We compute the desired number of test documents (`n_test = round(n * test_size)`).\n",
        "\n",
        "2. **Label availability tracking.** We count how many documents contain each parent label (`all_counts`) and keep a mutable counter `remaining` to track how many examples of each label would remain in the training pool if we move documents into the test set.\n",
        "\n",
        "3. **Safety constraint.** A document is considered *safe* to move into the test set if doing so does not exhaust any of its labels in the remaining pool:\n",
        "   - `is_safe(i)` returns `True` only if for every label in document `i`, `remaining[label] ≥ 2`.\n",
        "   This conservative rule ensures that after selecting the test items, each label included in a moved document still has at least one example left for training (and avoids dropping a label entirely from the training set).\n",
        "\n",
        "4. **Coverage-oriented greedy selection.** We iteratively build the test set using a greedy criterion:\n",
        "   - `gain(i)` measures how many **new** parent labels a candidate document would contribute to the current test set (labels not yet covered in `covered_test`).\n",
        "   At each step we choose, among safe candidates, a document with maximal gain (ties are broken randomly). This increases the diversity of labels represented in the test split without violating the safety constraint.\n",
        "\n",
        "5. **Fallback filling.** If we cannot reach the desired test size using the greedy coverage criterion (because the safety constraint becomes too restrictive), we fill the remaining slots by randomly selecting from the remaining safe documents.\n",
        "\n",
        "Finally, we return two dataframes: `train_df` and `test_df`. This split is designed to be **more stable and fair** than a naive random split for small multi-label datasets, because it reduces the risk of creating “unseen-in-training” labels and improves the interpretability of downstream evaluation (e.g., Parent-Hit@3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Q5NKFWkUJueH",
      "metadata": {
        "id": "Q5NKFWkUJueH"
      },
      "outputs": [],
      "source": [
        "df = df.copy()\n",
        "df[\"labels\"] = df[\"labels\"].apply(clean_label_list)\n",
        "df[\"labels_parent\"] = df[\"labels\"].apply(to_parent_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "74pcW-C0KX4z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "74pcW-C0KX4z",
        "outputId": "0b3b73d3-2b9d-45bb-e081-6a81fd6b5352"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels_parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "      <td>[402]</td>\n",
              "      <td>[402]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "      <td>[410]</td>\n",
              "      <td>[410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "      <td>[703*]</td>\n",
              "      <td>[703]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "      <td>[530]</td>\n",
              "      <td>[530]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "      <td>[735A]</td>\n",
              "      <td>[735]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tale_id                                       summary_norm  \\\n",
              "0    era_vene_1_503_1                                   царевна-лягушка.   \n",
              "1    era_vene_1_515_1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2  era_vene_12_105_22                                        снегурочка.   \n",
              "3  era_vene_12_137_98                                        иван-дурак.   \n",
              "4   era_vene_12_189_1                                         два брата.   \n",
              "\n",
              "                                           text_norm  labels labels_parent  \n",
              "0  тили были царь с царицей у не было три сына. ц...   [402]         [402]  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...   [410]         [410]  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  [703*]         [703]  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...   [530]         [530]  \n",
              "4  жили — брели два брата. и посла смерти отца об...  [735A]         [735]  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "mPClGSGHQvfy",
      "metadata": {
        "id": "mPClGSGHQvfy"
      },
      "outputs": [],
      "source": [
        "def stratified_multilabel_split_by_parent(\n",
        "    df: pd.DataFrame,\n",
        "    label_col: str = \"labels_parent\",\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    min_train_count_per_label: int = 1,\n",
        "    require_nonempty_labels: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Greedy multi-label split by parent labels (heuristic).\n",
        "    - Tries to reach ~test_size for test\n",
        "    - Maximizes parent-label coverage in test\n",
        "    - Keeps at least min_train_count_per_label occurrences of each label in train when possible\n",
        "    \"\"\"\n",
        "    if not (0.0 < test_size < 1.0):\n",
        "        raise ValueError(\"test_size must be in (0, 1)\")\n",
        "    if label_col not in df.columns:\n",
        "        raise KeyError(f\"Column '{label_col}' not found. Build it before splitting.\")\n",
        "\n",
        "    rng = np.random.RandomState(random_state)\n",
        "\n",
        "    # Work on a copy; reset index for stable positional indexing\n",
        "    df = df.reset_index(drop=True).copy()\n",
        "\n",
        "    # Use your existing clean_label_list() to normalize list[str] per row\n",
        "    df[label_col] = df[label_col].apply(clean_label_list)\n",
        "\n",
        "    if require_nonempty_labels:\n",
        "        df = df[df[label_col].map(len) > 0].reset_index(drop=True)\n",
        "\n",
        "    n = len(df)\n",
        "    if n < 2:\n",
        "        raise ValueError(\"Need at least 2 rows to split\")\n",
        "\n",
        "    n_test = int(round(n * test_size))\n",
        "    n_test = max(1, min(n - 1, n_test))  # leave at least 1 row in train\n",
        "\n",
        "    # label frequencies\n",
        "    all_counts = Counter(lab for labs in df[label_col] for lab in labs)\n",
        "    remaining = Counter(all_counts)\n",
        "\n",
        "    test_idx = []\n",
        "    covered_test = set()\n",
        "\n",
        "    candidates = list(range(n))\n",
        "    rng.shuffle(candidates)\n",
        "\n",
        "    def is_safe(i: int) -> bool:\n",
        "        labs = df.at[i, label_col]\n",
        "        if not labs:\n",
        "            return True\n",
        "        # ensure train keeps >= min_train_count_per_label after moving row i to test\n",
        "        return all((remaining[lab] - 1) >= min_train_count_per_label for lab in labs)\n",
        "\n",
        "    def gain(i: int) -> int:\n",
        "        labs = set(df.at[i, label_col])\n",
        "        return len(labs - covered_test)\n",
        "\n",
        "    # Greedy selection: maximize new-label coverage subject to safety\n",
        "    while len(test_idx) < n_test:\n",
        "        safe = [i for i in candidates if (i not in test_idx and is_safe(i))]\n",
        "        if not safe:\n",
        "            break\n",
        "\n",
        "        gains = np.array([gain(i) for i in safe], dtype=int)\n",
        "        best_gain = gains.max()\n",
        "        best = [safe[j] for j in np.where(gains == best_gain)[0]]\n",
        "        chosen = int(rng.choice(best))\n",
        "\n",
        "        test_idx.append(chosen)\n",
        "        for lab in df.at[chosen, label_col]:\n",
        "            remaining[lab] -= 1\n",
        "            covered_test.add(lab)\n",
        "\n",
        "    # Backfill with any remaining safe rows (random order)\n",
        "    if len(test_idx) < n_test:\n",
        "        safe_rest = [i for i in range(n) if (i not in test_idx and is_safe(i))]\n",
        "        rng.shuffle(safe_rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(safe_rest[:need])\n",
        "\n",
        "    # Last resort: fill randomly if still short (may violate constraints for ultra-rare labels)\n",
        "    if len(test_idx) < n_test:\n",
        "        rest = [i for i in range(n) if i not in test_idx]\n",
        "        rng.shuffle(rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(rest[:need])\n",
        "\n",
        "    # Dedup + ensure not all docs in test\n",
        "    test_idx = sorted(set(test_idx))\n",
        "    if len(test_idx) >= n:\n",
        "        test_idx = test_idx[: n - 1]\n",
        "\n",
        "    train_idx = [i for i in range(n) if i not in test_idx]\n",
        "\n",
        "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "    test_df = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "aVbjrqZCQy3T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVbjrqZCQy3T",
        "outputId": "53943a9e-d45b-4410-9dc6-159aa638833b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (40, 5) | Test: (10, 5)\n",
            "Unique parents train: 32\n",
            "Unique parents test: 11\n"
          ]
        }
      ],
      "source": [
        "# usage\n",
        "train_df, test_df = stratified_multilabel_split_by_parent(\n",
        "    df,\n",
        "    label_col=\"labels_parent\",\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    min_train_count_per_label=1,\n",
        "    require_nonempty_labels=False\n",
        ")\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"| Test:\", test_df.shape)\n",
        "print(\"Unique parents train:\", len({l for labs in train_df[\"labels_parent\"] for l in labs}))\n",
        "print(\"Unique parents test:\", len({l for labs in test_df[\"labels_parent\"] for l in labs}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "oDzu-fkbQ3IK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oDzu-fkbQ3IK",
        "outputId": "4b41a1c9-6ed4-4517-f002-5957e8bef265"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels_parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "      <td>[402]</td>\n",
              "      <td>[402]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "      <td>[410]</td>\n",
              "      <td>[410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "      <td>[703*]</td>\n",
              "      <td>[703]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "      <td>[530]</td>\n",
              "      <td>[530]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "      <td>[735A]</td>\n",
              "      <td>[735]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tale_id                                       summary_norm  \\\n",
              "0    era_vene_1_503_1                                   царевна-лягушка.   \n",
              "1    era_vene_1_515_1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2  era_vene_12_105_22                                        снегурочка.   \n",
              "3  era_vene_12_137_98                                        иван-дурак.   \n",
              "4   era_vene_12_189_1                                         два брата.   \n",
              "\n",
              "                                           text_norm  labels labels_parent  \n",
              "0  тили были царь с царицей у не было три сына. ц...   [402]         [402]  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...   [410]         [410]  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  [703*]         [703]  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...   [530]         [530]  \n",
              "4  жили — брели два брата. и посла смерти отца об...  [735A]         [735]  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "rvLaCCYKAaxt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvLaCCYKAaxt",
        "outputId": "ffa84d42-d024-42aa-f32d-81b0d58f7fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels only in test (will be ignored by mlb): 0\n"
          ]
        }
      ],
      "source": [
        "train_labels = set(l for labs in train_df[\"labels\"] for l in labs)\n",
        "test_labels  = set(l for labs in test_df[\"labels\"] for l in labs)\n",
        "unknown_in_test = sorted(test_labels - train_labels)\n",
        "\n",
        "print(\"Labels only in test (will be ignored by mlb):\", len(unknown_in_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "o1MF8m8fToFJ",
      "metadata": {
        "id": "o1MF8m8fToFJ"
      },
      "outputs": [],
      "source": [
        "X_train = build_X(train_df, (\"summary_norm\", \"text_norm\"))\n",
        "X_test  = build_X(test_df,  (\"summary_norm\", \"text_norm\"))\n",
        "y_train_list = train_df[\"labels\"]\n",
        "y_test_list  = test_df[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "C0Vv4u-AU9ur",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Vv4u-AU9ur",
        "outputId": "5b3f40dc-0e45-483b-b44c-bedcc5798d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "summary_norm    по пьяни мужик спорит, что сможет принести ноч...\n",
            "text_norm       раз пяное, ребятище» подился. что можит в 12 ч...\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X_train.iloc[1][:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8uiT1XY0IQiN",
      "metadata": {
        "id": "8uiT1XY0IQiN"
      },
      "outputs": [],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "Y_train = mlb.fit_transform(y_train_list)\n",
        "Y_test  = mlb.transform(y_test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "dbk_UAr1AS5C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbk_UAr1AS5C",
        "outputId": "627360d6-e7b4-4a4c-c561-f73b0120fd12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (40, 2) y_train: (40, 37)\n",
            "X_test : (10, 2) y_test : (10, 37)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train:\", X_train.shape, \"y_train:\", Y_train.shape)\n",
        "print(\"X_test :\", X_test.shape,  \"y_test :\", Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q2Qnef2wwikl",
      "metadata": {
        "id": "Q2Qnef2wwikl"
      },
      "source": [
        "### Feature extraction and multi-label classifier (TF-IDF + One-vs-Rest Logistic Regression)\n",
        "\n",
        "This block defines the **final text-based baseline model** as a single scikit-learn `Pipeline` that (i) converts textual inputs into numerical features and (ii) trains a **multi-label** classifier over ATU types.\n",
        "\n",
        "**1) Character-level TF-IDF on OCR/HTR text (`text_norm`).**  \n",
        "We build a TF-IDF representation using **character n-grams (3–5)**. Character n-grams are a common and effective choice for noisy OCR/HTR corpora because they remain informative even when word boundaries or spellings are corrupted. We enable `sublinear_tf=True` (log-scaled term frequency) and cap the vocabulary with `max_features=50,000` to control dimensionality on a small dataset.\n",
        "\n",
        "**2) Word-level TF-IDF on summaries (`summary_norm`).**  \n",
        "In parallel, we build a TF-IDF representation using **word n-grams (1–2)** from the tale summary. Summaries typically contain less OCR noise and capture higher-level semantics, which complements the robustness of character n-grams. We similarly apply log-scaled TF and cap the vocabulary at `max_features=20,000`.\n",
        "\n",
        "**3) Feature concatenation via `ColumnTransformer`.**  \n",
        "The `ColumnTransformer` applies each vectorizer to its corresponding dataframe column and **concatenates** the resulting sparse vectors into a single feature space. All other dataframe columns are dropped (`remainder=\"drop\"`), ensuring that only text-derived signals enter the model.\n",
        "\n",
        "**4) Multi-label classification with One-vs-Rest Logistic Regression.**  \n",
        "Because a tale can legitimately have **multiple ATU assignments**, we use a `OneVsRestClassifier(LogisticRegression)` scheme: a separate binary logistic regression is trained for each ATU label, producing a score per label. Logistic regression is fast, stable on sparse TF-IDF features, and provides well-behaved ranking scores for Top-k recommendation.\n",
        "\n",
        "**5) End-to-end pipeline.**  \n",
        "Finally, we wrap preprocessing and classification into a single `Pipeline` so that the same transformations are consistently applied at training and inference time. This also simplifies serialization and deployment (e.g., saving the pipeline as a single artifact for the Streamlit application).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "P9XvkUX_bV_B",
      "metadata": {
        "id": "P9XvkUX_bV_B"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(\n",
        "    use_word_summary: bool = True,\n",
        "    use_word_text: bool = False,\n",
        "    char_analyzer: str = \"char\",              # \"char\" or \"char_wb\"\n",
        "    char_ngram: Tuple[int, int] = (3, 5),\n",
        "    word_ngram: Tuple[int, int] = (1, 2),\n",
        "    char_max_features: int = 50000,\n",
        "    word_max_features: int = 20000,\n",
        "    C: float = 2.0,\n",
        "    class_weight: Optional[str] = None,       # usually None for multi-label\n",
        "    random_state: int = 42,\n",
        ") -> Pipeline:\n",
        "    transformers = [\n",
        "        (\n",
        "            \"char_tfidf_text\",\n",
        "            TfidfVectorizer(\n",
        "                analyzer=char_analyzer,\n",
        "                ngram_range=char_ngram,\n",
        "                min_df=1,\n",
        "                max_features=char_max_features,\n",
        "                sublinear_tf=True,\n",
        "                lowercase=False,\n",
        "            ),\n",
        "            \"text_norm\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    if use_word_summary:\n",
        "        transformers.append(\n",
        "            (\n",
        "                \"word_tfidf_summary\",\n",
        "                TfidfVectorizer(\n",
        "                    analyzer=\"word\",\n",
        "                    ngram_range=word_ngram,\n",
        "                    min_df=1,\n",
        "                    max_features=word_max_features,\n",
        "                    sublinear_tf=True,\n",
        "                    lowercase=False,\n",
        "                ),\n",
        "                \"summary_norm\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if use_word_text:\n",
        "        transformers.append(\n",
        "            (\n",
        "                \"word_tfidf_text\",\n",
        "                TfidfVectorizer(\n",
        "                    analyzer=\"word\",\n",
        "                    ngram_range=word_ngram,\n",
        "                    min_df=1,\n",
        "                    max_features=word_max_features,\n",
        "                    sublinear_tf=True,\n",
        "                    lowercase=False,\n",
        "                ),\n",
        "                \"text_norm\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    features = ColumnTransformer(\n",
        "        transformers=transformers,\n",
        "        remainder=\"drop\",\n",
        "        sparse_threshold=0.3,\n",
        "    )\n",
        "\n",
        "    base_lr = LogisticRegression(\n",
        "        solver=\"liblinear\",\n",
        "        max_iter=2000,\n",
        "        C=C,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    clf = OneVsRestClassifier(base_lr, n_jobs=1)\n",
        "\n",
        "    return Pipeline([\n",
        "        (\"features\", features),\n",
        "        (\"clf\", clf),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Uxa5jra8cwgo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxa5jra8cwgo",
        "outputId": "e1b35b3b-d77d-46f0-982d-d02f525fa802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> (40, 2) Index(['summary_norm', 'text_norm'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(type(X_train), getattr(X_train, \"shape\", None), getattr(X_train, \"columns\", None))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "AmwQSqvFcBMW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AmwQSqvFcBMW",
        "outputId": "bda8e4ee-6bc5-430d-9a0c-e6d46847fee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CV on TRAIN: A_char + word_summary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 9 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 15 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 36 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 1: Xt shape=(8, 52815) nnz=37478\n",
            "[DEBUG] Fold 1: top-3 labels (first 3 val): [['480A', '552', '650A'], ['703*', '480A', '552'], ['480D*', '552', '480A']]\n",
            "[DEBUG] Fold 1: top-3 parents (first 3 val): [['480', '552', '650'], ['703', '480', '552'], ['480', '552', '480']]\n",
            "  Fold 1: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 1 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 8 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 12 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 22 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 27 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 28 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 29 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 30 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 2: Xt shape=(8, 52394) nnz=42503\n",
            "[DEBUG] Fold 2: top-3 labels (first 3 val): [['707', '552', '402'], ['707', '307', '849*'], ['707', '307', '552']]\n",
            "[DEBUG] Fold 2: top-3 parents (first 3 val): [['707', '552', '402'], ['707', '307', '849'], ['707', '307', '552']]\n",
            "  Fold 2: Parent-Hit@3=0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 2 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 3 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 6 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 11 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 13 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 16 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 17 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 35 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 3: Xt shape=(8, 53439) nnz=26051\n",
            "[DEBUG] Fold 3: top-3 labels (first 3 val): [['552', '707', '650A'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "[DEBUG] Fold 3: top-3 parents (first 3 val): [['552', '707', '650'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "  Fold 3: Parent-Hit@3=0.125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 4 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 5 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 32 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 4: Xt shape=(8, 53614) nnz=31545\n",
            "[DEBUG] Fold 4: top-3 labels (first 3 val): [['707', '530', '402'], ['480D*', '707', '650A'], ['707', '552', '650A']]\n",
            "[DEBUG] Fold 4: top-3 parents (first 3 val): [['707', '530', '402'], ['480', '707', '650'], ['707', '552', '650']]\n",
            "  Fold 4: Parent-Hit@3=0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 7 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 10 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 20 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 25 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 34 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 5: Xt shape=(8, 53450) nnz=30198\n",
            "[DEBUG] Fold 5: top-3 labels (first 3 val): [['703*', '707', '402'], ['707', '650A', '402'], ['480A', '707', '402']]\n",
            "[DEBUG] Fold 5: top-3 parents (first 3 val): [['703', '707', '402'], ['707', '650', '402'], ['480', '707', '402']]\n",
            "  Fold 5: Parent-Hit@3=0.625\n",
            "  CV mean=0.4500 std=0.1871 scores=[0.375 0.5   0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "CV on TRAIN: B_char + word_summary + word_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 9 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 15 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 36 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 1: Xt shape=(8, 72815) nnz=39069\n",
            "[DEBUG] Fold 1: top-3 labels (first 3 val): [['480A', '552', '707'], ['703*', '480A', '552'], ['480D*', '552', '480A']]\n",
            "[DEBUG] Fold 1: top-3 parents (first 3 val): [['480', '552', '707'], ['703', '480', '552'], ['480', '552', '480']]\n",
            "  Fold 1: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 1 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 8 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 12 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 22 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 27 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 28 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 29 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 30 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 2: Xt shape=(8, 72394) nnz=44202\n",
            "[DEBUG] Fold 2: top-3 labels (first 3 val): [['707', '402', '552'], ['707', '307', '849*'], ['707', '307', '849*']]\n",
            "[DEBUG] Fold 2: top-3 parents (first 3 val): [['707', '402', '552'], ['707', '307', '849'], ['707', '307', '849']]\n",
            "  Fold 2: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 2 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 3 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 6 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 11 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 13 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 16 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 17 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 35 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 3: Xt shape=(8, 73439) nnz=27063\n",
            "[DEBUG] Fold 3: top-3 labels (first 3 val): [['552', '707', '650A'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "[DEBUG] Fold 3: top-3 parents (first 3 val): [['552', '707', '650'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "  Fold 3: Parent-Hit@3=0.125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 4 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 5 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 32 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 4: Xt shape=(8, 73614) nnz=32775\n",
            "[DEBUG] Fold 4: top-3 labels (first 3 val): [['707', '530', '402'], ['480D*', '707', '402'], ['707', '552', '650A']]\n",
            "[DEBUG] Fold 4: top-3 parents (first 3 val): [['707', '530', '402'], ['480', '707', '402'], ['707', '552', '650']]\n",
            "  Fold 4: Parent-Hit@3=0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 7 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 10 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 20 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 25 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 34 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 5: Xt shape=(8, 73450) nnz=31343\n",
            "[DEBUG] Fold 5: top-3 labels (first 3 val): [['703*', '707', '402'], ['707', '650A', '402'], ['480A', '707', '402']]\n",
            "[DEBUG] Fold 5: top-3 parents (first 3 val): [['703', '707', '402'], ['707', '650', '402'], ['480', '707', '402']]\n",
            "  Fold 5: Parent-Hit@3=0.625\n",
            "  CV mean=0.4250 std=0.1871 scores=[0.375 0.375 0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "CV on TRAIN: C_charWB + word_summary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 9 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 15 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 36 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 1: Xt shape=(8, 52815) nnz=25445\n",
            "[DEBUG] Fold 1: top-3 labels (first 3 val): [['480A', '552', '650A'], ['703*', '480A', '552'], ['480D*', '552', '480A']]\n",
            "[DEBUG] Fold 1: top-3 parents (first 3 val): [['480', '552', '650'], ['703', '480', '552'], ['480', '552', '480']]\n",
            "  Fold 1: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 1 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 8 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 12 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 22 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 27 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 28 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 29 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 30 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 2: Xt shape=(8, 52394) nnz=29070\n",
            "[DEBUG] Fold 2: top-3 labels (first 3 val): [['707', '552', '402'], ['707', '307', '849*'], ['707', '307', '552']]\n",
            "[DEBUG] Fold 2: top-3 parents (first 3 val): [['707', '552', '402'], ['707', '307', '849'], ['707', '307', '552']]\n",
            "  Fold 2: Parent-Hit@3=0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 2 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 3 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 6 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 11 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 13 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 16 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 17 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 35 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 3: Xt shape=(8, 53439) nnz=17769\n",
            "[DEBUG] Fold 3: top-3 labels (first 3 val): [['552', '707', '650A'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "[DEBUG] Fold 3: top-3 parents (first 3 val): [['552', '707', '650'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "  Fold 3: Parent-Hit@3=0.125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 4 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 5 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 32 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 4: Xt shape=(8, 53614) nnz=21456\n",
            "[DEBUG] Fold 4: top-3 labels (first 3 val): [['707', '402', '530'], ['480D*', '707', '402'], ['707', '552', '650A']]\n",
            "[DEBUG] Fold 4: top-3 parents (first 3 val): [['707', '402', '530'], ['480', '707', '402'], ['707', '552', '650']]\n",
            "  Fold 4: Parent-Hit@3=0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 7 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 10 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 20 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 25 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 34 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 5: Xt shape=(8, 53450) nnz=20401\n",
            "[DEBUG] Fold 5: top-3 labels (first 3 val): [['703*', '707', '402'], ['707', '650A', '402'], ['480A', '707', '402']]\n",
            "[DEBUG] Fold 5: top-3 parents (first 3 val): [['703', '707', '402'], ['707', '650', '402'], ['480', '707', '402']]\n",
            "  Fold 5: Parent-Hit@3=0.625\n",
            "  CV mean=0.4500 std=0.1871 scores=[0.375 0.5   0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "CV on TRAIN: D_charWB + word_summary + word_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 9 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 15 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 36 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 1: Xt shape=(8, 72815) nnz=27036\n",
            "[DEBUG] Fold 1: top-3 labels (first 3 val): [['480A', '552', '707'], ['703*', '480A', '552'], ['480D*', '552', '480A']]\n",
            "[DEBUG] Fold 1: top-3 parents (first 3 val): [['480', '552', '707'], ['703', '480', '552'], ['480', '552', '480']]\n",
            "  Fold 1: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 1 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 8 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 12 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 22 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 27 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 28 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 29 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 30 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 2: Xt shape=(8, 72394) nnz=30769\n",
            "[DEBUG] Fold 2: top-3 labels (first 3 val): [['707', '402', '552'], ['707', '307', '849*'], ['707', '307', '849*']]\n",
            "[DEBUG] Fold 2: top-3 parents (first 3 val): [['707', '402', '552'], ['707', '307', '849'], ['707', '307', '849']]\n",
            "  Fold 2: Parent-Hit@3=0.375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 2 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 3 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 6 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 11 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 13 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 16 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 17 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 35 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 3: Xt shape=(8, 73439) nnz=18781\n",
            "[DEBUG] Fold 3: top-3 labels (first 3 val): [['552', '707', '650A'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "[DEBUG] Fold 3: top-3 parents (first 3 val): [['552', '707', '650'], ['552', '707', '307'], ['707', '552', '307']]\n",
            "  Fold 3: Parent-Hit@3=0.125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 4 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 5 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 32 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 4: Xt shape=(8, 73614) nnz=22686\n",
            "[DEBUG] Fold 4: top-3 labels (first 3 val): [['707', '530', '402'], ['480D*', '707', '402'], ['707', '552', '650A']]\n",
            "[DEBUG] Fold 4: top-3 parents (first 3 val): [['707', '530', '402'], ['480', '707', '402'], ['707', '552', '650']]\n",
            "  Fold 4: Parent-Hit@3=0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 7 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 10 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 20 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 25 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] Fold 5: Xt shape=(8, 73450) nnz=21546\n",
            "[DEBUG] Fold 5: top-3 labels (first 3 val): [['703*', '707', '402'], ['707', '650A', '402'], ['480A', '707', '402']]\n",
            "[DEBUG] Fold 5: top-3 parents (first 3 val): [['703', '707', '402'], ['707', '650', '402'], ['480', '707', '402']]\n",
            "  Fold 5: Parent-Hit@3=0.625\n",
            "  CV mean=0.4250 std=0.1871 scores=[0.375 0.375 0.125 0.625 0.625]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eugenia/miniforge3/envs/magictagger/lib/python3.11/site-packages/sklearn/multiclass.py:90: UserWarning: Label not 34 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A_char + word_summary</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C_charWB + word_summary</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B_char + word_summary + word_text</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D_charWB + word_summary + word_text</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 model   mean       std\n",
              "0                A_char + word_summary  0.450  0.187083\n",
              "1              C_charWB + word_summary  0.450  0.187083\n",
              "2    B_char + word_summary + word_text  0.425  0.187083\n",
              "3  D_charWB + word_summary + word_text  0.425  0.187083"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BEST by CV: A_char + word_summary\n"
          ]
        }
      ],
      "source": [
        "y_parent_train = train_df[\"labels_parent\"].tolist()\n",
        "classes = np.asarray(mlb.classes_)\n",
        "\n",
        "# --- CV function (train only) ---\n",
        "def cv_parent_hit_at_k(\n",
        "    X_train: pd.DataFrame,\n",
        "    Y_train: np.ndarray,\n",
        "    y_parent_train: list[list[str]],\n",
        "    classes: np.ndarray,\n",
        "    model_builder,\n",
        "    k: int = 3,\n",
        "    n_splits: int = 5,\n",
        "    cv_seed: int = 123,\n",
        "    verbose: bool = True,\n",
        "    debug_features: bool = False,   # <-- добавьте флаг\n",
        "    debug_n: int = 3,\n",
        ") -> np.ndarray:\n",
        "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=cv_seed)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_train), start=1):\n",
        "        model = model_builder()\n",
        "        model.fit(X_train.iloc[tr_idx], Y_train[tr_idx])\n",
        "\n",
        "        # =========================\n",
        "        # DEBUG INSERT HERE\n",
        "        # =========================\n",
        "        if debug_features:\n",
        "            # 1) shape/sparsity of features on VAL (do not touch labels)\n",
        "            Xt = model.named_steps[\"features\"].transform(X_train.iloc[va_idx])\n",
        "            nnz = Xt.nnz if hasattr(Xt, \"nnz\") else None\n",
        "            print(f\"[DEBUG] Fold {fold}: Xt shape={Xt.shape} nnz={nnz}\")\n",
        "\n",
        "        proba = model.predict_proba(X_train.iloc[va_idx])\n",
        "\n",
        "        # normalize possible list-of-arrays to 2D array\n",
        "        if isinstance(proba, list):\n",
        "            cols = []\n",
        "            for p in proba:\n",
        "                p = np.asarray(p)\n",
        "                if p.ndim == 2 and p.shape[1] == 2:\n",
        "                    cols.append(p[:, 1])\n",
        "                elif p.ndim == 2 and p.shape[1] == 1:\n",
        "                    cols.append(p[:, 0])\n",
        "                else:\n",
        "                    cols.append(p.reshape(-1))\n",
        "            proba = np.column_stack(cols)\n",
        "        else:\n",
        "            proba = np.asarray(proba)\n",
        "\n",
        "        if debug_features:\n",
        "            # 2) show top-k predicted labels for a few VAL samples\n",
        "            topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "            show = min(debug_n, topk_idx.shape[0])\n",
        "            preds = [[classes[j] for j in topk_idx[i]] for i in range(show)]\n",
        "            pred_parents = [[atu_parent(l) for l in preds[i]] for i in range(show)]\n",
        "            print(f\"[DEBUG] Fold {fold}: top-{k} labels (first {show} val): {preds}\")\n",
        "            print(f\"[DEBUG] Fold {fold}: top-{k} parents (first {show} val): {pred_parents}\")\n",
        "\n",
        "\n",
        "        score = parent_hit_at_k_from_proba(\n",
        "            y_true_parent_lists=[y_parent_train[i] for i in va_idx],\n",
        "            proba=proba,\n",
        "            classes=classes,\n",
        "            k=k,\n",
        "        )\n",
        "        scores.append(score)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Fold {fold}: Parent-Hit@{k}={score:.3f}\")\n",
        "\n",
        "    return np.asarray(scores, dtype=float)\n",
        "\n",
        "# --- experiments ---\n",
        "experiments = {\n",
        "    \"A_char + word_summary\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char\"),\n",
        "    \"B_char + word_summary + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char\"),\n",
        "    \"C_charWB + word_summary\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char_wb\"),\n",
        "    \"D_charWB + word_summary + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char_wb\"),\n",
        "}\n",
        "\n",
        "# --- run CV & pick best ---\n",
        "cv_results = {}\n",
        "for name, builder in experiments.items():\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"CV on TRAIN:\", name)\n",
        "\n",
        "    scores = cv_parent_hit_at_k(\n",
        "        X_train=X_train,\n",
        "        Y_train=Y_train,\n",
        "        y_parent_train=y_parent_train,\n",
        "        classes=classes,\n",
        "        model_builder=builder,\n",
        "        k=3,\n",
        "        n_splits=5,\n",
        "        cv_seed=123,\n",
        "        verbose=True,\n",
        "        debug_features=True,   # <-- включить\n",
        "        debug_n=3,\n",
        "    )\n",
        "    cv_results[name] = scores\n",
        "    print(f\"  CV mean={scores.mean():.4f} std={scores.std(ddof=0):.4f} scores={scores}\")\n",
        "\n",
        "cv_summary = (\n",
        "    pd.DataFrame({\n",
        "        \"model\": list(cv_results.keys()),\n",
        "        \"mean\": [cv_results[m].mean() for m in cv_results],\n",
        "        \"std\":  [cv_results[m].std(ddof=0) for m in cv_results],\n",
        "    })\n",
        "    .sort_values(\"mean\", ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "display(cv_summary)\n",
        "\n",
        "best_name = cv_summary.loc[0, \"model\"]\n",
        "best_builder = experiments[best_name]\n",
        "print(\"\\nBEST by CV:\", best_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8BPas2eww620",
      "metadata": {
        "id": "8BPas2eww620"
      },
      "source": [
        "In a repeated hold-out evaluation (10 random seeds; 80/20 split using the parent-aware multi-label splitter), the TF-IDF + OvR Logistic Regression classifier substantially outperformed the naïve frequency baseline under the project’s primary metric, Parent-Hit@3 (success if at least one gold ATU parent code appears among the parents of the model’s Top-3 predicted fine-grained types). The frequency baseline reaches only ~0.15 Parent-Hit@3 (≈1–2 hits per 10 tales), whereas the proposed text-based models achieve 0.43–0.46 on average (≈4–5 hits per 10 tales), indicating that textual features provide strong predictive signal beyond label priors. Across ablations, combining character TF-IDF on text_norm with word TF-IDF on the summary fallback is already effective (mean 0.43–0.45), while adding word TF-IDF on text_norm yields a small but consistent improvement and better stability (mean 0.46, minimum 0.40 across seeds). Using char_wb instead of char did not materially change performance in this setting. Based on these results, the mixed vector representation (char + word summary + optional word text) is retained as the default baseline model for subsequent experiments and UI integration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uYc5zM622p7n",
      "metadata": {
        "id": "uYc5zM622p7n"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plpe17Wwflw9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plpe17Wwflw9",
        "outputId": "a94daf5d-c75a-4e0e-f720-165f382c0547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 1: baseline-majority Parent-Hit@3=0.375 | topk=['480', '552', '707']\n",
            "  Fold 2: baseline-majority Parent-Hit@3=0.250 | topk=['480', '707', '402']\n",
            "  Fold 3: baseline-majority Parent-Hit@3=0.125 | topk=['480', '707', '552']\n",
            "  Fold 4: baseline-majority Parent-Hit@3=0.375 | topk=['707', '480', '703']\n",
            "  Fold 5: baseline-majority Parent-Hit@3=0.375 | topk=['480', '707', '402']\n",
            "Baseline majority: mean=0.3000 std=0.1000 scores=[0.375 0.25  0.125 0.375 0.375]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def cv_baseline_majority_parent_hit_at_k(\n",
        "    y_parent_train: list[list[str]],\n",
        "    k: int = 3,\n",
        "    n_splits: int = 5,\n",
        "    cv_seed: int = 123,\n",
        "    verbose: bool = True,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Baseline: in each fold, predict the top-k most frequent PARENTS from the TRAIN fold.\n",
        "    Score: Parent-Hit@k on the VAL fold (any match).\n",
        "    \"\"\"\n",
        "    n = len(y_parent_train)\n",
        "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=cv_seed)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(cv.split(np.arange(n)), start=1):\n",
        "        # parent frequency on TRAIN fold only\n",
        "        cnt = Counter(p for i in tr_idx for p in (y_parent_train[i] or []))\n",
        "        topk_parents = [p for p, _ in cnt.most_common(k)]\n",
        "\n",
        "        # evaluate on VAL\n",
        "        hits = []\n",
        "        for i in va_idx:\n",
        "            gold = set(y_parent_train[i] or [])\n",
        "            hits.append(1 if gold.intersection(topk_parents) else 0)\n",
        "\n",
        "        score = float(np.mean(hits)) if hits else 0.0\n",
        "        scores.append(score)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Fold {fold}: baseline-majority Parent-Hit@{k}={score:.3f} | topk={topk_parents}\")\n",
        "\n",
        "    return np.asarray(scores, dtype=float)\n",
        "\n",
        "# run\n",
        "baseline_scores = cv_baseline_majority_parent_hit_at_k(\n",
        "    y_parent_train=y_parent_train,\n",
        "    k=3,\n",
        "    n_splits=5,\n",
        "    cv_seed=123,\n",
        "    verbose=True\n",
        ")\n",
        "print(f\"Baseline majority: mean={baseline_scores.mean():.4f} std={baseline_scores.std(ddof=0):.4f} scores={baseline_scores}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JhD0bTqCfq_T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhD0bTqCfq_T",
        "outputId": "8203bb04-0075-4323-eddf-05c486a0f3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 1: baseline-random Parent-Hit@3=0.125\n",
            "  Fold 2: baseline-random Parent-Hit@3=0.000\n",
            "  Fold 3: baseline-random Parent-Hit@3=0.250\n",
            "  Fold 4: baseline-random Parent-Hit@3=0.000\n",
            "  Fold 5: baseline-random Parent-Hit@3=0.125\n",
            "Baseline random: mean=0.1000 std=0.0935 scores=[0.125 0.    0.25  0.    0.125]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def cv_baseline_random_label_parent_hit_at_k(\n",
        "    y_parent_train: list[list[str]],\n",
        "    classes: np.ndarray,   # fine labels, e.g. mlb.classes_\n",
        "    k: int = 3,\n",
        "    n_splits: int = 5,\n",
        "    cv_seed: int = 123,\n",
        "    verbose: bool = True,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Baseline: random top-k fine labels (uniform) per sample in VAL fold,\n",
        "    then map to parents via atu_parent and compute Parent-Hit@k.\n",
        "    \"\"\"\n",
        "    n = len(y_parent_train)\n",
        "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=cv_seed)\n",
        "    scores = []\n",
        "\n",
        "    # map fine label -> parent once\n",
        "    classes_parent = np.array([atu_parent(c) for c in classes], dtype=object)\n",
        "\n",
        "    rng = np.random.RandomState(cv_seed)\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(cv.split(np.arange(n)), start=1):\n",
        "        hits = []\n",
        "        for i in va_idx:\n",
        "            gold = set(y_parent_train[i] or [])\n",
        "            if not gold:\n",
        "                hits.append(0)\n",
        "                continue\n",
        "\n",
        "            # random k distinct fine-label indices\n",
        "            if len(classes) <= k:\n",
        "                sampled = np.arange(len(classes))\n",
        "            else:\n",
        "                sampled = rng.choice(len(classes), size=k, replace=False)\n",
        "\n",
        "            pred_parents = set(classes_parent[sampled])\n",
        "            pred_parents.discard(\"\")\n",
        "            hits.append(1 if gold.intersection(pred_parents) else 0)\n",
        "\n",
        "        score = float(np.mean(hits)) if hits else 0.0\n",
        "        scores.append(score)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Fold {fold}: baseline-random Parent-Hit@{k}={score:.3f}\")\n",
        "\n",
        "    return np.asarray(scores, dtype=float)\n",
        "\n",
        "# run\n",
        "random_scores = cv_baseline_random_label_parent_hit_at_k(\n",
        "    y_parent_train=y_parent_train,\n",
        "    classes=classes,\n",
        "    k=3,\n",
        "    n_splits=5,\n",
        "    cv_seed=123,\n",
        "    verbose=True\n",
        ")\n",
        "print(f\"Baseline random: mean={random_scores.mean():.4f} std={random_scores.std(ddof=0):.4f} scores={random_scores}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "uQW-GTvffuXO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "uQW-GTvffuXO",
        "outputId": "478e7b10-06f7-4024-ed82-bf82ccb0a399"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A_char + word_summary</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C_charWB + word_summary</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B_char + word_summary + word_text</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D_charWB + word_summary + word_text</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BASE_majority_parent</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BASE_random_fine</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.093541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 model   mean       std\n",
              "0                A_char + word_summary  0.450  0.187083\n",
              "1              C_charWB + word_summary  0.450  0.187083\n",
              "2    B_char + word_summary + word_text  0.425  0.187083\n",
              "3  D_charWB + word_summary + word_text  0.425  0.187083\n",
              "4                 BASE_majority_parent  0.300  0.100000\n",
              "5                     BASE_random_fine  0.100  0.093541"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cv_results_with_baselines = dict(cv_results)\n",
        "cv_results_with_baselines[\"BASE_majority_parent\"] = baseline_scores\n",
        "cv_results_with_baselines[\"BASE_random_fine\"] = random_scores\n",
        "\n",
        "cv_summary2 = (\n",
        "    pd.DataFrame({\n",
        "        \"model\": list(cv_results_with_baselines.keys()),\n",
        "        \"mean\": [cv_results_with_baselines[m].mean() for m in cv_results_with_baselines],\n",
        "        \"std\":  [cv_results_with_baselines[m].std(ddof=0) for m in cv_results_with_baselines],\n",
        "    })\n",
        "    .sort_values(\"mean\", ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "display(cv_summary2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mbh5CLJEjLrx",
      "metadata": {
        "id": "mbh5CLJEjLrx"
      },
      "source": [
        "Parent-Hit@3 ≈ 0.45 means that, on average, in 45% of cases the model’s top-3 fine-grained ATU predictions include at least one label whose numeric parent code (digits only, e.g., 480 for 480A/480D*) matches one of the gold parent codes for that tale.\n",
        "\n",
        "A majority-parent baseline of 0.30 shows that simply predicting the most frequent parent codes already yields 30% hits under this metric. However, the best model variants improve this to 0.45, i.e., an absolute gain of +0.15 over the frequency baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2PPrXdXOjtOz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "2PPrXdXOjtOz",
        "outputId": "67cc1468-b30e-4c85-8e7c-6004c9247e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST Parent-Hit@3: 0.6000\n",
            "TEST Exact-Hit@3:  0.6000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>gold_labels</th>\n",
              "      <th>gold_parents</th>\n",
              "      <th>pred_top3_labels</th>\n",
              "      <th>pred_top3_parents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_12_541_1</td>\n",
              "      <td>[700]</td>\n",
              "      <td>[700]</td>\n",
              "      <td>[700, 707, 552]</td>\n",
              "      <td>[700, 707, 552]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_12_592_4</td>\n",
              "      <td>[703*]</td>\n",
              "      <td>[703]</td>\n",
              "      <td>[703*, 707, 552]</td>\n",
              "      <td>[703, 707, 552]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_97_19</td>\n",
              "      <td>[480D*]</td>\n",
              "      <td>[480]</td>\n",
              "      <td>[480D*, 552, 707]</td>\n",
              "      <td>[480, 552, 707]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_13_106_14</td>\n",
              "      <td>[307, 410]</td>\n",
              "      <td>[307, 410]</td>\n",
              "      <td>[707, 552, 650A]</td>\n",
              "      <td>[707, 552, 650]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_14_451_7</td>\n",
              "      <td>[650A]</td>\n",
              "      <td>[650]</td>\n",
              "      <td>[707, 402, 480A]</td>\n",
              "      <td>[707, 402, 480]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>era_vene_16_744_22</td>\n",
              "      <td>[300]</td>\n",
              "      <td>[300]</td>\n",
              "      <td>[707, 402, 552]</td>\n",
              "      <td>[707, 402, 552]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>era_vene_2_622_5</td>\n",
              "      <td>[425C]</td>\n",
              "      <td>[425]</td>\n",
              "      <td>[707, 552, 425C]</td>\n",
              "      <td>[707, 552, 425]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>era_vene_7_71_1</td>\n",
              "      <td>[301]</td>\n",
              "      <td>[301]</td>\n",
              "      <td>[707, 552, 650A]</td>\n",
              "      <td>[707, 552, 650]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rkm_vene_1_82_47</td>\n",
              "      <td>[707]</td>\n",
              "      <td>[707]</td>\n",
              "      <td>[707, 650A, 552]</td>\n",
              "      <td>[707, 650, 552]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tru_vkk_5_36_20</td>\n",
              "      <td>[530]</td>\n",
              "      <td>[530]</td>\n",
              "      <td>[707, 530, 552]</td>\n",
              "      <td>[707, 530, 552]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tale_id gold_labels gold_parents   pred_top3_labels  \\\n",
              "0   era_vene_12_541_1       [700]        [700]    [700, 707, 552]   \n",
              "1   era_vene_12_592_4      [703*]        [703]   [703*, 707, 552]   \n",
              "2   era_vene_12_97_19     [480D*]        [480]  [480D*, 552, 707]   \n",
              "3  era_vene_13_106_14  [307, 410]   [307, 410]   [707, 552, 650A]   \n",
              "4   era_vene_14_451_7      [650A]        [650]   [707, 402, 480A]   \n",
              "5  era_vene_16_744_22       [300]        [300]    [707, 402, 552]   \n",
              "6    era_vene_2_622_5      [425C]        [425]   [707, 552, 425C]   \n",
              "7     era_vene_7_71_1       [301]        [301]   [707, 552, 650A]   \n",
              "8    rkm_vene_1_82_47       [707]        [707]   [707, 650A, 552]   \n",
              "9     tru_vkk_5_36_20       [530]        [530]    [707, 530, 552]   \n",
              "\n",
              "  pred_top3_parents  \n",
              "0   [700, 707, 552]  \n",
              "1   [703, 707, 552]  \n",
              "2   [480, 552, 707]  \n",
              "3   [707, 552, 650]  \n",
              "4   [707, 402, 480]  \n",
              "5   [707, 402, 552]  \n",
              "6   [707, 552, 425]  \n",
              "7   [707, 552, 650]  \n",
              "8   [707, 650, 552]  \n",
              "9   [707, 530, 552]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# If you want to force the best model explicitly (recommended for reproducibility):\n",
        "best_builder = lambda: build_model(use_word_summary=True, use_word_text=False, char_analyzer=\"char\")  # Model A\n",
        "\n",
        "K = 3\n",
        "\n",
        "Y_train = mlb.fit_transform(y_train_list)\n",
        "classes = np.asarray(mlb.classes_)\n",
        "\n",
        "# ---- train best model on FULL TRAIN ----\n",
        "best_model = best_builder()\n",
        "best_model.fit(X_train, Y_train)\n",
        "\n",
        "# ---- predict on TEST ----\n",
        "proba = best_model.predict_proba(X_test)\n",
        "\n",
        "# normalize possible list-of-arrays to 2D array (defensive)\n",
        "if isinstance(proba, list):\n",
        "    cols = []\n",
        "    for p in proba:\n",
        "        p = np.asarray(p)\n",
        "        if p.ndim == 2 and p.shape[1] == 2:\n",
        "            cols.append(p[:, 1])\n",
        "        elif p.ndim == 2 and p.shape[1] == 1:\n",
        "            cols.append(p[:, 0])\n",
        "        else:\n",
        "            cols.append(p.reshape(-1))\n",
        "    proba = np.column_stack(cols)\n",
        "else:\n",
        "    proba = np.asarray(proba)\n",
        "\n",
        "# ---- metrics on TEST (no fitting here) ----\n",
        "test_parent_hit3 = parent_hit_at_k_from_proba(\n",
        "    y_true_parent_lists=test_df[\"labels_parent\"].tolist(),\n",
        "    proba=proba,\n",
        "    classes=classes,\n",
        "    k=K,\n",
        ")\n",
        "\n",
        "test_exact_hit3 = exact_hit_at_k_from_proba(\n",
        "    y_true_labels_lists=y_test_list,\n",
        "    proba=proba,\n",
        "    classes=classes,\n",
        "    k=K,\n",
        ")\n",
        "\n",
        "print(f\"TEST Parent-Hit@{K}: {test_parent_hit3:.4f}\")\n",
        "print(f\"TEST Exact-Hit@{K}:  {test_exact_hit3:.4f}\")\n",
        "\n",
        "# ---- optional: per-item Top-3 report (useful for QA/UI) ----\n",
        "topk_idx = np.argsort(-proba, axis=1)[:, :K]\n",
        "pred_topk = [[classes[j] for j in row] for row in topk_idx]\n",
        "pred_topk_parent = [[atu_parent(lab) for lab in row] for row in pred_topk]\n",
        "\n",
        "report = pd.DataFrame({\n",
        "    \"tale_id\": test_df[\"tale_id\"] if \"tale_id\" in test_df.columns else np.arange(len(test_df)),\n",
        "    \"gold_labels\": y_test_list,\n",
        "    \"gold_parents\": test_df[\"labels_parent\"].tolist(),\n",
        "    \"pred_top3_labels\": pred_topk,\n",
        "    \"pred_top3_parents\": pred_topk_parent,\n",
        "})\n",
        "\n",
        "display(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "Z0snPhSZkPTZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0snPhSZkPTZ",
        "outputId": "eb006da8-89b8-4eda-cffb-bb2424a4003a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gold parents in TEST: Counter({'700': 1, '703': 1, '480': 1, '307': 1, '410': 1, '650': 1, '300': 1, '425': 1, '301': 1, '707': 1, '530': 1})\n",
            "Pred parents in top-3: Counter({'707': 10, '552': 9, '650': 3, '480': 2, '402': 2, '700': 1, '703': 1, '425': 1, '530': 1})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "gold_parent_flat = [p for ps in test_df[\"labels_parent\"].tolist() for p in ps]\n",
        "pred_parent_flat = [p for row in pred_topk_parent for p in row]\n",
        "\n",
        "print(\"Gold parents in TEST:\", Counter(gold_parent_flat))\n",
        "print(\"Pred parents in top-3:\", Counter(pred_parent_flat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yhC682NWkkhP",
      "metadata": {
        "id": "yhC682NWkkhP"
      },
      "source": [
        "Each parent appears once: 700, 703, 480, 307, 410, 650, 300, 425, 301, 707, 530. This means the test set covers 11 distinct parents with no repetition, so performance is very sensitive to whether the model can generalize to rare parents.\n",
        "\n",
        "Hits mostly occur when the gold parent is among the “default set” the model frequently predicts (e.g., 707, 480) or when the exact label is seen strongly enough to surface (e.g., 703, 530). Rare parents outside that set are consistently missed.\n",
        "\n",
        "*Potential improvement (future work).* The current Top-3 predictions are strongly concentrated on a few high-frequency parents (e.g., 707/552/480), suggesting a class-imbalance effect. We will add more texts to increase type coverage in the Top-k list and potentially improve Parent-Hit@3. For the present milestone, we keep the metric and model configuration fixed to establish a stable baseline for the end-to-end system."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YNH3coQK-eGp",
      "metadata": {
        "id": "YNH3coQK-eGp"
      },
      "source": [
        "## Best model saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4d2dd9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_git_sha_short(default: str = \"unknown\") -> str:\n",
        "    \"\"\"Пробует взять git sha (если проект в git и git доступен).\"\"\"\n",
        "    try:\n",
        "        sha = subprocess.check_output(\n",
        "            [\"git\", \"rev-parse\", \"--short\", \"HEAD\"],\n",
        "            stderr=subprocess.DEVNULL,\n",
        "            text=True\n",
        "        ).strip()\n",
        "        return sha or default\n",
        "    except Exception:\n",
        "        return default"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a236a2d4",
      "metadata": {},
      "source": [
        "We additionally refit the final classifier on the full labeled corpus (train + test) to maximize class coverage, so the model is exposed to ATU types that may be absent or underrepresented in the training split; however, all reported performance metrics are computed strictly on the frozen test split before this refit, and the full-corpus model is used only for deployment and interactive exploration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "8E6ZAlzNA1rx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E6ZAlzNA1rx",
        "outputId": "c2304b20-cfa0-457e-93c2-41e605149558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROOT_DIR: /Users/eugenia/Desktop/thesis/magic_tagger\n",
            "MODELS_DIR: /Users/eugenia/Desktop/thesis/magic_tagger/models\n"
          ]
        }
      ],
      "source": [
        "K = 3\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Resolve repo root robustly (works in scripts and notebooks)\n",
        "# ------------------------------------------------------------\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Walk up from `start` until we find the repo root markers:\n",
        "    - folder 'models' (your case), and/or\n",
        "    - folder 'src'\n",
        "    Adjust markers if needed.\n",
        "    \"\"\"\n",
        "    cur = start.resolve()\n",
        "    for _ in range(8):  # enough for typical repo depth\n",
        "        if (cur / \"models\").is_dir() and (cur / \"src\").is_dir():\n",
        "            return cur\n",
        "        cur = cur.parent\n",
        "    # fallback: use start\n",
        "    return start.resolve()\n",
        "\n",
        "try:\n",
        "    # if running as a .py file\n",
        "    ROOT_DIR = Path(__file__).resolve().parents[1]  # .../magic_tagger (from src/*)\n",
        "except NameError:\n",
        "    # running in notebook / REPL\n",
        "    ROOT_DIR = find_repo_root(Path.cwd())\n",
        "\n",
        "MODELS_DIR = ROOT_DIR / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"ROOT_DIR:\", ROOT_DIR)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "25ac506f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained final_model on FULL dataset.\n",
            "X_full shape: (50, 2)\n",
            "Y_full shape: (50, 37)\n",
            "n_classes: 37\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Train FINAL model on FULL dataset (train + test merged)\n",
        "#   - Use only text columns (no IDs / metadata)\n",
        "#   - Fit MLB on FULL labels (so the model \"sees\" more types)\n",
        "#   - Train best model (A + balanced)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# 0) Merge\n",
        "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# 1) Build X only from text columns (no IDs / metadata)\n",
        "X_full = build_X(full_df, (\"summary_norm\", \"text_norm\"))\n",
        "\n",
        "# 2) Prepare labels and fit MLB on FULL dataset\n",
        "y_full_list = [clean_label_list(x) for x in full_df[\"labels\"].tolist()]\n",
        "\n",
        "mlb_full = MultiLabelBinarizer()\n",
        "Y_full = mlb_full.fit_transform(y_full_list)\n",
        "classes_full = [str(c) for c in mlb_full.classes_]\n",
        "# 3) Train best model (A + balanced)\n",
        "final_model = build_model(\n",
        "    use_word_summary=True,\n",
        "    use_word_text=False,\n",
        "    char_analyzer=\"char\",\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "final_model.fit(X_full, Y_full)\n",
        "\n",
        "print(\"Trained final_model on FULL dataset.\")\n",
        "print(\"X_full shape:\", X_full.shape)\n",
        "print(\"Y_full shape:\", Y_full.shape)\n",
        "print(\"n_classes:\", len(classes_full))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "DkD1fds4BMie",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkD1fds4BMie",
        "outputId": "01772570-e5d3-46c7-f3b3-d85360eda1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/eugenia/Desktop/thesis/magic_tagger/models/model.joblib /Users/eugenia/Desktop/thesis/magic_tagger/models/labels.json /Users/eugenia/Desktop/thesis/magic_tagger/models/meta.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Save artifacts to magic_tagger/models/\n",
        "# ------------------------------------------------------------\n",
        "joblib.dump(best_model, MODELS_DIR / \"model.joblib\")\n",
        "\n",
        "with open(MODELS_DIR / \"labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(classes_full, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "meta = {\n",
        "    \"task\": \"ATU multilabel classification (Top-3) + parent match\",\n",
        "    \"k\": K,\n",
        "    \"text_cols\": [\"summary_norm\", \"text_norm\"],\n",
        "    \"model_name\": \"A_char + word_summary (balanced)\",\n",
        "    \"note\": \"predict_proba columns correspond to labels.json order\",\n",
        "    \"model_version\": get_git_sha_short(),\n",
        "    \"generated_at\": datetime.now(timezone.utc).replace(microsecond=0).isoformat()\n",
        "}\n",
        "with open(MODELS_DIR / \"meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved:\",\n",
        "      MODELS_DIR / \"model.joblib\",\n",
        "      MODELS_DIR / \"labels.json\",\n",
        "      MODELS_DIR / \"meta.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "18019c01",
      "metadata": {},
      "outputs": [],
      "source": [
        "def proba_to_2d(proba) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Нормализует выход final_model.predict_proba:\n",
        "    - если list-of-arrays (часто для OVR/мульти-голов) -> (n_samples, n_classes)\n",
        "    - если уже ndarray -> просто np.asarray\n",
        "    \"\"\"\n",
        "    if isinstance(proba, list):\n",
        "        cols = []\n",
        "        for p in proba:\n",
        "            p = np.asarray(p)\n",
        "            # бинарный классификатор: берем proba класса \"1\"\n",
        "            if p.ndim == 2 and p.shape[1] == 2:\n",
        "                cols.append(p[:, 1])\n",
        "            elif p.ndim == 2 and p.shape[1] == 1:\n",
        "                cols.append(p[:, 0])\n",
        "            else:\n",
        "                cols.append(p.reshape(-1))\n",
        "        return np.column_stack(cols)\n",
        "    return np.asarray(proba)\n",
        "\n",
        "def make_json_safe(x):\n",
        "    \"\"\"Приводит numpy-типы/массивы к сериализуемым.\"\"\"\n",
        "    if isinstance(x, dict):\n",
        "        return {k: make_json_safe(v) for k, v in x.items()}\n",
        "    if isinstance(x, list):\n",
        "        return [make_json_safe(v) for v in x]\n",
        "    if isinstance(x, tuple):\n",
        "        return [make_json_safe(v) for v in x]\n",
        "    if isinstance(x, (np.floating,)):\n",
        "        return float(x)\n",
        "    if isinstance(x, (np.integer,)):\n",
        "        return int(x)\n",
        "    if isinstance(x, (np.ndarray,)):\n",
        "        return x.tolist()\n",
        "    return x\n",
        "\n",
        "def build_result_from_model(model, X_one, classes, k=3, sample_id=None):\n",
        "    \"\"\"\n",
        "    X_one: DataFrame из 1 строки (важно!)\n",
        "    classes: список классов в том же порядке, что proba-колонки\n",
        "    \"\"\"\n",
        "    proba = model.predict_proba(X_one)\n",
        "    proba = proba_to_2d(proba)               # (1, n_classes)\n",
        "    p = proba[0]\n",
        "\n",
        "    topk_idx = np.argsort(-p)[:k]\n",
        "    candidates = [{\"atu\": str(classes[j]), \"score\": float(p[j])} for j in topk_idx]\n",
        "\n",
        "    result = {\n",
        "        \"id\": sample_id,\n",
        "        \"meta\": {\n",
        "            \"k\": int(k),\n",
        "            \"n_classes\": int(len(classes)),\n",
        "        },\n",
        "        \"candidates\": candidates,\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "63df99ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/eugenia/Desktop/thesis/magic_tagger/notebooks/debug/predict_result_tru_vkk_13_59_4.json\n",
            "{\n",
            "  \"id\": \"tru_vkk_13_59_4\",\n",
            "  \"meta\": {\n",
            "    \"k\": 3,\n",
            "    \"n_classes\": 37\n",
            "  },\n",
            "  \"candidates\": [\n",
            "    {\n",
            "      \"atu\": \"554\",\n",
            "      \"score\": 0.9447313578419488\n",
            "    },\n",
            "    {\n",
            "      \"atu\": \"556F*\",\n",
            "      \"score\": 0.9447313578419488\n",
            "    },\n",
            "    {\n",
            "      \"atu\": \"302C*\",\n",
            "      \"score\": 0.9447313578419488\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 1) выберите индекс примера\n",
        "idx = 33  # поменяйте на любой (например, 10, 57, ...)\n",
        "\n",
        "# 2) сформируйте X_one (ВАЖНО: 2D, поэтому двойные скобки)\n",
        "X_one = X_full.iloc[[idx]]\n",
        "\n",
        "# 3) попробуем сделать sample_id из full_df, если есть tale_id, иначе row_{idx}\n",
        "if \"tale_id\" in full_df.columns:\n",
        "    sample_id = str(full_df.loc[idx, \"tale_id\"])\n",
        "else:\n",
        "    sample_id = f\"row_{idx}\"\n",
        "\n",
        "# 4) построить result\n",
        "result = build_result_from_model(\n",
        "    model=final_model,\n",
        "    X_one=X_one,\n",
        "    classes=classes_full,\n",
        "    k=3,\n",
        "    sample_id=sample_id\n",
        ")\n",
        "\n",
        "# 5) сохранить\n",
        "out_dir = Path(\"debug\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "out_path = out_dir / f\"predict_result_{sample_id}.json\"\n",
        "out_path.write_text(\n",
        "    json.dumps(make_json_safe(result), ensure_ascii=False, indent=2),\n",
        "    encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "print(\"Saved:\", out_path.resolve())\n",
        "print(json.dumps(result, ensure_ascii=False, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "magictagger",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
