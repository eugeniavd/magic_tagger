{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8ef39f9c",
      "metadata": {
        "id": "8ef39f9c"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "import joblib\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_URL = \"https://github.com/eugeniavd/magic_tagger.git\"  # <-- EDIT if needed\n",
        "!git clone {REPO_URL}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XKYeDbOYu_l",
        "outputId": "f6e61eef-eb52-408f-d346-81d28c2646c7"
      },
      "id": "9XKYeDbOYu_l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'magic_tagger' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = Path(\"/content/magic_tagger\")\n",
        "\n",
        "csv_path = PROJECT_ROOT / \"data\" / \"processed\" / \"classify_data_normalized.csv\"\n",
        "\n",
        "# --- load ---\n",
        "df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
        "print(\"Loaded:\", csv_path)\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "unR7iLZ9XTA7",
        "outputId": "0c43e9a2-000c-4814-d82b-2415a56327e6"
      },
      "id": "unR7iLZ9XTA7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/magic_tagger/data/processed/classify_data_normalized.csv\n",
            "Shape: (50, 14)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              tale_id rights_status  \\\n",
              "0    era_vene_1_503_1          open   \n",
              "1    era_vene_1_515_1          open   \n",
              "2  era_vene_12_105_22          open   \n",
              "3  era_vene_12_137_98          open   \n",
              "4   era_vene_12_189_1          open   \n",
              "\n",
              "                                 content_description       set  \\\n",
              "0                                 [Царевна-лягушка].      core   \n",
              "1  [По пьяни мужик спорит, что сможет принести но...  coverage   \n",
              "2                                        Снегурочка.      core   \n",
              "3                                        Иван-дурак.      core   \n",
              "4                                         Два брата.      core   \n",
              "\n",
              "  sampling_version  type_count collection  volume_no  \\\n",
              "0      v1_20251230           3  ERA, Vene          1   \n",
              "1      v1_20251230           1  ERA, Vene          1   \n",
              "2      v1_20251230           3  ERA, Vene         12   \n",
              "3      v1_20251230           4  ERA, Vene         12   \n",
              "4      v1_20251230           2  ERA, Vene         12   \n",
              "\n",
              "                  source_ref atu_labels_json  \\\n",
              "0     ERA, Vene 1, 503/4 (1)         [\"402\"]   \n",
              "1     ERA, Vene 1, 515/6 (1)         [\"410\"]   \n",
              "2     ERA, Vene 12, 105 (22)        [\"703*\"]   \n",
              "3  ERA, Vene 12, 137/41 (98)         [\"530\"]   \n",
              "4   ERA, Vene 12, 189/94 (1)        [\"735A\"]   \n",
              "\n",
              "                                            txt_path  \\\n",
              "0  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "1  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "2  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "3  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "4  /Users/eugenia/Desktop/thesis/magic_tagger/dat...   \n",
              "\n",
              "                                            text_raw  \\\n",
              "0  Тили были царь с царицей у не\\nбыло три сына. ...   \n",
              "1  Раз пяное, ребятище» подился.\\nчто можит в 12 ...   \n",
              "2  Сделали дети со снегу куклу.\\nВ одного старина...   \n",
              "3  Кил-был стажк. В яво бло\\nтра сегна. Миша, Гри...   \n",
              "4  Жили – брели два брата.\\nи посла смерти отца о...   \n",
              "\n",
              "                                        summary_norm  \\\n",
              "0                                   царевна-лягушка.   \n",
              "1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2                                        снегурочка.   \n",
              "3                                        иван-дурак.   \n",
              "4                                         два брата.   \n",
              "\n",
              "                                           text_norm  \n",
              "0  тили были царь с царицей у не было три сына. ц...  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...  \n",
              "4  жили — брели два брата. и посла смерти отца об...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d48f213-b8f2-4172-8e6c-5d856ad24287\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>rights_status</th>\n",
              "      <th>content_description</th>\n",
              "      <th>set</th>\n",
              "      <th>sampling_version</th>\n",
              "      <th>type_count</th>\n",
              "      <th>collection</th>\n",
              "      <th>volume_no</th>\n",
              "      <th>source_ref</th>\n",
              "      <th>atu_labels_json</th>\n",
              "      <th>txt_path</th>\n",
              "      <th>text_raw</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>open</td>\n",
              "      <td>[Царевна-лягушка].</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>3</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene 1, 503/4 (1)</td>\n",
              "      <td>[\"402\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Тили были царь с царицей у не\\nбыло три сына. ...</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>open</td>\n",
              "      <td>[По пьяни мужик спорит, что сможет принести но...</td>\n",
              "      <td>coverage</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>1</td>\n",
              "      <td>ERA, Vene 1, 515/6 (1)</td>\n",
              "      <td>[\"410\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Раз пяное, ребятище» подился.\\nчто можит в 12 ...</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>open</td>\n",
              "      <td>Снегурочка.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>3</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 105 (22)</td>\n",
              "      <td>[\"703*\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Сделали дети со снегу куклу.\\nВ одного старина...</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>open</td>\n",
              "      <td>Иван-дурак.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>4</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 137/41 (98)</td>\n",
              "      <td>[\"530\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Кил-был стажк. В яво бло\\nтра сегна. Миша, Гри...</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>open</td>\n",
              "      <td>Два брата.</td>\n",
              "      <td>core</td>\n",
              "      <td>v1_20251230</td>\n",
              "      <td>2</td>\n",
              "      <td>ERA, Vene</td>\n",
              "      <td>12</td>\n",
              "      <td>ERA, Vene 12, 189/94 (1)</td>\n",
              "      <td>[\"735A\"]</td>\n",
              "      <td>/Users/eugenia/Desktop/thesis/magic_tagger/dat...</td>\n",
              "      <td>Жили – брели два брата.\\nи посла смерти отца о...</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d48f213-b8f2-4172-8e6c-5d856ad24287')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d48f213-b8f2-4172-8e6c-5d856ad24287 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d48f213-b8f2-4172-8e6c-5d856ad24287');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ac90cfad-f349-4df8-8684-0affc58aa7dc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac90cfad-f349-4df8-8684-0affc58aa7dc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ac90cfad-f349-4df8-8684-0affc58aa7dc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tale_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"era_vene_1_515_1\",\n          \"era_vene_12_189_1\",\n          \"era_vene_12_105_22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rights_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"open\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\u041f\\u043e \\u043f\\u044c\\u044f\\u043d\\u0438 \\u043c\\u0443\\u0436\\u0438\\u043a \\u0441\\u043f\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u0441\\u043c\\u043e\\u0436\\u0435\\u0442 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u0442\\u0438 \\u043d\\u043e\\u0447\\u044c\\u044e \\u0441 \\u043a\\u0430\\u043c\\u0435\\u043d\\u043a\\u0438 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c. \\u0418\\u0434\\u0451\\u0442 \\u0432 \\u0431\\u0430\\u043d\\u044e, \\u0431\\u0435\\u0440\\u0451\\u0442 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c, \\u0435\\u0433\\u043e \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0445\\u0432\\u0430\\u0442\\u0430\\u0435\\u0442 \\u0437\\u0430 \\u0440\\u0443\\u043a\\u0443. \\u0421\\u043b\\u044b\\u0448\\u0438\\u0442 \\u0433\\u043e\\u043b\\u043e\\u0441 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0438, \\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u043e\\u0442\\u043f\\u0443\\u0441\\u0442\\u0438\\u0442, \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u0435\\u0441\\u043b\\u0438 \\u0437\\u0430\\u043c\\u0443\\u0436 \\u0432\\u043e\\u0437\\u044c\\u043c\\u0451\\u0442. \\u041c\\u0443\\u0436\\u0438\\u043a \\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f, \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u043e\\u0442\\u043f\\u0443\\u0441\\u043a\\u0430\\u0435\\u0442.\\n\\u0427\\u0435\\u0440\\u0435\\u0437 \\u0432\\u0440\\u0435\\u043c\\u044f \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u0435\\u043c\\u0443 \\u0432\\u043e \\u0441\\u043d\\u0435, \\u043c\\u0443\\u0447\\u0430\\u0435\\u0442 \\u0435\\u0433\\u043e. \\u0421\\u0432\\u0430\\u0434\\u0435\\u0431\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0435\\u0437\\u0434 \\u043e\\u0441\\u0442\\u0430\\u043d\\u0430\\u0432\\u043b\\u0438\\u0432\\u0430\\u0435\\u0442\\u0441\\u044f \\u0443 \\u0431\\u0430\\u043d\\u0438, \\u0432\\u044b\\u0432\\u043e\\u0434\\u044f\\u0442 \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0443 \\u0438\\u0437-\\u043f\\u043e\\u0434 \\u043f\\u043e\\u043b\\u0430. \\u041f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0435 \\u0438\\u0434\\u0451\\u0442 \\u0432 \\u0446\\u0435\\u0440\\u043a\\u043e\\u0432\\u044c. \\u0413\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u043f\\u0443\\u0441\\u0442\\u044c \\u043f\\u043e\\u043f \\u043a\\u0438\\u043d\\u0435\\u0442 \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e \\u0440\\u0435\\u0431\\u0451\\u043d\\u043a\\u0430 \\u0432 \\u043f\\u0435\\u0447\\u044c, \\u043f\\u043e\\u0442\\u043e\\u043c\\u0443 \\u0447\\u0442\\u043e \\u044d\\u0442\\u043e \\u043f\\u043e\\u0434\\u043c\\u0451\\u043d\\u044b\\u0448 \\u0447\\u0435\\u0440\\u0442\\u0435\\u0439, \\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u0435\\u0451 \\u0432 \\u0431\\u0430\\u043d\\u0438 \\u0437\\u0430\\u0441\\u0430\\u0434\\u0438\\u043b\\u0438. \\u041f\\u043e\\u043f \\u0441\\u043b\\u0443\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f, \\u043c\\u0443\\u0436\\u0438\\u043a \\u0438 \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430\\u044f \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u0436\\u0435\\u043d\\u044f\\u0442\\u0441\\u044f.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"coverage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sampling_version\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"v1_20251230\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"collection\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ERA, Vene\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume_no\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ERA, Vene 1, 515/6 (1)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atu_labels_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"410\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"txt_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/Users/eugenia/Desktop/thesis/magic_tagger/data/processed/text_extraction/era_vene_1_515_1.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0420\\u0430\\u0437 \\u043f\\u044f\\u043d\\u043e\\u0435, \\u0440\\u0435\\u0431\\u044f\\u0442\\u0438\\u0449\\u0435\\u00bb \\u043f\\u043e\\u0434\\u0438\\u043b\\u0441\\u044f.\\n\\u0447\\u0442\\u043e \\u043c\\u043e\\u0436\\u0438\\u0442 \\u0432 12 \\u0447\\u0430\\u0441\\u043e\\u0432 \\u043d\\u043e\\u0447\\u0438 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u043e\\n\\u0441 \\u043f\\u0430\\u043c\\u0435\\u043d\\u043a\\u0438 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c. \\u0423\\u044e\\u0448\\u0430\\u044f \\u043e\\u043d \\u0432 \\u0431\\u0430\\u043d\\u044e\\n\\u041a\\u0430\\u043a \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u0432\\u0437\\u044f\\u043b \\u043e\\u043d \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c, \\u043f\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443\\n\\u0445\\u0432\\u043e\\u0442\\u0438\\u043b \\u043a\\u0442\\u043e \\u043f\\u043e \\u0435\\u043c\\u0443 \\u0437\\u0430 \\u0440\\u0443\\u043a\\u0443 \\u0438 \\u043d\\u0435\\n\\u043f\\u0443\\u0441\\u043d\\u0430\\u0435\\u0442. \\u041f\\u0440\\u043e\\u0431\\u044b\\u043b \\u043e\\u043d \\u0440\\u0432\\u0430\\u0442\\u044c\\u0441\\u044f, \\u043d\\u043e \\u043d\\u0435\\n\\u0447\\u0442\\u043e \\u043d\\u0435 \\u043f\\u043e\\u043c\\u043e\\u0433\\u0430\\u0441\\u0442\\u044c. \\u0412\\u0434\\u0440\\u0443\\u0433 \\u043f\\u043e\\u0441\\u043b\\u044b\\u0448\\u0438\\u043b\\u0441\\u044f\\n\\u0433\\u043e\\u043b\\u043e\\u0435 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0438. \\u041e\\u043d\\u0430 \\u0435\\u043c\\u0443 \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430.\\n\\u0432\\u043e\\u0437\\u043c\\u0438 \\u043c\\u0435\\u043d\\u044f \\u0437\\u0430\\u043c\\u0443\\u0436, \\u0430 \\u0435\\u0441\\u043b\\u0438 \\u043d\\u0435 \\u0432\\u043e\\u0437\\u043c\\u0435\\u043d\\u044c\\n\\u0442\\u043e \\u044f \\u0442\\u0435\\u0431\\u044f \\u043e\\u0442 \\u0441\\u044e\\u0434\\u0430 \\u043d\\u0435 \\u043f\\u0443\\u0449\\u0443. \\u0414\\u0435\\u043b\\u0430\\u0442\\u044c\\n\\u0431\\u044b\\u043b\\u043e \\u043d\\u0435\\u0447\\u0435\\u0433\\u043e. \\u041e\\u043d \\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u0438\\u043b\\u0441\\u044f \\u0435\\u0435 \\u0432\\u0437\\u044f\\u0442\\u044c.\\n\\u0437\\u0430\\u043c\\u0443\\u0436. \\u041e\\u043d\\u0430 \\u0435\\u0433\\u043e \\u043e\\u0442\\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0430 \\u0434\\u043e\\u043c\\u043e\\u0439.\\n\\u041f\\u0440\\u0438\\u0448\\u0430\\u044f \\u043e\\u043d \\u0434\\u043e\\u043c\\u043e\\u0439 \\u0438 \\u043d\\u0435\\u043c\\u043e\\u0436\\u0438\\u0442\\n\\n\\n\\u043e\\u043f\\u043e\\u043c\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f. \\u041f\\u0440\\u043e\\u0448\\u043b\\u043e \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e \\u0432\\u0440\\u0435\\u043c\\u0435\\u043d\\u0438.\\n\\u0434\\u0435\\u0442\\u0438\\u0449\\u0435 \\u0447\\u0442\\u043e\\u0442 \\u0443\\u0436\\u0435 \\u0432\\u0441\\u0435 \\u0437\\u0430\\u0431\\u044b\\u043b. \\u0421\\u0435\\u0440\\u0435\\u0437\\u0436\\u0435\\u043d\\n\\u0432\\u0440\\u0435\\u043c\\u044f \\u0441\\u0442\\u0430\\u043b\\u0430 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u0435\\u043c\\u0443 \\u044f\\u0432\\u043b\\u044f\\u0442\\u0441\\u044f \\u0432\\u043e\\u0441\\u043d\\u0435\\n\\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u043b\\u0430 \\u0442\\u0435\\u0436\\u0435 \\u0441\\u043b\\u043e\\u0432\\u0430. \\u041e\\u043d\\u0430 \\u0436\\u0434\\u043e\\u0432\\u0430\\u043b\\u0430 \\u0435\\u043c\\u0443\\n\\u0441\\u043f\\u043e\\u043a\\u043e\\u044e. \\u041f\\u0440\\u0438\\u0448\\u043b\\u043e\\u0441\\u044c \\u0435\\u043c\\u0443 \\u043c\\u0435\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f \\u043d\\u0430 \\u043f\\u0435\\u0439\\n\\u0417\\u0430\\u043f\\u0440\\u044f\\u0442\\u0438 \\u043b\\u043e\\u0433\\u0430\\u0434\\u0435\\u0439 \\u0438 \\u0433\\u043e\\u0441\\u0445\\u0430\\u043b\\u0438 \\u0433\\u043e\\u0441\\u0442\\u0438 \\u0437\\u0430 \\u043c\\n\\u0442\\u043e\\u0439. \\u0416\\u0430\\u043d\\u0438\\u0445 \\u0435\\u0434\\u0438\\u0442 \\u043d\\u0430 \\u043f\\u0435\\u0440\\u0435\\u0434\\u043d\\u0435\\u0439 \\u0433\\u043e\\u0442\\u0430\\u0434\\u044b. \\u0412\\u0434\\n\\u043e\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u043b\\u0441\\u044f \\u0438\\u0430\\u043d\\u0438\\u0445 \\u043f\\u0435\\u0440\\u0435\\u0434 \\u0431\\u0430\\u043d\\u0435\\u0439 \\u0412\\u0441\\u0435\\u0433\\u043e\\u0441\\u0442\\u0430\\n\\u0438\\u0441\\u043f\\u0443\\u0433\\u0430\\u043b\\u0438\\u0441\\u044c \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0435\\u0433\\u043e \\u0441\\u043f\\u0440\\u0430\\u0448\\u0438\\u0432\\u0430\\u0442\\u044c, \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e\\n\\u0436\\u0438\\u0432\\u0435\\u0442 \\u0442\\u0432\\u043e\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430. \\u041e\\u043d \\u0438\\u0438 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438 \\u043f\\u043e\\u0445\\u0430\\u0442\\u044c\\n\\u0412\\u043e\\u0448\\u043b\\u0438 \\u043e\\u043d\\u0438 \\u0432 \\u0431\\u0430\\u043d\\u044e\\u043b \\u0432\\u044b\\u0432\\u0435\\u0447\\u0438\\u0438 \\u043f\\u043e\\u0434 \\u043f\\u043e\\u043b\\u043a\\u0430\\n\\u043a\\u0440\\u0430\\u0441\\u0430\\u0432\\u0438\\u0446\\u0443 \\u2013 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0443, \\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f \\u0431\\u044b\\u043b\\u0430 \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430.\\n\\u041f\\u043e\\u0435\\u0445\\u0430\\u043b\\u0438 \\u043e\\u043d\\u0438 \\u0432 \\u0426\\u0435\\u0440\\u043a\\u043e\\u0432\\u044c \\u0432\\u0435\\u043d\\u0447\\u0430\\u0442\\u044c\\u0441\\u044f. \\u041e\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u0432\\u0430\\n\\u043a\\u0430\\u0433\\u043e \\u0446\\u0435\\u0440\\u043a\\u0432\\u0438, \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0435 \\u0438\\u0434\\u0435\\u0442 1 \\u0446\\u0435\\u0440\\u043a\\u043e\\u0432\\u044a. \\u041e\\u043d\\u0430\\n\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430: \\u041f\\u043e\\u0434\\u0438 \\u043a \\u043f\\u043e\\u043f\\u0443, \\u043f\\u0443\\u0441\\u043a\\u043e\\u0439 \\u043e\\u043a\\u0438 \\u043d\\u0438\\u043d\\u0443\\u0442 \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e\\n\\u0440\\u0435\\u0431\\u0435\\u043d\\u043a\\u0430 \\u0432 \\u0433\\u043e\\u0440\\u044f\\u0447\\u0443\\u044e \\u043f\\u0435\\u0447\\u044c, \\u044d\\u0442\\u043e \\u0447\\u0435\\u0440\\u0442\\u0438 \\u0438\\u043c\\n\\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u043b\\u0438 \\u043d\\u0430 \\u043c\\u0435\\u0441\\u0442\\u043e \\u043c\\u0435\\u043d\\u044f, \\u0430 \\u043c\\u0435\\u043d\\u044f \\u0442\\u0443\\u0434\\u0430\\n\\u0432 \\u0431\\u0430\\u043d\\u044e \\u0441\\u043f\\u0435\\u0441\\u043b\\u0438 \\u0430 \\u044f \\u0443\\u0436\\u0435 \\u0442\\u0430\\u043c 10\\u0433\\u043e\\u0434 \\u0436\\u0438\\u043b\\u0430.\\n\\u041f\\u043e\\u0441\\u043b\\u0443\\u0448\\u0430\\u043b\\u0441\\u044f \\u043f\\u043e\\u043f\\u0438 \\u0441\\u0436\\u043e\\u043a \\u0447\\u0435\\u0440\\u0442\\u0435\\u043d\\u0435\\u043d\\u043a\\u0430.\\n\\u041e\\u043d\\u0438 \\u043e\\u0431\\u044b\\u043d\\u0430\\u043b\\u0438\\u0441\\u044c \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0432\\u043c\\u0435\\u0441\\u0442\\u0435 \\u043c\\u043d\\u0435\\n\\u043f\\u043e\\u0436\\u0438\\u0432\\u0430\\u0442\\u044c.\\n\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u043f\\u043e \\u043f\\u044c\\u044f\\u043d\\u0438 \\u043c\\u0443\\u0436\\u0438\\u043a \\u0441\\u043f\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u0441\\u043c\\u043e\\u0436\\u0435\\u0442 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u0442\\u0438 \\u043d\\u043e\\u0447\\u044c\\u044e \\u0441 \\u043a\\u0430\\u043c\\u0435\\u043d\\u043a\\u0438 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c. \\u0438\\u0434\\u0435\\u0442 \\u0432 \\u0431\\u0430\\u043d\\u044e, \\u0431\\u0435\\u0440\\u0435\\u0442 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c, \\u0435\\u0433\\u043e \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0445\\u0432\\u0430\\u0442\\u0430\\u0435\\u0442 \\u0437\\u0430 \\u0440\\u0443\\u043a\\u0443. \\u0441\\u043b\\u044b\\u0448\\u0438\\u0442 \\u0433\\u043e\\u043b\\u043e\\u0441 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0438, \\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u043e\\u0442\\u043f\\u0443\\u0441\\u0442\\u0438\\u0442, \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u0435\\u0441\\u043b\\u0438 \\u0437\\u0430\\u043c\\u0443\\u0436 \\u0432\\u043e\\u0437\\u044c\\u043c\\u0435\\u0442. \\u043c\\u0443\\u0436\\u0438\\u043a \\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f, \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u043e\\u0442\\u043f\\u0443\\u0441\\u043a\\u0430\\u0435\\u0442. \\u0447\\u0435\\u0440\\u0435\\u0437 \\u0432\\u0440\\u0435\\u043c\\u044f \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u0435\\u043c\\u0443 \\u0432\\u043e \\u0441\\u043d\\u0435, \\u043c\\u0443\\u0447\\u0430\\u0435\\u0442 \\u0435\\u0433\\u043e. \\u0441\\u0432\\u0430\\u0434\\u0435\\u0431\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0435\\u0437\\u0434 \\u043e\\u0441\\u0442\\u0430\\u043d\\u0430\\u0432\\u043b\\u0438\\u0432\\u0430\\u0435\\u0442\\u0441\\u044f \\u0443 \\u0431\\u0430\\u043d\\u0438, \\u0432\\u044b\\u0432\\u043e\\u0434\\u044f\\u0442 \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0443 \\u0438\\u0437-\\u043f\\u043e\\u0434 \\u043f\\u043e\\u043b\\u0430. \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0435 \\u0438\\u0434\\u0435\\u0442 \\u0432 \\u0446\\u0435\\u0440\\u043a\\u043e\\u0432\\u044c. \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u043f\\u0443\\u0441\\u0442\\u044c \\u043f\\u043e\\u043f \\u043a\\u0438\\u043d\\u0435\\u0442 \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e \\u0440\\u0435\\u0431\\u0435\\u043d\\u043a\\u0430 \\u0432 \\u043f\\u0435\\u0447\\u044c, \\u043f\\u043e\\u0442\\u043e\\u043c\\u0443 \\u0447\\u0442\\u043e \\u044d\\u0442\\u043e \\u043f\\u043e\\u0434\\u043c\\u0435\\u043d\\u044b\\u0448 \\u0447\\u0435\\u0440\\u0442\\u0435\\u0439, \\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u0435\\u0435 \\u0432 \\u0431\\u0430\\u043d\\u0438 \\u0437\\u0430\\u0441\\u0430\\u0434\\u0438\\u043b\\u0438. \\u043f\\u043e\\u043f \\u0441\\u043b\\u0443\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f, \\u043c\\u0443\\u0436\\u0438\\u043a \\u0438 \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430\\u044f \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u0436\\u0435\\u043d\\u044f\\u0442\\u0441\\u044f.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0440\\u0430\\u0437 \\u043f\\u044f\\u043d\\u043e\\u0435, \\u0440\\u0435\\u0431\\u044f\\u0442\\u0438\\u0449\\u0435\\u00bb \\u043f\\u043e\\u0434\\u0438\\u043b\\u0441\\u044f. \\u0447\\u0442\\u043e \\u043c\\u043e\\u0436\\u0438\\u0442 \\u0432 12 \\u0447\\u0430\\u0441\\u043e\\u0432 \\u043d\\u043e\\u0447\\u0438 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u043e \\u0441 \\u043f\\u0430\\u043c\\u0435\\u043d\\u043a\\u0438 \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c. \\u0443\\u044e\\u0448\\u0430\\u044f \\u043e\\u043d \\u0432 \\u0431\\u0430\\u043d\\u044e \\u043a\\u0430\\u043a \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u0432\\u0437\\u044f\\u043b \\u043e\\u043d \\u043a\\u0430\\u043c\\u0435\\u043d\\u044c, \\u043f\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443 \\u0445\\u0432\\u043e\\u0442\\u0438\\u043b \\u043a\\u0442\\u043e \\u043f\\u043e \\u0435\\u043c\\u0443 \\u0437\\u0430 \\u0440\\u0443\\u043a\\u0443 \\u0438 \\u043d\\u0435 \\u043f\\u0443\\u0441\\u043d\\u0430\\u0435\\u0442. \\u043f\\u0440\\u043e\\u0431\\u044b\\u043b \\u043e\\u043d \\u0440\\u0432\\u0430\\u0442\\u044c\\u0441\\u044f, \\u043d\\u043e \\u043d\\u0435 \\u0447\\u0442\\u043e \\u043d\\u0435 \\u043f\\u043e\\u043c\\u043e\\u0433\\u0430\\u0441\\u0442\\u044c. \\u0432\\u0434\\u0440\\u0443\\u0433 \\u043f\\u043e\\u0441\\u043b\\u044b\\u0448\\u0438\\u043b\\u0441\\u044f \\u0433\\u043e\\u043b\\u043e\\u0435 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0438. \\u043e\\u043d\\u0430 \\u0435\\u043c\\u0443 \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430. \\u0432\\u043e\\u0437\\u043c\\u0438 \\u043c\\u0435\\u043d\\u044f \\u0437\\u0430\\u043c\\u0443\\u0436, \\u0430 \\u0435\\u0441\\u043b\\u0438 \\u043d\\u0435 \\u0432\\u043e\\u0437\\u043c\\u0435\\u043d\\u044c \\u0442\\u043e \\u044f \\u0442\\u0435\\u0431\\u044f \\u043e\\u0442 \\u0441\\u044e\\u0434\\u0430 \\u043d\\u0435 \\u043f\\u0443\\u0449\\u0443. \\u0434\\u0435\\u043b\\u0430\\u0442\\u044c \\u0431\\u044b\\u043b\\u043e \\u043d\\u0435\\u0447\\u0435\\u0433\\u043e. \\u043e\\u043d \\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u0438\\u043b\\u0441\\u044f \\u0435\\u0435 \\u0432\\u0437\\u044f\\u0442\\u044c. \\u0437\\u0430\\u043c\\u0443\\u0436. \\u043e\\u043d\\u0430 \\u0435\\u0433\\u043e \\u043e\\u0442\\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0430 \\u0434\\u043e\\u043c\\u043e\\u0439. \\u043f\\u0440\\u0438\\u0448\\u0430\\u044f \\u043e\\u043d \\u0434\\u043e\\u043c\\u043e\\u0439 \\u0438 \\u043d\\u0435\\u043c\\u043e\\u0436\\u0438\\u0442 \\u043e\\u043f\\u043e\\u043c\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f. \\u043f\\u0440\\u043e\\u0448\\u043b\\u043e \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e \\u0432\\u0440\\u0435\\u043c\\u0435\\u043d\\u0438. \\u0434\\u0435\\u0442\\u0438\\u0449\\u0435 \\u0447\\u0442\\u043e\\u0442 \\u0443\\u0436\\u0435 \\u0432\\u0441\\u0435 \\u0437\\u0430\\u0431\\u044b\\u043b. \\u0441\\u0435\\u0440\\u0435\\u0437\\u0436\\u0435\\u043d \\u0432\\u0440\\u0435\\u043c\\u044f \\u0441\\u0442\\u0430\\u043b\\u0430 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u0435\\u043c\\u0443 \\u044f\\u0432\\u043b\\u044f\\u0442\\u0441\\u044f \\u0432\\u043e\\u0441\\u043d\\u0435 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u043b\\u0430 \\u0442\\u0435\\u0436\\u0435 \\u0441\\u043b\\u043e\\u0432\\u0430. \\u043e\\u043d\\u0430 \\u0436\\u0434\\u043e\\u0432\\u0430\\u043b\\u0430 \\u0435\\u043c\\u0443 \\u0441\\u043f\\u043e\\u043a\\u043e\\u044e. \\u043f\\u0440\\u0438\\u0448\\u043b\\u043e\\u0441\\u044c \\u0435\\u043c\\u0443 \\u043c\\u0435\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f \\u043d\\u0430 \\u043f\\u0435\\u0439 \\u0437\\u0430\\u043f\\u0440\\u044f\\u0442\\u0438 \\u043b\\u043e\\u0433\\u0430\\u0434\\u0435\\u0439 \\u0438 \\u0433\\u043e\\u0441\\u0445\\u0430\\u043b\\u0438 \\u0433\\u043e\\u0441\\u0442\\u0438 \\u0437\\u0430 \\u043c \\u0442\\u043e\\u0439. \\u0436\\u0430\\u043d\\u0438\\u0445 \\u0435\\u0434\\u0438\\u0442 \\u043d\\u0430 \\u043f\\u0435\\u0440\\u0435\\u0434\\u043d\\u0435\\u0439 \\u0433\\u043e\\u0442\\u0430\\u0434\\u044b. \\u0432\\u0434 \\u043e\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u043b\\u0441\\u044f \\u0438\\u0430\\u043d\\u0438\\u0445 \\u043f\\u0435\\u0440\\u0435\\u0434 \\u0431\\u0430\\u043d\\u0435\\u0439 \\u0432\\u0441\\u0435\\u0433\\u043e\\u0441\\u0442\\u0430 \\u0438\\u0441\\u043f\\u0443\\u0433\\u0430\\u043b\\u0438\\u0441\\u044c \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0435\\u0433\\u043e \\u0441\\u043f\\u0440\\u0430\\u0448\\u0438\\u0432\\u0430\\u0442\\u044c, \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0436\\u0438\\u0432\\u0435\\u0442 \\u0442\\u0432\\u043e\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430. \\u043e\\u043d \\u0438\\u0438 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438 \\u043f\\u043e\\u0445\\u0430\\u0442\\u044c \\u0432\\u043e\\u0448\\u043b\\u0438 \\u043e\\u043d\\u0438 \\u0432 \\u0431\\u0430\\u043d\\u044e\\u043b \\u0432\\u044b\\u0432\\u0435\\u0447\\u0438\\u0438 \\u043f\\u043e\\u0434 \\u043f\\u043e\\u043b\\u043a\\u0430 \\u043a\\u0440\\u0430\\u0441\\u0430\\u0432\\u0438\\u0446\\u0443 \\u2014 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0443, \\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f \\u0431\\u044b\\u043b\\u0430 \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u0442\\u0430. \\u043f\\u043e\\u0435\\u0445\\u0430\\u043b\\u0438 \\u043e\\u043d\\u0438 \\u0432 \\u0446\\u0435\\u0440\\u043a\\u043e\\u0432\\u044c \\u0432\\u0435\\u043d\\u0447\\u0430\\u0442\\u044c\\u0441\\u044f. \\u043e\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u0432\\u0430 \\u043a\\u0430\\u0433\\u043e \\u0446\\u0435\\u0440\\u043a\\u0432\\u0438, \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0435 \\u0438\\u0434\\u0435\\u0442 1 \\u0446\\u0435\\u0440\\u043a\\u043e\\u0432\\u044a. \\u043e\\u043d\\u0430 \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430: \\u043f\\u043e\\u0434\\u0438 \\u043a \\u043f\\u043e\\u043f\\u0443, \\u043f\\u0443\\u0441\\u043a\\u043e\\u0439 \\u043e\\u043a\\u0438 \\u043d\\u0438\\u043d\\u0443\\u0442 \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e \\u0440\\u0435\\u0431\\u0435\\u043d\\u043a\\u0430 \\u0432 \\u0433\\u043e\\u0440\\u044f\\u0447\\u0443\\u044e \\u043f\\u0435\\u0447\\u044c, \\u044d\\u0442\\u043e \\u0447\\u0435\\u0440\\u0442\\u0438 \\u0438\\u043c \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u043b\\u0438 \\u043d\\u0430 \\u043c\\u0435\\u0441\\u0442\\u043e \\u043c\\u0435\\u043d\\u044f, \\u0430 \\u043c\\u0435\\u043d\\u044f \\u0442\\u0443\\u0434\\u0430 \\u0432 \\u0431\\u0430\\u043d\\u044e \\u0441\\u043f\\u0435\\u0441\\u043b\\u0438 \\u0430 \\u044f \\u0443\\u0436\\u0435 \\u0442\\u0430\\u043c 10\\u0433\\u043e\\u0434 \\u0436\\u0438\\u043b\\u0430. \\u043f\\u043e\\u0441\\u043b\\u0443\\u0448\\u0430\\u043b\\u0441\\u044f \\u043f\\u043e\\u043f\\u0438 \\u0441\\u0436\\u043e\\u043a \\u0447\\u0435\\u0440\\u0442\\u0435\\u043d\\u0435\\u043d\\u043a\\u0430. \\u043e\\u043d\\u0438 \\u043e\\u0431\\u044b\\u043d\\u0430\\u043b\\u0438\\u0441\\u044c \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0432\\u043c\\u0435\\u0441\\u0442\\u0435 \\u043c\\u043d\\u0435 \\u043f\\u043e\\u0436\\u0438\\u0432\\u0430\\u0442\\u044c.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = \"atu_labels_json\"\n",
        "\n",
        "def parse_labels(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    s = str(x).strip()\n",
        "    if not s:\n",
        "        return []\n",
        "    try:\n",
        "        v = json.loads(s)\n",
        "        if isinstance(v, list):\n",
        "            return [str(t).strip() for t in v if str(t).strip()]\n",
        "\n",
        "        return [str(v).strip()]\n",
        "    except Exception:\n",
        "\n",
        "        return [t.strip() for t in s.split(\",\") if t.strip()]\n",
        "\n",
        "df[\"labels\"] = df[col].apply(parse_labels)\n",
        "\n",
        "unique_labels = sorted({lab for labs in df[\"labels\"] for lab in labs})\n",
        "print(\"Unique labels:\", len(unique_labels))\n",
        "print(\"Example:\", unique_labels[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40phv8G3ZNyy",
        "outputId": "c752f45f-dd53-4c1c-92f4-21217f75f4fd"
      },
      "id": "40phv8G3ZNyy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels: 37\n",
            "Example: ['1000', '1060', '1168', '1174', '300', '300A', '301', '302C*', '302С*', '307', '313', '325', '327A', '331', '402', '410', '425C', '470', '480A', '480D*']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = pd.Series([lab for labs in df[\"labels\"] for lab in labs]).value_counts()\n",
        "display(label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "siWCTWCSZ4j8",
        "outputId": "d5440e23-73ea-4c87-d1bb-de72edb7ed90"
      },
      "id": "siWCTWCSZ4j8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "707      6\n",
              "480D*    5\n",
              "530      3\n",
              "703*     3\n",
              "402      3\n",
              "552      3\n",
              "480A     3\n",
              "650A     3\n",
              "307      3\n",
              "301      2\n",
              "410      2\n",
              "550      2\n",
              "700      2\n",
              "300      2\n",
              "425C     2\n",
              "735A     1\n",
              "580      1\n",
              "849*     1\n",
              "1060     1\n",
              "302С*    1\n",
              "1000     1\n",
              "511      1\n",
              "470      1\n",
              "706      1\n",
              "556А*    1\n",
              "325      1\n",
              "530A     1\n",
              "709      1\n",
              "300A     1\n",
              "331      1\n",
              "1174     1\n",
              "1168     1\n",
              "313      1\n",
              "302C*    1\n",
              "554      1\n",
              "556F*    1\n",
              "327A     1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480D*</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703*</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480A</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650A</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425C</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735A</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849*</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1060</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302С*</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556А*</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530A</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300A</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302C*</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556F*</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327A</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DROP_COLS = [\n",
        "    \"rights_status\",\n",
        "    \"content_description\",\n",
        "    \"sampling_version\",\n",
        "    \"type_count\",\n",
        "    \"collection\",\n",
        "    \"volume_no\",\n",
        "    \"source_ref\",\n",
        "    \"atu_labels_json\",\n",
        "    \"txt_path\",\n",
        "    \"text_raw\",\n",
        "    \"set\"\n",
        "]\n",
        "\n",
        "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns]).copy()\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XXQtFVSz7LB3",
        "outputId": "1143d7ad-d56d-462a-9aba-f37e64c1fb15"
      },
      "id": "XXQtFVSz7LB3",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tale_id                                       summary_norm  \\\n",
              "0    era_vene_1_503_1                                   царевна-лягушка.   \n",
              "1    era_vene_1_515_1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2  era_vene_12_105_22                                        снегурочка.   \n",
              "3  era_vene_12_137_98                                        иван-дурак.   \n",
              "4   era_vene_12_189_1                                         два брата.   \n",
              "\n",
              "                                           text_norm  labels  \n",
              "0  тили были царь с царицей у не было три сына. ц...   [402]  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...   [410]  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  [703*]  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...   [530]  \n",
              "4  жили — брели два брата. и посла смерти отца об...  [735A]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-181742a1-21ab-44a3-ac31-ee3b14998729\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "      <td>[402]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "      <td>[410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "      <td>[703*]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "      <td>[530]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "      <td>[735A]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-181742a1-21ab-44a3-ac31-ee3b14998729')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-181742a1-21ab-44a3-ac31-ee3b14998729 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-181742a1-21ab-44a3-ac31-ee3b14998729');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47a5df0d-c894-4485-99dc-7e8533a2a504\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47a5df0d-c894-4485-99dc-7e8533a2a504')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47a5df0d-c894-4485-99dc-7e8533a2a504 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"tale_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"era_vene_13_15_1\",\n          \"tru_vkk_5_58_29\",\n          \"era_vene_2_748_27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"\\u0441\\u043a\\u0430\\u0437\\u043a\\u0430 \\u043c\\u043e\\u0440\\u043e\\u0437\\u043a\\u043e.\",\n          \"\\u0441\\u043a\\u0430\\u0437\\u043a\\u0430 \\u043e\\u0431 \\u0430\\u043b\\u0435\\u043d\\u044c\\u043a\\u043e\\u043c \\u0446\\u0432\\u0435\\u0442\\u043e\\u0447\\u043a\\u0435.\",\n          \"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437 \\u043f\\u0440\\u043e \\u0447\\u0435\\u0440\\u0442\\u0435\\u0439. \\u0442\\u0440\\u0438 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\\u0430 \\u043f\\u0440\\u043e\\u0441\\u044f\\u0442\\u0441\\u044f \\u043d\\u043e\\u0447\\u0435\\u0432\\u0430\\u0442\\u044c \\u043a \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0435-\\u0447\\u0435\\u0440\\u0442\\u0438\\u0445\\u0435. \\u043e\\u043d\\u0430 \\u0443\\u043a\\u043b\\u0430\\u0434\\u044b\\u0432\\u0430\\u0435\\u0442 \\u0438\\u0445 \\u0432 \\u043a\\u043e\\u043d\\u044e\\u0448\\u043d\\u0435, \\u0443\\u0442\\u0440\\u043e\\u043c \\u043d\\u0435 \\u0432\\u044b\\u043f\\u0443\\u0441\\u043a\\u0430\\u0435\\u0442. \\u0434\\u0432\\u0430 \\u0432\\u044b\\u0441\\u043a\\u043e\\u0447\\u0438\\u043b\\u0438 \\u0438 \\u0443\\u0431\\u0435\\u0436\\u0430\\u043b\\u0438, \\u0442\\u0440\\u0435\\u0442\\u0438\\u0439 \\u043e\\u0441\\u0442\\u0430\\u043b\\u0441\\u044f. \\u043e\\u0442\\u043c\\u0430\\u043b\\u0438\\u0432\\u0430\\u0435\\u0442 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0443 \\u0442\\u0440\\u0438 \\u043d\\u043e\\u0447\\u0438, \\u043e\\u0442 \\u0447\\u0435\\u0440\\u0442\\u0435\\u0439 \\u0437\\u0430\\u0449\\u0438\\u0449\\u0430\\u0435\\u0442 \\u043a\\u0440\\u0443\\u0433. \\u043d\\u0430 \\u0442\\u0440\\u0435\\u0442\\u044c\\u044e \\u043d\\u043e\\u0447\\u044c \\u043f\\u0440\\u0438\\u0448\\u0435\\u043b \\u0441\\u0430\\u043c \\u0447\\u0435\\u0440\\u0442, \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a \\u043e\\u0433\\u043b\\u044f\\u043d\\u0443\\u043b\\u0441\\u044f \\u0432 \\u0435\\u0433\\u043e \\u0433\\u043b\\u0430\\u0437\\u0430, \\u0435\\u0433\\u043e \\u0441\\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0438 \\u0438 \\u0440\\u0430\\u0441\\u0442\\u0435\\u0440\\u0437\\u0430\\u043b\\u0438.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"1-2 \\u0430\\u0432\\u0434\\u043e\\u0442\\u044c\\u044f \\u0435\\u0440\\u0448\\u043e\\u0432\\u0430 \\u2014 76 \\u043b\\u0435\\u0442; \\u0434\\u0435\\u0440\\u0435\\u0432\\u044c\\u044f \\u0441\\u0442\\u0430\\u0440\\u044b\\u0439 \\u0438\\u0437\\u0431\\u043e\\u0440\\u0435\\u043a. \\u0432\\u0441\\u044e \\u0436\\u0438\\u0437\\u043d\\u044c \\u043f\\u0440\\u043e\\u0436\\u0438\\u043b\\u0430 \\u0432 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u0434\\u0435\\u0440\\u0435\\u0432\\u043d\\u0435. \\u043f\\u043e\\u0441\\u043b\\u0435 \\u0434\\u043e\\u043b\\u0433\\u043e\\u0439 \\u0438 \\u0443\\u043f\\u043e\\u0440\\u043d\\u043e\\u0439 \\u043f\\u0440\\u043e\\u0441\\u044c\\u0431\\u044b \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430. \\u043d\\u0435\\u0433\\u0440\\u0430\\u043c\\u043e\\u0442\\u043d\\u0430\\u044f 1. \\u043d\\u0435\\u0438\\u043b \\u0434\\u0435\\u0446 \\u0441 \\u0431\\u0430\\u0431\\u043e\\u0439, \\u0431\\u044b\\u043b\\u0430 \\u0432 \\u0434\\u0435\\u0434\\u0430 \\u0430\\u043d\\u043d\\u0430\\u044f \\u0434\\u0430\\u0446\\u043a\\u0430, \\u0430 \\u0432 \\u0431\\u0430\\u0431\\u044b \\u0434\\u0432\\u0435 \\u0434\\u0430\\u0446\\u043a\\u0438. \\u0434\\u0435\\u0434\\u043e\\u0432\\u0430 \\u0434\\u0430\\u0446\\u043a\\u0430 \\u0431\\u044b\\u043b\\u0430 \\u0434\\u044e\\u043e\\u0436\\u0430 \\u043a\\u0440\\u0430\\u0441\\u0438\\u0432\\u0430\\u044f \\u0437\\u0430 \\u0445\\u043e\\u0440\\u043e\\u0448\\u0430\\u044f. \\u0430 \\u043c\\u0430\\u0434\\u0438\\u043a\\u0430 \\u0431\\u044b\\u043b\\u0430 \\u043b\\u0438\\u043a\\u043e\\u044f \\u043d\\u0438\\u0437\\u043b\\u044e\\u0431\\u0438\\u043b\\u0430 \\u0434\\u0430\\u0434\\u044b\\u0432\\u0443 \\u0434\\u0430\\u0446\\u043a\\u0443. \\u0437\\u0430\\u0441\\u0442\\u0430\\u043b\\u0441\\u044f \\u044f\\u043b\\u0430 \\u0434\\u0435\\u0434\\u0430 \\u0432\\u0435\\u0441\\u0442\\u0438\\u0435 \\u0434\\u0430\\u0446\\u043a\\u0443 \\u044f\\u0432\\u043e\\u043d\\u044b\\u0432\\u0443 6 \\u043b\\u0435\\u0435 \\u0434\\u0430 \\u0438 \\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u044c \\u0442\\u0430\\u043c\\u0430. \\u0437\\u0430\\u043f\\u043b\\u0430\\u043d\\u044b\\u0435 \\u0434\\u0435\\u0434, \\u043b\\u044e\\u0431\\u0438\\u044f \\u0435\\u043d \\u0441\\u0432\\u043e\\u044e \\u0434\\u0430\\u0443\\u043a\\u0443, \\u043d\\u0438 \\u0445\\u0430\\u0437\\u0435\\u0435 \\u0443\\u0442\\u0432\\u0430\\u0437\\u0438\\u0442\\u044c \\u0435\\u043d\\u0443 \\u0430 \\u043c\\u0430\\u0447\\u0438\\u0441\\u0430 \\u0432\\u0441\\u0435 \\u043f\\u0440\\u0438\\u0441\\u0442\\u0430\\u0435 \\u0443\\u0442\\u0432\\u0435\\u0440\\u0438 \\u0443\\u0442\\u0432\\u044f\\u0437\\u0438. \\u0434\\u0435\\u043b\\u043e \\u0431\\u044b\\u043b\\u043e \\u0437\\u0438\\u043c\\u043e\\u0439, \\u0434\\u0433\\u043e\\u043d\\u0441\\u0430 \\u0445\\u043e\\u043b\\u044b\\u043d\\u043d\\u043e \\u0431\\u044b\\u043b\\u043e \\u043d\\u0430 \\u0443\\u043b\\u0438\\u0446\\u044b. \\u0432\\u043d\\u0435\\u0435 \\u0434\\u0435\\u0434 \\u0441\\u0432\\u043e\\u044e \\u0434\\u0430\\u0446\\u043a\\u0443, \\u043d\\u044b\\u0441\\u0430\\u0434\\u0438\\u043b \\u043d\\u0430 \\u0434\\u0440\\u043e\\u0432\\u043d\\u0438 \\u0438 \\u043d\\u0430\\u0432\\u0435\\u0437 \\u0432\\u043b\\u0435\\u0441. \\u043f\\u044b\\u0441\\u0430\\u0434\\u0438\\u043b \\u044f\\u043c\\u0443 \\u0432 \\u0435\\u043b\\u0435\\u0446 \\u043d\\u043e \\u0441\\u043d\\u0435\\u0433, \\u043f\\u043e\\u0437\\u0432\\u0435\\u043b \\u0441\\u0438 \\u0430\\u0433\\u043e\\u043d\\u0438\\u0447\\u0438\\u043a; \\u0432\\u0430\\u0440\\u0438 \\u0434\\u0435\\u0432\\u044b\\u043d\\u043e\\u043a\\u0430 \\u043a\\u0430\\u0448\\u043a\\u0443 \\u0437\\u0430\\u043c\\u0430\\u043c\\u0441\\u044f \\u0431\\u043e\\u0433\\u0443, \\u0435\\u043d \\u0441\\u043d\\u0430\\u0441\\u0435 \\u0442\\u044f\\u0431\\u044f. \\u043b\\u0441\\u0442\\u0430\\u043b\\u0430\\u0441\\u044f \\u0434\\u0435\\u0444\\u043a\\u0430 \\u0430\\u043d\\u043d\\u0430\\u044f, \\u0441\\u0442\\u0430\\u043b\\u0430 \\u0432\\u0430\\u0440\\u0438\\u0442\\u044c \\u043a\\u0430\\u0448\\u043a\\u0443 \\u0438 \\u043c\\u0430\\u043c\\u0441\\u0442\\u0432\\u044b \\u0447\\u0438\\u0442\\u0442 \\u0434\\u0440\\u0443\\u0433 \\u0441\\u043a\\u043e\\u043a \\u043d\\u0430\\u0441\\u043a\\u043e\\u043a \\u043d\\u0430 \\u0432\\u0435\\u0442\\u044b\\u0446\\u043a\\u0430\\u043c \\u043f\\u0440\\u0438\\u0441\\u043a\\u0430\\u043a\\u0430\\u044f \\u0434\\u0435\\u0446-\\u043c\\u0430\\u0440\\u043e\\u0437 \\u0438 \\u0433\\u044b\\u0432\\u0430\\u0440\\u0438\\u0442\\u044c \\u0435\\u0439: \\u201c\\u00ab\\u0434\\u0435\\u0432\\u044b\\u043d\\u044c\\u043a\\u0430, \\u043c\\u0430\\u0440\\u043e\\u0437, \\u0430 \\u0435\\u043d\\u0430 \\u044f\\u043b\\u0438 \\u0442\\u0432\\u0430\\u044f: \\u0433\\u0430\\u0441\\u043f\\u043e\\u0434\\u044c \\u043f\\u0438\\u0435\\u0431\\u044f \\u0441\\u0433\\u043e\\u0434\\u044b \\u043f\\u0440\\u0438 \\u043d\\u0435\\u0441. \\u0432\\u0438\\u0434\\u044f \\u0434\\u0443 \\u043c\\u0430\\u0440\\u043e\\u0433, \\u0448\\u0441\\u0442\\u043e \\u0434\\u0435\\u0432\\u043a\\u0430 \\u0445\\u043e\\u0440\\u043e\\u0448\\u0430, \\u043a\\u0438\\u043d\\u0443\\u043b \\u0435\\u0439 \\u0432\\u0430\\u043b\\u0438\\u043d\\u0446\\u044b. \\u043d\\u0430\\u0434\\u0435\\u043b\\u0430 \\u043e\\u043d\\u0430 \\u0432\\u0430\\u043b\\u0438\\u043d\\u044b\\u0446\\u043a\\u0438 \\u0438 \\u0430\\u043f\\u043e\\u0442\\u044c \\u0441\\u0438\\u0434\\u0438\\u0442\\u044c \\u043a\\u0443\\u043d \\u0430\\u0433\\u043d\\u044f \\u0433\\u0440\\u0435\\u0439\\u0446\\u0430. \\u0432 \\u0434\\u0440\\u0443\\u0433\\u043e-\\u0440\\u044f\\u0434 \\u0434\\u0435\\u0434 \\u043c\\u0430\\u0440\\u043e, \\u0441\\u043a\\u043e\\u043d \\u043d\\u043e\\u0441\\u043f\\u043e\\u043a \\u043d\\u0435 \\u0435\\u043b\\u043e\\u0434\\u043a\\u0430\\u043c \\u0438 \\u0430\\u043d\\u043e\\u0448\\u044c \\u0435\\u0439; \\u0434\\u0435\\u0432\\u0432\\u0435\\u043d\\u044c\\u043a\\u0430 \\u043c\\u0430\\u0440\\u043e\\u0437\\u00bb, \\u0435\\u043d\\u0430 \\u044f\\u043c\\u0443: \\u201c\\u0433\\u0430\\u0441\\u043f\\u043e\\u0434\\u044c \\u0435\\u0431\\u044f \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441. \\u0438 \\u0430\\u0442\\u044f\\u0442\\u044c \\u0448\\u0432\\u044b\\u0440\\u044c\\u043a \\u0435\\u0439 \\u0442\\u0435\\u043f\\u043b\\u044b\\u0439 \\u043f\\u043b\\u0430\\u0442\\u043e\\u043a. \\u0434\\u0435\\u0432\\u043a\\u0430 \\u0442\\u043e\\u043f\\u0435\\u0440\\u044c \\u0430\\u043c\\u0438\\u0448\\u0435 \\u043d\\u0443\\u0448\\u0438\\u0438 \\u0431\\u043e\\u0433\\u0443 \\u043c\\u043e\\u043b\\u0438\\u0442\\u0446\\u0430 \\u0437\\u043d\\u0430\\u044f, \\u0448\\u0442\\u043e \\u0441\\u043d\\u0430\\u0441\\u0435 \\u0435\\u043d \\u0435\\u043d\\u0443. \\u0438 \\u0432 \\u0442\\u0440\\u0435\\u0442\\u0438\\u0438 \\u0440\\u0430\\u0437 \\u043f\\u0440\\u0438\\u0441\\u043a\\u0430\\u043d\\u0430\\u043b\\u0434\\u0430 \\u043c\\u0430\\u0440\\u043e, \\u0438 \\u043a\\u0440\\u044b\\u043b\\u044b\\u0442\\u044c \\u0435\\u0439 \\u201c\\u043e\\u043d, \\u0434\\u0435\\u0432\\u044b\\u043d\\u043e\\u043a\\u0430 \\u043c\\u0430\\u0440\\u043e\\u0437, \\u043e\\u043d\\u0430 \\u0435\\u043c\\u0443 \\u0432\\u0430\\u0442\\u044c\\u0435\\u0442: \\u0437\\u0430\\u0441\\u043f\\u043e\\u0434 \\u043f\\u0442\\u0435\\u0431\\u044f \\u043f\\u0440\\u0438\\u043d\\u0435\\u0435: \\u0438 \\u0434\\u0440\\u0443\\u0433 \\u0437\\u0430 \\u0431\\u0440\\u044f\\u0446\\u0430\\u043b\\u0438 \\u0437\\u0432\\u0430\\u043d\\u0446\\u044b \\u0438 \\u043d\\u0430\\u0434\\u044a\\u0435\\u0441\\u0430\\u043b\\u0438 \\u043f\\u043e\\u0433\\u0438, \\u0437\\u0430\\u043f\\u0440\\u044f\\u0436\\u043e\\u043d\\u044b \\u0432 \\u0434\\u0430\\u0440\\u044f\\u0433\\u0435 \\u0440\\u043e\\u0432\\u043d\\u0438, \\u0430 \\u043f\\u043e \\u0434\\u0440\\u0430\\u0432\\u043d\\u0435\\u043a \\u0442\\u043e \\u043b\\u0443\\u0448\\u0438\\u0442\\u044b \\u043b\\u0430\\u0440\\u0435\\u0443 \\u0441\\u0442\\u0430\\u0438\\u0442\\u044c \\u0437 \\u0442\\u043e\\u043c \\u043a\\u043e\\u0432\\u0430\\u043d, \\u0430 \\u0432 \\u043b\\u0430\\u0440\\u0446\\u044b \\u0432\\u0441\\u0435\\u0441\\u043d\\u043e\\u0432\\u043e \\u0437\\u0430\\u0431\\u0440\\u0430 \\u0442\\u044b\\u043f\\u043e\\u043b\\u043e\\u0436\\u0438\\u043d. \\u0441\\u0430\\u0434\\u0438\\u0441\\u044c \\u0434\\u0435\\u0432\\u044b\\u043d\\u044c\\u043a\\u0430 \\u0432 \\u0434\\u0440\\u043e\\u0432\\u043d\\u0438 \\u0438 \\u043f\\u044b\\u044f\\u0436\\u043e\\u043c \\u0441 \\u0431\\u043e\\u0433\\u043e\\u043c. \\u0435 \\u0434\\u043e\\u043c\\u0430, \\u0432 \\u043c\\u0430\\u0447\\u0438\\u0441\\u0438 \\u0431\\u044b\\u043b\\u0430 \\u0441\\u0430\\u0431\\u0430\\u0447\\u0435\\u043d\\u043d\\u0438 \\u043f\\u0435\\u0449\\u0430\\u043a\\u0430 \\u0438 \\u0432\\u0441\\u0435 \\u0437\\u0435\\u0442\\u0430\\u044f \\u0436\\u0443\\u0434\\u043a\\u0430. \\u0430\\u044f \\u0438 \\u043f\\u0440\\u0438\\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0432\\u0430\\u044f \\u0434\\u0435\\u0434\\u044b\\u0432\\u0430 \\u0437\\u0430\\u0446\\u043a\\u0430 \\u0435\\u0434\\u044f \\u0434\\u0430\\u043c\\u043e\\u0439 \\u0438 \\u0434\\u0435\\u043b\\u044c\\u043d\\u044b\\u0439 \\u043b\\u0430\\u0442\\u0435\\u0439 \\u0434\\u043e\\u0431\\u0440\\u0430 \\u0432\\u0435\\u0437\\u0435, \\u0430 \\u0431\\u0430\\u0431\\u0438\\u043d\\u0430 \\u0434\\u0430\\u0446\\u043a\\u0430 \\u043d\\u0435 \\u0441\\u0442\\u043e\\u044f \\u043f\\u0438\\u0442\\u0430\\u0446\\u043a\\u0430: \\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0430 \\u043c\\u0430\\u0446\\u044b\\u0445\\u0430 \\u043f\\u0430\\u043b\\u043a\\u0443 \\u0438 \\u043f\\u0440\\u043e\\u0441\\u0438\\u043b\\u0430 \\u0432 \\u0436\\u0443\\u0446\\u043a\\u0443, \\u0442\\u0430\\u044f\\u0438 \\u043c\\u043e\\u043b\\u0446\\u0430\\u043b\\u0430. \\u0443\\u0441\\u043b\\u044b\\u0445\\u0430\\u043b\\u0438 \\u043d\\u0435 \\u0434\\u0432\\u0430\\u0440\\u0438 \\u0431\\u0443\\u0431\\u044f\\u043d\\u0446\\u044b \\u0437\\u0432\\u043e\\u043d\\u044e\\u0442 \\u0438 \\u0443\\u0432\\u0438\\u0434\\u043b\\u0438 \\u0435\\u0434\\u044f \\u0434\\u0435\\u0434\\u044b\\u0432\\u0430 \\u0434\\u0430\\u0446\\u043a\\u0430, \\u0430 \\u043d\\u0430 \\u0434\\u0440\\u0430\\u043d\\u0435\\u0445 \\u0431\\u0430\\u043b\\u044c\\u043c\\u0443\\u0448\\u0448\\u0438\\u0439 \\u043b\\u0430\\u0440\\u0435\\u0446 \\u0441\\u0434\\u0430\\u0431\\u0440\\u043e\\u043c \\u043a\\u0430\\u043a \\u0437\\u044b\\u0433\\u043b\\u044f\\u0434\\u0435\\u043b\\u0438 \\u0437\\u0430\\u0432\\u0438\\u0434\\u0443\\u0448\\u043d\\u0430\\u044f \\u043c\\u043e\\u0434\\u044b\\u0445\\u0430 \\u0447\\u0442\\u043e \\u0438 \\u043a\\u0440\\u044b\\u0447\\u044b\\u0442\\u044c \\u0434\\u0435 \\u0434\\u0443 \\u0432\\u0435\\u0442\\u0438 \\u0438 \\u043c\\u0430\\u044e \\u0434\\u0430\\u0446\\u043a\\u0443 \\u0432\\u043b\\u0435\\u0435 \\u0438 \\u0435\\u043d\\u0430 \\u0434\\u0430\\u0431\\u0440\\u0430 \\u043f\\u0440\\u0438\\u0432\\u044f\\u0442\\u0435\\u00bb. \\u043d\\u0430\\u0434 \\u043e\\u0439 \\u0434\\u0435\\u043d\\u044c, \\u0447\\u0443\\u0442\\u044c \\u0441\\u0432\\u0435\\u0442\\u043e\\u043a \\u043f\\u044b\\u0441\\u0430\\u0434\\u0438\\u0430 \\u043e \\u043c\\u0430\\u0446\\u044b\\u043a\\u0438\\u043d\\u0443 \\u0434\\u043e\\u043b\\u043a\\u0443 \\u0438 \\u0430\\u0442\\u0432\\u0435\\u0440 \\u0432 \\u043b\\u0435\\u0435. \\u0440\\u0430\\u0437\\u0432\\u0435\\u043b \\u0435\\u0439 \\u0430\\u0433\\u043e\\u043d\\u0438\\u0446\\u044b\\u043a \\u0438 \\u0446\\u0435\\u0445\\u0430\\u043b \\u0441\\u043b\\u044b\\u0448\\u0430 \\u0434\\u0430\\u0446\\u043a\\u0430 \\u044d\\u0442\\u043e-\\u0442\\u043e \\u0441\\u043a\\u0430\\u0446\\u043a\\u0430 \\u043d\\u043e \\u0432\\u0435\\u0448\\u043a\\u0438 \\u0438 \\u043f\\u0440\\u044f\\u043b\\u043e \\u043a \\u0435 \\u0438 \\u0433\\u044b\\u0432\\u0430\\u0440\\u0438\\u0442\\u044c: \\u0430\\u0439, \\u0434\\u0435\\u0432\\u044b\\u043d\\u044c\\u043a\\u0430 \\u043c\\u0430\\u0440\\u043e\\u0437: \\u00ab\\u0430 \\u0435\\u043d, \\u0435\\u043c\\u0443: \\u201c\\u043b\\u0435\\u0448\\u0456\\u0438 \\u043f\\u043b\\u0435\\u0431\\u044f \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441. \\u0440\\u044b\\u0441\\u0441\\u044f\\u0440\\u0434\\u0438\\u043b\\u0441\\u044f \\u043d\\u043e \\u0435\\u043d\\u0443 \\u0434\\u0435\\u0434 \\u043c\\u0430\\u0440\\u043e\\u0433, \\u0438\\u044b\\u0447\\u0430\\u0441\\u043d\\u0438 \\u0435\\u0439 \\u0430\\u0433\\u043e\\u043d\\u0438\\u0446\\u044b\\u043a \\u0438 \\u0434\\u044b\\u043c\\u0430\\u0440\\u043e\\u0437\\u0438\\u044f \\u0435\\u043d\\u0443 \\u043f\\u044b\\u0441\\u044b\\u043b\\u0430\\u044f \\u043c\\u0430\\u0446\\u044b\\u0445\\u0430 \\u0434\\u0435\\u0434\\u0430 \\u0432 \\u043b\\u0435 \\u043f\\u0440\\u0438\\u0432\\u0435\\u0441\\u0442\\u0438 \\u0441\\u0432\\u043e\\u044e \\u0434\\u0430\\u043b\\u043a\\u0443 \\u0441 \\u0434\\u0430\\u0431\\u0440\\u043e\\u043c \\u0434\\u0430\\u043c\\u043e\\u0439. \\u0438 \\u0436\\u0443\\u0446\\u043a\\u0430 \\u0430\\u0442\\u0435\\u0442\\u044c \\u043b\\u0430\\u044f \\u0438 \\u043f\\u0440\\u0438\\u0433\\u043e\\u0432\\u0430\\u0440\\u0438\\u0432\\u0430\\u044f: m\\u0438\\u0441\\u044c, \\u043f\\u0438\\u0441\\u044c \\u0430 \\u043c\\u0430\\u0446\\u044b\\u043a\\u0438\\u043d\\u043e\\u0439 \\u0434\\u0430\\u0446\\u043a\\u0438 \\u0430\\u043d\\u043d\\u044b\\u0435 \\u043a\\u043e\\u0441\\u0442\\u043e\\u044f\\u043a\\u0438 \\u0432\\u0435\\u0437\\u0443\\u0448\\u044c\\u00bb. \\u0438 \\u0432\\u0431\\u044b\\u043b\\u044c, \\u0442\\u0430\\u043a, \\u043f\\u0440\\u0438\\u0432\\u0435\\u0437 \\u0434\\u0435\\u0430\\u043d\\u043d\\u044b\\u0435 \\u043a\\u043e\\u0441\\u0442\\u043e\\u0434\\u043a\\u0438 \\u0442 \\u043c\\u0430\\u0446\\u044b\\u0435\\u043d\\u043e\\u0439 \\u0434\\u0430\\u0446\\u043a\\u0438.\",\n          \"\\u0436\\u0438\\u043d\\u0438-\\u0431\\u044b\\u043a\\u0438 \\u0434\\u0435\\u0434 \\u0438 \\u0437\\u0430\\u0434\\u0430 \\u0443 \\u043d\\u0438\\u0445 \\u0434\\u044b \\u0434\\u043e\\u0433\\u043d\\u0430 \\u0434\\u0435\\u0434\\u043e\\u0432\\u0430 \\u0434\\u043e \\u0438 \\u0431\\u0430\\u0431\\u0438\\u043d\\u0430 \\u0434\\u043e\\u0433. \\u0431\\u0430\\u0434\\u0430 \\u043e\\u0447\\u0435\\u043d\\u044c \\u043d\\u0435\\u043f\\u0430 \\u0432\\u0438\\u0434\\u0435\\u043a\\u0430 \\u0434\\u0435\\u0434\\u0430\\u0432\\u0443 \\u0434\\u043e\\u0447\\u043d\\u0443 \\u0438 \\u0437\\u0430\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u043a\\u0430 \\u043c\\u043d\\u043e\\u0433\\u0430 \\u0440\\u0430\\u0434\\u043e\\u0442\\u0430\\u0442\\u044c, \\u0430 \\u0441\\u0432\\u0430\\u044e \\u0434\\u043e\\u0433 \\u0447\\u0430\\u0441\\u043a\\u0430\\u043a\\u0430 \\u0438 \\u0433\\u0430\\u043b\\u0443\\u0431\\u0438\\u043b\\u0430. \\u04320 \\u0438 \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438 \\u0440\\u0430\\u0437 \\u0431\\u0430\\u0431\\u0430 \\u201c\\u0437\\u044b\\u0437\\u0438 \\u0441\\u0432\\u0430\\u044e \\u0434\\u043e\\u0433 \\u043d\\u0430 \\u043c\\u0430\\u0440\\u043e\\u0437, \\u043d\\u043e \\u0434 \\u044f \\u044f\\u0435 \\u043d\\u0435 \\u0432\\u0438\\u0434\\u0435\\u043b\\u0430. \\u0437\\u0438\\u0447\\u0435\\u0433\\u043e \\u0434\\u0435\\u043b\\u0430\\u0442\\u044c \\u0430\\u0443, \\u0437\\u0430\\u043f\\u0440\\u044f\\u0442 \\u043d\\u0430\\u0448\\u0430\\u0434\\u044f 6 \\u0441\\u0430\\u043d\\u0438 \\u0438 \\u043f\\u0430\\u0432\\u0441\\u0435 \\u044f\\u0441. \\u043b\\u0430\\u043d \\u0438 \\u0440\\u0430\\u0441\\u0438\\u0443\\u0433\\u0438\\u043b \\u043f\\u0430\\u0434 \\u0434\\u0435\\u0440\\u043d\\u043e\\u0439. \\u043d\\u043e\\u0447\\u044c\\u044e \\u043f\\u0440\\u0438\\u0445\\u043e\\u0434\\u0438\\u0442 \\u043c\\u0430\\u0440\\u043e \\u0438 \\u0441\\u0443\\u0433\\u0438\\u0439 \\u043f\\u0430\\u043b\\u0438\\u0446\\u0435\\u0439 \\u0440\\u0430 \\u0434\\u0435\\u0440\\u0435\\u0432\\u0443 \\u0438 \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0438 \\u044f \\u043f\\u0431\\u044f \\u0437\\u0430\\u043c\\u0430\\u0440\\u043e\\u0436\\u0443 \\u0438 \\u0434\\u0435\\u0432\\u043e\\u0433\\u043d\\u0430 \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0439 \\u043c\\u0430\\u0440\\u043e\\u0433, \\u043d\\u0430\\u0440\\u043e\\u0437, \\u0442\\u0435\\u0434\\u044f \\u0431\\u043e\\u0445 \\u043f\\u0440\\u0438\\u043d\\u0438\\u0435, \\u043d\\u0435\\u043c\\u0430\\u0440\\u043e\\u0441. \\u043c\\u0435\\u043d\\u044f. \\u043a\\u0430\\u0436\\u0430\\u043b\\u043e\\u044f \\u043c\\u0430\\u0440\\u043e\\u044a \\u0434\\u0435\\u0432\\u0430\\u0447\\u043a\\u0443, \\u0434\\u0430\\u043b \\u0435\\u0439 \\u043c\\u0443\\u0434\\u0443 \\u0438 \\u0432\\u0430\\u043b\\u0435\\u043d\\u043a\\u0438. \\u043f\\u0440\\u0438\\u0448\\u0435\\u043b \\u043d\\u0430\\u0440\\u043e\\u0437 \\u0432\\u0442\\u0430\\u0440\\u0430\\u0439 \\u0440\\u0430\\u0437 \\u0438 \\u0434\\u0435\\u0432\\u0430\\u0447\\u043d\\u0430 \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442: \\u201c\\u043c\\u0430\\u0440\\u043e\\u0437, \\u043d\\u0430\\u0440\\u043e\\u0437, \\u0442\\u0435\\u0431\\u044f \\u0434\\u043e\\u0445 \\u043f\\u0440\\u0438\\u043d\\u0435, \\u043d\\u0430 \\u043d\\u0430\\u0440\\u043e\\u0441\\u044c \\u043c\\u0435\\u043d\\u044f. \\u0438 \\u043f\\u0430\\u0436\\u0430\\u043b\\u0435\\u043b \\u043c\\u0430\\u0440\\u043e\\u0437 \\u044f\\u0435. \\u043d\\u0430 \\u0442\\u0440\\u0435\\u0442\\u044c\\u044e \\u043d\\u043e\\u0433 \\u0430\\u043f\\u044f\\u0442\\u044c \\u043d\\u0430\\u0440\\u043e\\u0437 \\u043f\\u0440\\u0438\\u043d\\u0438\\u0445. \\u043d\\u0438 \\u043d\\u0430\\u0440\\u043e\\u0437\\u0438\\u0435 \\u0434\\u0435\\u0432\\u043e\\u0447\\u043d\\u0443 \\u0430 \\u0441\\u0443\\u043d\\u0434\\u0443\\u043a \\u043f\\u043e\\u043b\\u043d\\u044b\\u0439 \\u0441\\u044f\\u043a\\u0440\\u043e\\u0432\\u0438\\u0438\\u0437 \\u044f\\u0439 \\u043f\\u0440\\u0438\\u043d\\u0438\\u0435. \\u0438 \\u0434\\u0430 \\u043e\\u043d \\u043e\\u0440\\u043e\\u043d\\u0438\\u044f\\u0434\\u0430 \\u0441\\u0432\\u0430\\u0441\\u043a \\u0434\\u043e\\u0447\\u043d\\u0443. \\u0445\\u0430\\u043d\\u0430\\u043d\\u0438\\u0438 \\u043e\\u043d \\u043d\\u0435 \\u0432\\u044b\\u0442\\u0435\\u0440\\u0442 \\u0438 \\u0431\\u0430\\u0441\\u0445\\u0430\\u043b \\u043d\\u0430 \\u0442\\u043e \\u0436\\u0435 \\u043d\\u0435\\u0441\\u0442\\u0430, \\u043a\\u0443\\u0434\\u0430 \\u0430\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b \\u0434\\u043e\\u0433. \\u0438 \\u0432\\u0438\\u0434\\u0435\\u0439 \\u0441\\u0438\\u0434\\u0438\\u0442 \\u0434\\u043e\\u0433 \\u0443 \\u0441\\u0443\\u043d\\u0434\\u0443\\u043a\\u0430 \\u0438 \\u043f\\u0435\\u0436\\u0434\\u0438 \\u0440\\u0430\\u0435\\u0442 \\u0434\\u0440\\u0430\\u0445\\u0430 \\u0435\\u043d\\u0438\\u043d\\u043e\\u0441\\u0442\\u044c \\u0438 \\u0437\\u043e\\u043b\\u043e\\u043f\\u0430, \\u00ab\\u0438 \\u0430\\u0442\\u043a\\u043e\\u043b\\u044c \\u043f\\u043e\\u0435 \\u0432\\u0441\\u0435 \\u0442\\u043e \\u044f\\u0442\\u0435\\u0446 \\u0441\\u043f\\u0440\\u0430\\u0441\\u0438\\u043b. \\u201c\\u0430 \\u043c\\u043d\\u0435 \\u043e\\u043e\\u0445 \\u043f\\u0440\\u0438\\u0441\\u043a\\u0430\\u043b. \\u0432\\u0437\\u0434\\u0443\\u043c\\u0430\\u043b \\u0434\\u0434 \\u201c\\u0442\\u044f\\u0440\\u0435\\u0440\\u044c \\u0442\\u0430 \\u0431\\u043e\\u0434\\u0430 \\u0431\\u0443\\u0434\\u0438\\u0442 \\u044f\\u044e \\u0434\\u0430 \\u0432\\u043e\\u043b\\u044c\\u043d\\u0430. \\u043f\\u0430\\u0432\\u044f\\u0437\\u0443 \\u044f \\u0434\\u0430\\u043c\\u043e\\u0439. \\u0443\\u043d\\u0430\\u044f\\u2014 \\u0441\\u0434\\u0435\\u043b\\u0430\\u044f. \\u0431\\u0430\\u0434\\u0430 \\u0434\\u043e\\u043c\\u0430 \\u0443\\u0437\\u043d\\u0430\\u043b\\u0430, \\u043a\\u0430\\u043a \\u0441\\u043f\\u0430\\u0435\\u043b\\u0430\\u0441\\u044c \\u0434\\u0435\\u0434\\u043e\\u0432\\u0430 \\u0434\\u043e\\u0433 \\u0438 6\\u0441\\u0435 \\u043d\\u0442\\u043e \\u0441 \\u043d\\u043e\\u0439 \\u0431\\u044b\\u043b\\u0430. \\u201c\\u0445\\u0430\\u0440\\u0430\\u0448\\u0430 \\u0431\\u044b \\u0438 \\u043c\\u043e\\u0435\\u0439 \\u0434\\u043e\\u0433\\u043d\\u0435 \\u0440\\u0430\\u0434\\u0430\\u0445\\u0430\\u0442\\u0438\\u044c. \\u043f\\u0430\\u0434\\u0443\\u043c\\u0430\\u043b\\u0430 \\u0434\\u0430\\u0434\\u0430 \\u0438 \\u043d\\u044f \\u0441\\u043b\\u044b\\u0448\\u0438\\u043b\\u0430 \\u0434\\u0435\\u0434\\u0430\\u0431\\u0430 \\u0434\\u043e\\u0433 \\u0431\\u043e\\u043b\\u044c\\u0448\\u0435 \\u0433\\u0440\\u0443\\u0431\\u0435\\u0445 \\u0435\\u0433\\u043e\\u0432 \\u0438\\u043e \\u043f\\u0440\\u0438\\u043a\\u0430\\u043a. \\u0436\\u0438\\u043d\\u0430 \\u0430\\u043d\\u0430 \\u0441\\u043a\\u043e\\u0432\\u043d\\u043e \\u0442\\u0438\\u0438\\u0447\\u043a\\u0430 \\u043d\\u0430 \\u0431\\u043e\\u043d\\u0435. \\u0438 \\u043f\\u0440\\u0438\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430 \\u0434\\u0430\\u0442\\u0430 \\u0438 \\u0441\\u0432\\u0430\\u044e \\u0434\\u043e\\u0433 \\u0442\\u044b\\u0441\\u0442\\u0438 \\u0432 \\u043b\\u0435 \\u043d\\u0430 \\u0442\\u043e \\u0436\\u0435 \\u043d\\u0435\\u0441\\u0442\\u043e, \\u0433\\u0434\\u0435 \\u0440\\u0430\\u0437\\u0431\\u0430\\u0445\\u0430\\u0442\\u044c\\u043b\\u0430 \\u0434\\u0435\\u0434\\u0430\\u0432\\u0430 \\u0434\\u043e\\u0433. \\u043d\\u0430\\u0441\\u043b\\u0443\\u0448\\u0430\\u043b\\u0441\\u044f \\u0434\\u0435\\u0434 \\u0438 \\u043a\\u0430\\u0442\\u044b\\u0435 \\u0437\\u0430\\u0434\\u0438\\u043d\\u0443 \\u0434\\u043e\\u0433 6 \\u043d\\u0435. \\u0442\\u0430\\u043c \\u0437\\u0430\\u0434\\u0438\\u043d\\u0430 \\u0434\\u043e\\u0433 \\u0441\\u0435\\u043b\\u0430 \\u0434\\u0435\\u0440\\u0435\\u0432\\u0446\\u0430 \\u0438 \\u0436\\u0434\\u0430\\u0442\\u044c \\u0441\\u0435\\u043b\\u043e. \\u0445\\u043e \\u043d\\u0430\\u0441\\u0442\\u0443\\u043f\\u0438\\u043b\\u0430, \\u0445\\u043e\\u043b\\u0430\\u0434\\u043d\\u0438\\u0435 \\u0441\\u0442\\u0430\\u043a\\u0430. \\u043d\\u043e\\u0447\\u044c\\u044e \\u043c\\u0430\\u0440\\u043e\\u0435 \\u043f\\u0440\\u0438\\u0448\\u0435 \\u0438 \\u0441\\u0442\\u0443\\u043a\\u043d\\u0443\\u043b \\u043f\\u0430\\u043b\\u0438\\u0446\\u0435\\u0439 \\u0437\\u0430 \\u0434\\u0435\\u0440\\u0435\\u0432\\u0446\\u0443. \\u0447\\u0435\\u0440 \\u043a\\u0430\\u043a\\u043e\\u0439 \\u0442\\u0435\\u0431\\u044f \\u043f\\u0440\\u0438\\u0441\\u043b\\u0430\\u043b \\u0441\\u0443\\u0434\\u0430. \\u0442\\u044b \\u043a\\u0442\\u043e! \\u043d\\u0438\\u0433\\u0430\\u0432 \\u043d\\u0430\\u0440\\u043e\\u0435 \\u043d\\u044f \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b \\u0438 \\u0434\\u0438\\u0432\\u0456\\u043e\\u043d\\u043a\\u0443 \\u043d\\u0430 \\u0440\\u0430\\u0436\\u0430\\u043b\\u0435\\u0445, \\u0430\\u0442 \\u043d\\u0430\\u0440\\u043e\\u0437\\u0438\\u043b \\u043d\\u043e\\u0441. \\u043d\\u0430 \\u0441\\u043d\\u0435\\u0434\\u0443\\u044e\\u0449\\u0443\\u044e \\u043f\\u043e\\u0433 \\u043e\\u043f\\u044f\\u0442\\u044c \\u0442\\u0430\\u0440\\u043e\\u0435 \\u043f\\u0440\\u0438\\u0448\\u0435\\u043b: \\u0447\\u0435\\u0440 \\u0442\\u0435\\u0431\\u044f \\u043a\\u0430\\u043a\\u043e\\u0439 \\u0441\\u0443\\u0434\\u0430 \\u043f\\u0440\\u0438 \\u0441\\u043a\\u0430\\u044f: \\u043d\\u044f \\u043f\\u0430\\u0436\\u0430\\u043b\\u0441\\u044f \\u043c\\u0430\\u0440\\u043e\\u0435 \\u0434\\u0435\\u0432\\u0433\\u043e\\u043d \\u043d\\u0443, \\u0440\\u0443\\u043a\\u0438 \\u0434\\u0430 \\u043d\\u043e\\u0448\\u043a\\u0438 \\u0430\\u0442\\u043d\\u043e\\u0440\\u043e \\u0433\\u043b\\u044f. \\u0431\\u0430\\u0434\\u043e\\u0432\\u0430 \\u0434\\u043e\\u0433 \\u0432\\u0441\\u044f \\u0434\\u0440\\u0430\\u0436\\u0438\\u0442, \\u0430 \\u043d\\u0430\\u0440\\u043e\\u0437\\u0430 \\u043f\\u0440\\u0430\\u0441\\u0442\\u044c \\u043d\\u0430 \\u0441\\u0430\\u0431\\u0438\\u0440\\u0430\\u0449\\u0430. \\u043d\\u0430\\u0441\\u0438\\u0443\\u0442\\u0438\\u043b\\u0430 \\u0442\\u0440\\u0435\\u0442\\u044c\\u044f \\u043f\\u043e\\u0433. \\u0438 \\u0430\\u043f\\u044f\\u0442\\u044c \\u043d\\u0430\\u0440\\u043e\\u0435 \\u0442\\u0443\\u0442 \\u043a\\u0430\\u043a \\u0431\\u0443\\u0442. \\u0438 \\u0437\\u0430\\u043a\\u0440\\u0438\\u0447\\u0430\\u043b\\u0430 \\u0431\\u0430\\u0434\\u043e\\u0432\\u0430 \\u0434\\u043e\\u0433. \\u043d\\u0430 \\u043d\\u0430\\u0432\\u043e. \\u0438 \\u0437\\u0430\\u043c\\u0438\\u0440\\u043e\\u0437\\u0438\\u043b \\u043d\\u0430\\u0440\\u043e \\u0443\\u043e\\u0432\\u0443 \\u0434\\u043e\\u0439. \\u0438 \\u0434\\u043e\\u043c\\u0430 \\u043e\\u0430\\u0434\\u0430 \\u0432\\u0441\\u0435 \\u0436\\u0434\\u0435 \\u0434\\u043e\\u0447. \\u043d\\u044f \\u0432\\u044b\\u0431\\u0435\\u0440\\u043f\\u044c\\u043b\\u0430 \\u0431\\u0430\\u0434\\u0430 \\u043f\\u0440\\u0438\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430 \\u0434\\u0434\\u0430 \\u0437\\u0430\\u043f\\u0440\\u044f\\u0447 \\u043b\\u043e\\u0448\\u0430\\u0434\\u044c \\u0438 \\u043f\\u0430\\u0441\\u0445\\u0430\\u043b\\u0438 6 \\u043d\\u0435\\u0441. \\u043e\\u0439. \\u0438 \\u0448\\u0442\\u043e \\u0430\\u043d \\u0442\\u0430 \\u0432\\u0438 \\u0434\\u044f. \\u0432\\u0438\\u0434\\u044f, \\u0448\\u043d\\u043e \\u0437\\u0430\\u043d\\u0435\\u0440\\u0437\\u043a\\u0430 \\u0430 \\u0431\\u0430\\u0434\\u0430\\u0432\\u0430 \\u0434\\u043e\\u0433. \\u0437\\u0430\\u0440\\u044b\\u0434\\u0430\\u043b\\u0430 \\u0437\\u0430\\u0434\\u0430, \\u0443\\u0442\\u0448\\u0430\\u043b \\u044f\\u0432\\u043e \\u0434\\u0435\\u0434 \\u0432\\u0434\\u0440\\u0443\\u0433 \\u0437\\u0430\\u0434\\u0430 \\u0442\\u0442\\u043e \\u0432\\u0438\\u0434\\u0438\\u0442: \\u043b\\u0435\\u0436\\u0438\\u0442 \\u0440\\u044f\\u0434\\u043e\\u043c. \\u0434\\u043e\\u0447\\u043d\\u043e\\u0439 \\u0441\\u0443\\u043d\\u0434\\u0443\\u0445. \\u0430\\u0431\\u0440\\u0430\\u0434\\u043e\\u0432\\u0430\\u043b\\u0430\\u0441\\u044c \\u0431\\u0430\\u0434\\u0430 \\u0432\\u0441\\u043d\\u0430\\u0447\\u0438\\u043b\\u0430 \\u0438 \\u0441\\u0443\\u043d\\u0434\\u0443\\u043a\\u0443, \\u044b \\u043b\\u0430, \\u0438 \\u2014 \\u0430\\u0445 \\u0431\\u044b \\u0431\\u043e\\u0445 \\u043d\\u0430\\u0439 \\u043c\\u0442 \\u0442\\u0435\\u043f\\u0435\\u0440\\u044c \\u0431\\u044b\\u043b\\u043e \\u0442\\u043a\\u0440\\u044b\\u043b\\u0430 \\u0441\\u0443\\u043d\\u0434\\u0446 \\u0438 \\u043d\\u0430\\u0432\\u0435\\u0442\\u0440\\u0435 \\u0447\\u0443 \\u0435\\u0439 \\u0432\\u044b\\u043f\\u0440\\u044b\\u0433\\u043d\\u0443\\u043b\\u0438 \\u0436\\u0430\\u0431\\u044b. \\u043d\\u0441\\u043f\\u0443\\u0433\\u0430\\u043b\\u0430\\u0441\\u044c \\u0430\\u043d\\u0430, \\u0443\\u043f\\u0430\\u043b\\u0430 \\u0438 \\u0442\\u0430\\u043c \\u0436\\u0435 \\u0443\\u043c\\u044f\\u0440\\u043b\\u0430. \\u0430 \\u0434\\u0435\\u0434 \\u0434\\u0430 \\u044f\\u0432\\u043e \\u0434\\u043e\\u0433 \\u0449\\u0430\\u0441 \\u043a\\u0438\\u0432\\u0430 \\u0436\\u0438\\u0442\\u044c \\u0441\\u0442\\u0430\\u043a\\u0438. \\u0449\\u0430\\u0441\\u043a\\u0438\\u0432\\u0430 \\u0436\\u0438\\u0442\\u044c \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0438 \\u0441\\u043a\\u0430\\u0441\\u043a\\u0435 \\u043d\\u0430\\u043d\\u0435\\u0446 \\u043d\\u0430\\u0441\\u0442\\u0430\\u043b.\",\n          \"\\u0448\\u043b\\u0438 \\u0442\\u0440\\u0438 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\\u0430, \\u0448\\u043b\\u0438 \\u043e\\u043d\\u0438 \\u043b\\u0435\\u0441\\u043e\\u043c. \\u043d\\u0430\\u0441\\u0442\\u0443\\u043f\\u0438\\u043b\\u0430 \\u043d\\u043e\\u0447\\u044c \\u0438 \\u043e\\u043d\\u0438 \\u0437\\u0430\\u0448\\u043b\\u0438 \\u0432 \\u0438\\u0437\\u0431\\u0443\\u0448\\u043a\\u0443 \\u0438 \\u043f\\u043e\\u043f\\u0440 \\u0441\\u0438\\u043b\\u0438\\u0441\\u044c \\u043d\\u043e\\u0447\\u0435\\u0432\\u0430\\u0442\\u044c. \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u0438\\u0445 \\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0430. \\u044d\\u0442\\u0430 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u0431\\u044b\\u043b\\u0430 \\u0447\\u0435\\u0440\\u0442\\u0438\\u0445\\u0430. \\u043e\\u043d\\u0430 \\u0438\\u043c \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430, \\u0447\\u0442\\u043e \\u0432 \\u043a\\u043e\\u043c\\u043d\\u0430\\u0442\\u0435 \\u0443 \\u043d\\u0435\\u0435 \\u043c\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0435\\u0442\\u0438 \\u0443\\u043b\\u043e\\u043d\\u0438\\u043b\\u0430 \\u0438\\u0445 \\u0432 \\u043a\\u043e\\u043d\\u044e\\u0448\\u043d\\u0435. \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u043f\\u0440\\u0438\\u0448\\u043b\\u0438 \\u0443\\u0442\\u0440\\u043e\\u043c \\u0438 \\u043d\\u0435 \\u0445\\u043e\\u0442\\u0435\\u043b\\u0430 \\u0438 \\u0432\\u044b\\u043f\\u0443\\u0441\\u043a\\u0430\\u0442\\u044c \\u0434\\u0432\\u0430 \\u043a\\u0430\\u043a\\u0442\\u043e, \\u0432\\u044b\\u0441\\u043a\\u043e\\u0447\\u0438\\u043b\\u0438 \\u0438 \\u0443\\u0431\\u0435\\u0433\\u043b\\u0438 \\u0430 \\u043e\\u0434\\u0438\\u043d \\u043e\\u0441\\u0442\\u0430\\u043b\\u0441\\u044f. \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u0435\\u043c\\u0443 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442: \\u044f \\u0442\\u0435\\u0431\\u044f \\u0440\\u0430\\u043d\\u044c\\u043d\\u0435 \\u0432\\u044b\\u043f\\u0443\\u0449\\u0443, \\u043f\\u043e\\u043a\\u0430 \\u0442\\u044b \\u043d\\u0435 \\u043e\\u0442\\u043c\\u043e\\u043b\\u0438\\u0438\\u044c\\u0441\\u044f \\u043c\\u043d\\u0435 \\u0442\\u0440\\u0438 \\u043d\\u043e\\u0433\\u0438 \\u043a\\u043e\\u0433\\u0434\\u0430 \\u043e\\u043d \\u043c\\u043e\\u043b\\u0438\\u043b\\u0441\\u044f \\u0435\\u0439 \\u0432 \\u043f\\u0435\\u0440\\u0435\\u0432\\u0443\\u044e \\u043d\\u043e\\u0447\\u044c, \\u0447\\u0435\\u0440\\u0442\\u0438 \\u0441\\u0437\\u0430\\u0434\\u0438 \\u043f\\u043b\\u044f\\u0441\\u0430\\u043b\\u0438 \\u0438 \\u0431\\u0440\\u0430\\u0441\\u0430\\u043b\\u0438\\u0441\\u044c \\u043f\\u0430\\u043b\\u043a\\u0430\\u043c\\u0438. \\u043a\\u043e\\u0433\\u0434\\u0430 \\u043e\\u043d \\u0441\\u0442\\u0430\\u043b \\u043c\\u043e\\u043b\\u0438\\u0442\\u044c\\u0441\\u044f, \\u0442\\u043e \\u0441\\u043f\\u0435\\u0440\\u0432\\u0430 \\u0432\\u0441\\u0442\\u0430\\u044f \\u043f\\u043e\\u0441\\u0435\\u0440\\u0435\\u0434\\u0438\\u043d\\u0435 \\u0438\\u0437\\u0431\\u044b \\u0438 \\u043e\\u0431\\u0432\\u0435\\u043b \\u043a\\u0440\\u0443\\u0433. \\u043e\\u043d \\u044d\\u0442\\u043e \\u0441\\u0434\\u0435\\u043b\\u0430\\u043b, \\u0447\\u0442\\u043e\\u0431\\u044b \\u0447\\u0435\\u0440\\u0442\\u0438 \\u043d\\u0435 \\u0432\\u0438\\u0434\\u0430\\u043b\\u0438 \\u0433\\u0434\\u0435 \\u043e\\u043d. \\u0442\\u043a\\u0430\\u043a \\u043c\\u043e\\u043b\\u0438\\u043b\\u0441\\u044f \\u043e\\u043d \\u043f\\u0435\\u0440\\u0432\\u0443\\u044e \\u0438 \\u0432\\u0442\\u043e\\u0440\\u0443\\u044e \\u043d\\u043e\\u0447\\u044c, \\u043d\\u0430 \\u0442\\u0440\\u0435\\u0442\\u044c\\u044f \\u0447\\u0435\\u0440\\u0442\\u0438. \\u043d\\u0435 \\u0445\\u043e\\u0442\\u0435\\u043b\\u0438 \\u0435\\u0433\\u043e \\u043e\\u0442\\u043f\\u0443\\u0441\\u043a\\u0430\\u0442\\u044c \\u0438 \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438, \\u0447\\u0442\\u043e\\u0431\\u044b \\u043e\\u043d \\u043d\\u0435 \\u0441\\u043c\\u0435\\u043b \\u043e\\u0433\\u043b\\u0430\\u0434\\u044c\\u0435\\u0432\\u0430\\u044c \\u0441\\u044f\\u0442\\u0430\\u043a \\u043a\\u0430\\u043a \\u043e\\u043d\\u0438 \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0443\\u0442 \\u0441\\u0430\\u043c\\u043e\\u0433\\u043e \\u0447\\u0435\\u0440\\u0442\\u0430. \\u0432\\u043e\\u0442 \\u043f\\u0440\\u0438\\u0448\\u0435\\u043b \\u0441\\u0430\\u043c \\u0447\\u0435\\u0440\\u0442 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442: \\u043e\\u0433\\u0438 \\u043e\\u0442\\u043a\\u0440\\u043e\\u0439\\u0442\\u0435 \\u0438\\u043b\\u043e\\u0432\\u0435\\u043a \\u0442\\u0430\\u043a \\u0438\\u0441\\u043f\\u0443\\u0436\\u0430\\u043b\\u0441\\u044f, \\u0447\\u0442\\u043e \\u043e\\u0442 \\u0441\\u0442\\u0440\\u0430\\u0445\\u0443 \\u0437\\u0430\\u0431\\u044b\\u043b, \\u0447\\u0442\\u043e \\u043d\\u0435\\u043b\\u044c\\u0437\\u044f \\u043e\\u0433\\u043b\\u044f \\u0434\\u044b\\u0432\\u0430\\u0442\\u044c\\u0441\\u044f. \\u043e\\u0433\\u043b\\u044f\\u043d\\u0443\\u043b\\u0441\\u044f, \\u0442\\u0443\\u0442 \\u0435\\u0433\\u043e \\u0447\\u0435\\u0440\\u0442\\u0438 \\u0441\\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0438 \\u0438 \\u0440\\u0430\\u0441\\u0442\\u0435\\u0440\\u0442\\u0430\\u043b\\u0438\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-label encoding and parent-level labels for evaluation\n",
        "\n",
        "Because each tale in our corpus can be assigned to **one or more ATU types**, we treat ATU prediction as a **multi-label classification** task. We first convert the human-assigned label sets into a machine-learning friendly representation using `MultiLabelBinarizer`. This step builds a fixed label vocabulary from the training data and transforms each tale’s label list into a **multi-hot binary vector**. This representation is required by standard multi-label classifiers (e.g., One-vs-Rest logistic regression) and ensures a reproducible mapping between labels and output dimensions.\n",
        "\n",
        "In addition to the original ATU labels, we derive a **parent-level label set** for evaluation. ATU types frequently include suffixes or modifiers (e.g., `327A`, `480D*`), while the **leading numeric component** (e.g., `327`, `480`) captures a higher-level category that is often more stable under noisy HTR conditions and small-data regimes. We therefore extract the first 1–4 digits from each ATU label via a simple regular expression and assign the resulting parent codes as `labels_parent`. This enables evaluation at a coarser granularity (e.g., Parent-Hit@3), which better reflects the intended use of the system as a **decision-support tool**: even when the model fails to predict the exact subtype, correctly retrieving the parent class can still provide a meaningful shortlist for expert review.\n"
      ],
      "metadata": {
        "id": "gNh9Iy4_stoC"
      },
      "id": "gNh9Iy4_stoC"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------\n",
        "# 1) ATU parent extraction\n",
        "# -------------------------\n",
        "RE_ATU_PARENT = re.compile(r\"(\\d{1,4})\")\n",
        "\n",
        "def atu_parent(label: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract the leading numeric ATU parent code.\n",
        "    Examples:\n",
        "      \"530\" -> \"530\"\n",
        "      \"327A\" -> \"327\"\n",
        "      \"ATU_480D*\" -> \"480\"\n",
        "      \"ATU 301\" -> \"301\"\n",
        "    \"\"\"\n",
        "    if label is None:\n",
        "        return \"\"\n",
        "    s = str(label).strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    m = RE_ATU_PARENT.search(s)\n",
        "    return m.group(1) if m else \"\"\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 2) Robust label utilities\n",
        "# -------------------------\n",
        "def _is_nan(x) -> bool:\n",
        "    return isinstance(x, float) and pd.isna(x)\n",
        "\n",
        "def to_parent_set(labels) -> list[str]:\n",
        "    \"\"\"\n",
        "    Convert a list of ATU labels to a sorted list of unique parent codes.\n",
        "    Robust to:\n",
        "      - labels=None / labels=NaN\n",
        "      - NaN elements inside the list\n",
        "      - empty/whitespace strings\n",
        "    \"\"\"\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "\n",
        "    out = set()\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        p = atu_parent(s)\n",
        "        if p:\n",
        "            out.add(p)\n",
        "\n",
        "    return sorted(out)\n",
        "\n",
        "def ensure_labels_parent(\n",
        "    df: pd.DataFrame,\n",
        "    labels_col: str = \"labels\",\n",
        "    out_col: str = \"labels_parent\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add df[out_col] as parent codes derived from df[labels_col] (list[str]).\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df[out_col] = df[labels_col].apply(to_parent_set)\n",
        "    return df\n",
        "\n",
        "def clean_label_list(labels) -> list[str]:\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "    if isinstance(labels, str):\n",
        "        s = labels.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# 3) Parent-Hit@k from proba (any match)\n",
        "# ---------------------------------------\n",
        "def parent_hit_at_k_from_proba(\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    proba: np.ndarray,\n",
        "    classes: np.ndarray,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Parent-Hit@k (any match):\n",
        "    success if at least one gold parent code appears among parent codes\n",
        "    of the model's top-k predicted labels.\n",
        "    \"\"\"\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be >= 1\")\n",
        "    if proba.shape[0] != len(y_true_parent_lists):\n",
        "        raise ValueError(\"n_samples mismatch between y_true_parent_lists and proba\")\n",
        "    if proba.shape[1] != len(classes):\n",
        "        raise ValueError(\"proba columns != classes length (alignment issue)\")\n",
        "\n",
        "    classes_parent = np.array([atu_parent(c) for c in classes])\n",
        "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "\n",
        "    hits = []\n",
        "    for i, gold_parents in enumerate(y_true_parent_lists):\n",
        "        gold_set = set(gold_parents or [])\n",
        "        pred_parent_set = set(classes_parent[topk_idx[i]])\n",
        "        pred_parent_set.discard(\"\")  # defensive\n",
        "        hits.append(1 if (gold_set & pred_parent_set) else 0)\n",
        "\n",
        "    return float(np.mean(hits))\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# 4) Exact-Hit@k from proba (any match)\n",
        "# -----------------------------------\n",
        "def exact_hit_at_k_from_proba(\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    proba: np.ndarray,\n",
        "    classes: np.ndarray,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Exact-Hit@k (any match):\n",
        "    success if at least one exact gold label appears among the model's top-k labels.\n",
        "    \"\"\"\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be >= 1\")\n",
        "    if proba.shape[0] != len(y_true_labels_lists):\n",
        "        raise ValueError(\"n_samples mismatch between y_true_labels_lists and proba\")\n",
        "    if proba.shape[1] != len(classes):\n",
        "        raise ValueError(\"proba columns != classes length (alignment issue)\")\n",
        "\n",
        "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "\n",
        "    hits = []\n",
        "    for i, gold_labels in enumerate(y_true_labels_lists):\n",
        "        gold_set = set(clean_label_list(gold_labels))\n",
        "        pred_set = set(classes[topk_idx[i]])\n",
        "        hits.append(1 if (gold_set & pred_set) else 0)\n",
        "\n",
        "    return float(np.mean(hits))\n",
        "\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 5) Weighted@k: exact=1.0, parent-only=parent_weight else 0\n",
        "# -------------------------------------------------------\n",
        "def weighted_hit_at_k_from_proba(\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    proba: np.ndarray,\n",
        "    classes: np.ndarray,\n",
        "    k: int = 3,\n",
        "    parent_weight: float = 0.5\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Weighted@k:\n",
        "      - 1.0 if exact-hit@k\n",
        "      - parent_weight if exact miss but parent-hit@k\n",
        "      - 0.0 otherwise\n",
        "    \"\"\"\n",
        "    if k <= 0:\n",
        "        raise ValueError(\"k must be >= 1\")\n",
        "    if not (0.0 <= parent_weight <= 1.0):\n",
        "        raise ValueError(\"parent_weight must be in [0, 1]\")\n",
        "    if proba.shape[0] != len(y_true_labels_lists) or proba.shape[0] != len(y_true_parent_lists):\n",
        "        raise ValueError(\"n_samples mismatch between y_true lists and proba\")\n",
        "    if proba.shape[1] != len(classes):\n",
        "        raise ValueError(\"proba columns != classes length (alignment issue)\")\n",
        "\n",
        "    classes_parent = np.array([atu_parent(c) for c in classes])\n",
        "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
        "\n",
        "    scores = []\n",
        "    for i in range(proba.shape[0]):\n",
        "        gold_labels = set(clean_label_list(y_true_labels_lists[i]))\n",
        "        gold_parents = set(y_true_parent_lists[i] or [])\n",
        "\n",
        "        pred_labels = set(classes[topk_idx[i]])\n",
        "        pred_parents = set(classes_parent[topk_idx[i]])\n",
        "        pred_parents.discard(\"\")\n",
        "\n",
        "        if gold_labels & pred_labels:\n",
        "            scores.append(1.0)\n",
        "        elif gold_parents & pred_parents:\n",
        "            scores.append(float(parent_weight))\n",
        "        else:\n",
        "            scores.append(0.0)\n",
        "\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 6) Model wrappers (assumes predict_proba)\n",
        "# -----------------------------------------\n",
        "def _get_model_scores(model, X_df: pd.DataFrame) -> np.ndarray:\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X_df)\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        scores = model.decision_function(X_df)\n",
        "        if scores.ndim == 1:\n",
        "            scores = scores.reshape(-1, 1)\n",
        "        return scores\n",
        "    raise AttributeError(\"Model must implement predict_proba or decision_function\")\n",
        "\n",
        "\n",
        "def parent_hit_at_k_model(\n",
        "    model,\n",
        "    X_df: pd.DataFrame,\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    mlb,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    scores = _get_model_scores(model, X_df)\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "    return parent_hit_at_k_from_proba(y_true_parent_lists, scores, classes, k=k)\n",
        "\n",
        "def exact_hit_at_k_model(\n",
        "    model,\n",
        "    X_df: pd.DataFrame,\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    mlb,\n",
        "    k: int = 3\n",
        ") -> float:\n",
        "    scores = _get_model_scores(model, X_df)\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "    return exact_hit_at_k_from_proba(y_true_labels_lists, scores, classes, k=k)\n",
        "\n",
        "def weighted_hit_at_k_model(\n",
        "    model,\n",
        "    X_df: pd.DataFrame,\n",
        "    y_true_labels_lists: list[list[str]],\n",
        "    y_true_parent_lists: list[list[str]],\n",
        "    mlb,\n",
        "    k: int = 3,\n",
        "    parent_weight: float = 0.5\n",
        ") -> float:\n",
        "    scores = _get_model_scores(model, X_df)\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "    return weighted_hit_at_k_from_proba(\n",
        "        y_true_labels_lists,\n",
        "        y_true_parent_lists,\n",
        "        scores,\n",
        "        classes,\n",
        "        k=k,\n",
        "        parent_weight=parent_weight\n",
        "    )\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 7) Recommended safe X construction example\n",
        "# -----------------------------------------\n",
        "def build_X_text_only(df: pd.DataFrame, text_cols=(\"summary_norm\", \"text_norm\")) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    SAFE helper: return X_df with ONLY the columns intended for vectorization.\n",
        "    This prevents accidental leakage via tale_id or metadata columns.\n",
        "    \"\"\"\n",
        "    cols = [c for c in text_cols if c in df.columns]\n",
        "    if not cols:\n",
        "        raise ValueError(f\"None of text_cols {text_cols} found in df columns\")\n",
        "    return df[cols].copy()"
      ],
      "metadata": {
        "id": "Bb7wz8w4-dUo"
      },
      "id": "Bb7wz8w4-dUo",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratified train/test split for multi-label data using parent ATU codes\n",
        "\n",
        "To evaluate the classifier on a held-out set while preserving label coverage, we implement a **custom stratified split** tailored to **multi-label** data. Standard stratification methods assume a single label per instance and do not directly support the setting where each tale can have **multiple ATU types**. This is especially problematic in our small corpus, where many labels are rare: a naive random split can easily place the only example of a label in the test set, leaving the model with **zero training examples** for that label.\n",
        "\n",
        "Our function `stratified_multilabel_split_by_parent()` performs an approximate stratification over `labels_parent` (coarser ATU parent codes), with the goal of constructing a test subset of size `test_size` while ensuring that the training set retains minimal coverage for the labels present.\n",
        "\n",
        "The procedure is as follows:\n",
        "\n",
        "1. **Target test size.** We compute the desired number of test documents (`n_test = round(n * test_size)`).\n",
        "\n",
        "2. **Label availability tracking.** We count how many documents contain each parent label (`all_counts`) and keep a mutable counter `remaining` to track how many examples of each label would remain in the training pool if we move documents into the test set.\n",
        "\n",
        "3. **Safety constraint.** A document is considered *safe* to move into the test set if doing so does not exhaust any of its labels in the remaining pool:\n",
        "   - `is_safe(i)` returns `True` only if for every label in document `i`, `remaining[label] ≥ 2`.\n",
        "   This conservative rule ensures that after selecting the test items, each label included in a moved document still has at least one example left for training (and avoids dropping a label entirely from the training set).\n",
        "\n",
        "4. **Coverage-oriented greedy selection.** We iteratively build the test set using a greedy criterion:\n",
        "   - `gain(i)` measures how many **new** parent labels a candidate document would contribute to the current test set (labels not yet covered in `covered_test`).\n",
        "   At each step we choose, among safe candidates, a document with maximal gain (ties are broken randomly). This increases the diversity of labels represented in the test split without violating the safety constraint.\n",
        "\n",
        "5. **Fallback filling.** If we cannot reach the desired test size using the greedy coverage criterion (because the safety constraint becomes too restrictive), we fill the remaining slots by randomly selecting from the remaining safe documents.\n",
        "\n",
        "Finally, we return two dataframes: `train_df` and `test_df`. This split is designed to be **more stable and fair** than a naive random split for small multi-label datasets, because it reduces the risk of creating “unseen-in-training” labels and improves the interpretability of downstream evaluation (e.g., Parent-Hit@3).\n"
      ],
      "metadata": {
        "id": "Uoegw2BKuXVe"
      },
      "id": "Uoegw2BKuXVe"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1) Fit MLB safely (labels must be list[str] per row) ---\n",
        "# If you already have ensure_list() from earlier, use it here.\n",
        "# Otherwise this minimal guard will prevent common issues with NaN / empty / stringified lists.\n",
        "def _is_nan(x) -> bool:\n",
        "    return isinstance(x, float) and pd.isna(x)\n",
        "\n",
        "def clean_label_list(labels) -> list[str]:\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "    # if labels accidentally stored as a single string, wrap it\n",
        "    if isinstance(labels, str):\n",
        "        s = labels.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    # unique, stable order\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "df = df.copy()\n",
        "df[\"labels\"] = df[\"labels\"].apply(clean_label_list)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df[\"labels\"])\n",
        "\n",
        "print(\"Docs:\", len(df))\n",
        "print(\"Unique labels:\", len(mlb.classes_))\n",
        "\n",
        "\n",
        "# --- 2) Parent labels for evaluation (robust, filters NaN inside lists) ---\n",
        "RE_ATU_PARENT = re.compile(r\"(\\d{1,4})\")\n",
        "\n",
        "def atu_parent(label: str) -> str:\n",
        "    if label is None:\n",
        "        return \"\"\n",
        "    s = str(label).strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    m = RE_ATU_PARENT.search(s)\n",
        "    return m.group(1) if m else \"\"\n",
        "\n",
        "def to_parent_set(labels) -> list[str]:\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "    out = set()\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        p = atu_parent(s)\n",
        "        if p:\n",
        "            out.add(p)\n",
        "    return sorted(out)\n",
        "\n",
        "df[\"labels_parent\"] = df[\"labels\"].apply(to_parent_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD-LTRQv-voO",
        "outputId": "9535721f-b934-4676-eba4-368974bb834d"
      },
      "id": "hD-LTRQv-voO",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docs: 50\n",
            "Unique labels: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def stratified_multilabel_split_by_parent(\n",
        "    df: pd.DataFrame,\n",
        "    label_col: str = \"labels_parent\",\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    min_train_count_per_label: int = 1,\n",
        "    require_nonempty_labels: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Greedy multi-label \"stratified-ish\" split by parent labels.\n",
        "    Goals:\n",
        "      - put ~test_size of rows into test\n",
        "      - maximize label coverage in test\n",
        "      - avoid removing too many instances of any label from train\n",
        "\n",
        "    Safety:\n",
        "      - filters NaN/None/empty labels\n",
        "      - guarantees: for any label assigned to a test doc, train keeps at least\n",
        "        min_train_count_per_label instances of that label (when possible).\n",
        "\n",
        "    Notes:\n",
        "      - This is heuristic (not exact stratification).\n",
        "      - If some labels are extremely rare, constraints may prevent reaching\n",
        "        the exact n_test; we backfill with best-effort safe picks.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    df = df.reset_index(drop=True).copy()\n",
        "\n",
        "    if not (0.0 < test_size < 1.0):\n",
        "        raise ValueError(\"test_size must be in (0, 1)\")\n",
        "    n = len(df)\n",
        "    if n < 2:\n",
        "        raise ValueError(\"Need at least 2 rows to split\")\n",
        "\n",
        "    # ---- normalize label lists: list[str], filter empties/NaNs ----\n",
        "    def _clean_labels(x):\n",
        "        if x is None or (isinstance(x, float) and pd.isna(x)):\n",
        "            return []\n",
        "        out = []\n",
        "        for lab in x:\n",
        "            if lab is None or (isinstance(lab, float) and pd.isna(lab)):\n",
        "                continue\n",
        "            s = str(lab).strip()\n",
        "            if s:\n",
        "                out.append(s)\n",
        "        # unique, stable order\n",
        "        seen = set()\n",
        "        dedup = []\n",
        "        for s in out:\n",
        "            if s not in seen:\n",
        "                seen.add(s)\n",
        "                dedup.append(s)\n",
        "        return dedup\n",
        "\n",
        "    df[label_col] = df[label_col].apply(_clean_labels)\n",
        "\n",
        "    if require_nonempty_labels:\n",
        "        # keep only rows with at least one label (optional strict mode)\n",
        "        df = df[df[label_col].map(len) > 0].reset_index(drop=True)\n",
        "        n = len(df)\n",
        "        if n < 2:\n",
        "            raise ValueError(\"After filtering empty labels, not enough rows to split\")\n",
        "\n",
        "    n_test = int(round(n * test_size))\n",
        "    n_test = max(1, min(n - 1, n_test))  # must leave at least 1 train row\n",
        "\n",
        "    # label frequency in full data\n",
        "    all_counts = Counter(lab for labs in df[label_col] for lab in labs)\n",
        "    remaining = Counter(all_counts)  # how many of each label still available for test assignment\n",
        "\n",
        "    test_idx = []\n",
        "    covered_test = set()\n",
        "\n",
        "    candidates = list(range(n))\n",
        "    rng.shuffle(candidates)\n",
        "\n",
        "    def is_safe(i: int) -> bool:\n",
        "        labs = df.at[i, label_col]\n",
        "        # If no labels, it's always safe (doesn't affect remaining counts)\n",
        "        if not labs:\n",
        "            return True\n",
        "        # Ensure leaving at least min_train_count_per_label in train after moving this row to test.\n",
        "        # That is: remaining[lab] - 1 >= min_train_count_per_label\n",
        "        return all((remaining[lab] - 1) >= min_train_count_per_label for lab in labs)\n",
        "\n",
        "    def gain(i: int) -> int:\n",
        "        labs = set(df.at[i, label_col])\n",
        "        return len(labs - covered_test)\n",
        "\n",
        "    # ---- greedy pick: maximize new label coverage under safety constraint ----\n",
        "    while len(test_idx) < n_test:\n",
        "        safe = [i for i in candidates if (i not in test_idx and is_safe(i))]\n",
        "        if not safe:\n",
        "            break\n",
        "\n",
        "        gains = np.array([gain(i) for i in safe], dtype=int)\n",
        "        best_gain = gains.max()\n",
        "        best = [safe[j] for j in np.where(gains == best_gain)[0]]\n",
        "        chosen = int(rng.choice(best))\n",
        "\n",
        "        test_idx.append(chosen)\n",
        "        labs_chosen = df.at[chosen, label_col]\n",
        "        for lab in labs_chosen:\n",
        "            remaining[lab] -= 1\n",
        "            covered_test.add(lab)\n",
        "\n",
        "    # ---- backfill if needed: pick any remaining safe rows (random order) ----\n",
        "    if len(test_idx) < n_test:\n",
        "        safe_rest = [i for i in range(n) if (i not in test_idx and is_safe(i))]\n",
        "        rng.shuffle(safe_rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(safe_rest[:need])\n",
        "\n",
        "    # if still short, last resort: fill randomly (may violate constraints for ultra-rare labels)\n",
        "    if len(test_idx) < n_test:\n",
        "        rest = [i for i in range(n) if i not in test_idx]\n",
        "        rng.shuffle(rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(rest[:need])\n",
        "\n",
        "    test_idx = sorted(set(test_idx))\n",
        "    # ensure not all docs went to test due to dedup\n",
        "    if len(test_idx) >= n:\n",
        "        test_idx = test_idx[: n - 1]\n",
        "\n",
        "    train_idx = [i for i in range(n) if i not in test_idx]\n",
        "\n",
        "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "    test_df = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# usage\n",
        "train_df, test_df = stratified_multilabel_split_by_parent(\n",
        "    df,\n",
        "    label_col=\"labels_parent\",\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    min_train_count_per_label=1,   # keep at least 1 occurrence of each label in train when possible\n",
        "    require_nonempty_labels=False  # set True if you want to exclude empty-labeled rows entirely\n",
        ")\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"| Test:\", test_df.shape)\n",
        "\n",
        "print(\"Unique parents train:\", len(set(l for labs in train_df[\"labels_parent\"] for l in labs)))\n",
        "print(\"Unique parents test:\", len(set(l for labs in test_df[\"labels_parent\"] for l in labs)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqoRyozw_b5w",
        "outputId": "075cc4ef-e936-4fb7-b7d5-8860b04d6dff"
      },
      "id": "CqoRyozw_b5w",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (40, 5) | Test: (10, 5)\n",
            "Unique parents train: 32\n",
            "Unique parents test: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Joz0A0Gc_ie7",
        "outputId": "2220eac0-9dd7-4920-8d78-746ed6b41c96"
      },
      "id": "Joz0A0Gc_ie7",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tale_id                                       summary_norm  \\\n",
              "0    era_vene_1_503_1                                   царевна-лягушка.   \n",
              "1    era_vene_1_515_1  по пьяни мужик спорит, что сможет принести ноч...   \n",
              "2  era_vene_12_105_22                                        снегурочка.   \n",
              "3  era_vene_12_137_98                                        иван-дурак.   \n",
              "4   era_vene_12_189_1                                         два брата.   \n",
              "\n",
              "                                           text_norm  labels labels_parent  \n",
              "0  тили были царь с царицей у не было три сына. ц...   [402]         [402]  \n",
              "1  раз пяное, ребятище» подился. что можит в 12 ч...   [410]         [410]  \n",
              "2  сделали дети со снегу куклу. в одного старина ...  [703*]         [703]  \n",
              "3  кил-был стажк. в яво бло тра сегна. миша, гриш...   [530]         [530]  \n",
              "4  жили — брели два брата. и посла смерти отца об...  [735A]         [735]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ec0b063-7b51-44c6-a879-ef954f59ec96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tale_id</th>\n",
              "      <th>summary_norm</th>\n",
              "      <th>text_norm</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels_parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>era_vene_1_503_1</td>\n",
              "      <td>царевна-лягушка.</td>\n",
              "      <td>тили были царь с царицей у не было три сына. ц...</td>\n",
              "      <td>[402]</td>\n",
              "      <td>[402]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>era_vene_1_515_1</td>\n",
              "      <td>по пьяни мужик спорит, что сможет принести ноч...</td>\n",
              "      <td>раз пяное, ребятище» подился. что можит в 12 ч...</td>\n",
              "      <td>[410]</td>\n",
              "      <td>[410]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>era_vene_12_105_22</td>\n",
              "      <td>снегурочка.</td>\n",
              "      <td>сделали дети со снегу куклу. в одного старина ...</td>\n",
              "      <td>[703*]</td>\n",
              "      <td>[703]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>era_vene_12_137_98</td>\n",
              "      <td>иван-дурак.</td>\n",
              "      <td>кил-был стажк. в яво бло тра сегна. миша, гриш...</td>\n",
              "      <td>[530]</td>\n",
              "      <td>[530]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>era_vene_12_189_1</td>\n",
              "      <td>два брата.</td>\n",
              "      <td>жили — брели два брата. и посла смерти отца об...</td>\n",
              "      <td>[735A]</td>\n",
              "      <td>[735]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ec0b063-7b51-44c6-a879-ef954f59ec96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ec0b063-7b51-44c6-a879-ef954f59ec96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ec0b063-7b51-44c6-a879-ef954f59ec96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2f8f965-2b70-45c5-a152-1f86e8f331bd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2f8f965-2b70-45c5-a152-1f86e8f331bd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2f8f965-2b70-45c5-a152-1f86e8f331bd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"tale_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"era_vene_15_308_4\",\n          \"era_vene_13_635_20\",\n          \"era_vene_13_43_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"\\u0434\\u0435\\u0434, \\u0431\\u0430\\u0431\\u0430 \\u0438 \\u0438\\u0445 \\u0434\\u043e\\u0447\\u0435\\u0440\\u0438 \\u043f\\u043e\\u0448\\u043b\\u0438 \\u0442\\u043a\\u0430\\u0442\\u044c \\u043f\\u043e\\u044f\\u0441\\u0430 \\u0432 \\u0431\\u0430\\u043d\\u044e. \\u0442\\u0443\\u0434\\u0430 \\u043f\\u0440\\u043e\\u0441\\u0438\\u0442\\u0441\\u044f \\u043f\\u043e\\u0433\\u0440\\u0435\\u0442\\u044c\\u0441\\u044f \\u0432\\u043e\\u043b\\u043a, \\u043f\\u0443\\u0441\\u043a\\u0430\\u044e\\u0442. \\u0432\\u0441\\u0435 \\u043a\\u0440\\u043e\\u043c\\u0435 \\u0442\\u0430\\u043d\\u0438 - \\u0434\\u0435\\u0434\\u0443\\u0448\\u043a\\u0438\\u043d\\u043e\\u0439 \\u0434\\u043e\\u0447\\u043a\\u0438, \\u043f\\u0443\\u0433\\u0430\\u044e\\u0442\\u0441\\u044f \\u0438 \\u0443\\u0431\\u0435\\u0433\\u0430\\u044e\\u0442. \\u0432\\u043e\\u043b\\u043a \\u0441\\u0432\\u0430\\u0442\\u0430\\u0435\\u0442 \\u0435\\u0435 \\u0437\\u0430 \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e \\u0441\\u044b\\u043d\\u0430, \\u0442\\u0430\\u043d\\u044f \\u043e\\u0442\\u0432\\u0435\\u0447\\u0430\\u0435\\u0442, \\u0447\\u0442\\u043e \\u0443 \\u043d\\u0435\\u0435 \\u043d\\u0435\\u0442 \\u043f\\u0440\\u0438\\u0434\\u0430\\u043d\\u043e\\u0433\\u043e. \\u0432\\u043e\\u043b\\u043a \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442 \\u0441\\u044b\\u043d\\u0443 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u0442\\u0438 \\u0442\\u043e, \\u0447\\u0442\\u043e \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430 \\u0442\\u0440\\u0435\\u0431\\u0443\\u0435\\u0442. \\u0432\\u0441\\u0435 \\u043f\\u0440\\u0438\\u043d\\u043e\\u0441\\u0438\\u0442\\u0441\\u044f \\u0438 \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430 \\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0430\\u0435\\u0442\\u0441\\u044f. \\u0432\\u044b\\u0445\\u043e\\u0434\\u044f\\u0442 \\u0438\\u0437 \\u0431\\u0430\\u043d\\u0438, \\u043e\\u043d\\u0430 \\u043f\\u0440\\u043e\\u0441\\u0438\\u0442 \\u043f\\u0435\\u0442\\u0443\\u0445\\u043e\\u0432 \\u0437\\u0430\\u043f\\u0435\\u0442\\u044c, \\u0447\\u0435\\u0440\\u0442 \\u0438 \\u0441\\u044b\\u043d \\u043f\\u0440\\u043e\\u0432\\u0430\\u043b\\u0438\\u0432\\u0430\\u044e\\u0442\\u0441\\u044f, \\u0442\\u0430\\u043d\\u044f \\u043e\\u0441\\u0442\\u0430\\u0435\\u0442\\u0441\\u044f \\u0441 \\u043f\\u0440\\u0438\\u0434\\u0430\\u043d\\u044b\\u043c. _x000d_ \\u043c\\u0430\\u0447\\u0435\\u0445\\u0430 \\u043f\\u043e\\u0441\\u044b\\u043b\\u0430\\u0435\\u0442 \\u0441\\u0432\\u043e\\u044e \\u0434\\u043e\\u0447\\u043a\\u0443 \\u0432 \\u0431\\u0430\\u043d\\u044e, \\u0443\\u0432\\u0438\\u0434\\u044f \\u043d\\u043e\\u0432\\u043e\\u0435 \\u043f\\u043b\\u0430\\u0442\\u044c\\u0435 \\u043d\\u0430 \\u043f\\u0430\\u0434\\u0447\\u0435\\u0440\\u0438\\u0446\\u0435. \\u0434\\u043e\\u0447\\u043a\\u0430 \\u0432\\u043f\\u0443\\u0441\\u043a\\u0430\\u0435\\u0442 \\u0432\\u043e\\u043b\\u043a\\u0430 \\u0432 \\u0431\\u0430\\u043d\\u044e, \\u043e\\u043d \\u0441\\u0432\\u0430\\u0442\\u0430\\u0435\\u0442 \\u0435\\u0435 \\u0437\\u0430 \\u0441\\u044b\\u043d\\u0430, \\u0434\\u043e\\u0447\\u043a\\u0430 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442, \\u0447\\u0442\\u043e \\u0443 \\u043d\\u0435\\u0435 \\u043d\\u0435\\u0442 \\u043f\\u0440\\u0438\\u0434\\u0430\\u043d\\u043e\\u0433\\u043e, \\u0441\\u044b\\u043d \\u043f\\u0440\\u0438\\u043d\\u043e\\u0441\\u0438\\u0442. \\u0434\\u0435\\u0432\\u043a\\u0430 \\u043d\\u0438\\u0447\\u0435\\u0433\\u043e \\u043d\\u0435 \\u043c\\u043e\\u0436\\u0435\\u0442 \\u0431\\u043e\\u043b\\u044c\\u0448\\u0435 \\u043f\\u0440\\u043e\\u0441\\u0438\\u0442\\u044c, \\u0432\\u043e\\u043b\\u043a \\u0435\\u0435 \\u0441\\u044a\\u0435\\u0434\\u0430\\u0435\\u0442.\",\n          \"\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0438 \\u043b\\u0438\\u0441\\u0438\\u0447\\u043a\\u0430.\",\n          \"\\u0434\\u0432\\u0430 \\u0431\\u0440\\u0430\\u0442\\u0430.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"4. \\u0436\\u0438\\u043b \\u0434\\u0435\\u0434 \\u0435\\u0430 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u043e\\u0439. \\u043d\\u0438\\u0445 \\u0431\\u044b\\u043b\\u0430 \\u0434\\u0432\\u043e\\u0435 \\u0434\\u044f\\u0442\\u0435\\u0439-\\u0431\\u0430\\u0431\\u043d\\u0438\\u043a\\u0430 \\u0434\\u043e \\u043e\\u0434\\u043d\\u0438\\u043d\\u0430. \\u0441\\u0430\\u0431\\u0440\\u0430\\u043b\\u0438\\u0441\\u044c \\u044f\\u043d\\u044b \\u0432 \\u0434\\u0430\\u0439\\u043d\\u044e \\u043f\\u0430\\u044f\\u0441\\u044b \\u0442\\u043a\\u0430\\u0442\\u044c. \\u0442\\u043a\\u0430\\u043c\\u0438 \\u043f\\u0430\\u044f\\u0441\\u044b, \\u0430 \\u043a \\u043d\\u0435\\u043c \\u0438\\u0434\\u0435 \\u0438 \\u043f\\u0440\\u043e\\u0441\\u0438\\u0442\\u0446\\u0430 \\u043f\\u0430\\u0433\\u0440\\u0435\\u0442\\u0446\\u0430 \\u0432\\u043e\\u043b\\u0445 \\u0441\\u0435\\u0440\\u044b\\u0439. \\u044f\\u043d\\u044b \\u0433\\u0430\\u0432\\u0430\\u0440\\u044f\\u0442, \\u0447\\u0442\\u043e \\u043d\\u0430\\u043c \\u0441\\u043a\\u0443\\u0434\\u0430. \\u0432\\u043e\\u043b\\u043a \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442: \\u00ab\\u043d\\u0443 \\u0445\\u043e\\u0448\\u044c \\u043d\\u0430 \\u043a\\u0430\\u043c\\u0435\\u043d\\u043a\\u0443 \\u043c\\u044f\\u043d\\u044f \\u043f\\u0443\\u0441\\u0442\\u0438\\u0442\\u0435! \\u0442\\u0430\\u043a \\u043d\\u0430 \\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0438 \\u0432\\u043e\\u043b\\u043a\\u0430. \\u0432\\u0441\\u0438 \\u0441\\u0442\\u0430\\u0440\\u0430 \\u043d\\u0438\\u043b\\u0441\\u044f, \\u043a\\u0430\\u043a \\u0442\\u043e\\u0439 \\u0443\\u0432\\u0438\\u0434\\u0430\\u043b\\u0438, \\u0447\\u0442\\u043e \\u043a\\u0430\\u043a \\u0438 \\u043f\\u0430\\u0437\\u0435\\u0432\\u0430\\u0442\\u044c \\u0441\\u0442\\u0430\\u043b, \\u0434\\u044e\\u0436\\u0435 \\u0437\\u0443\\u0431\\u044b \\u0431\\u043e\\u043b\\u044c \\u0431\\u044b\\u043b\\u0438, \\u0430 \\u0441\\u0430\\u043c \\u0432\\u0435\\u0441\\u044c \\u043b\\u0430\\u0432\\u044b\\u0439. \\u0442\\u0430\\u0433\\u0434\\u044b \\u0434\\u0440\\u0443\\u0433\\u0438\\u0435 \\u0441\\u043f\\u0443\\u0433\\u0430\\u043b\\u0438\\u0441\\u044c \\u0434\\u043e\\u043b\\u0438\\u0441\\u0430\\u043b\\u0438 \\u0434\\u0430\\u043c\\u043e\\u0439. \\u043e\\u0441\\u0442\\u0430\\u043b\\u0430\\u0441\\u044c \\u0442\\u043e\\u043b\\u044c \\u0430 \\u0442\\u0430\\u043d\\u044f-\\u0434\\u0435\\u0434\\u043d\\u0438\\u043d \\u0434\\u043e\\u0447\\u043a\\u0430. \\u0442\\u0430\\u0433\\u0434\\u0430 \\u0432\\u043e\\u043b\\u043e\\u0435 \\u043f\\u0440\\u0438\\u0448\\u043e\\u043b \\u043a \\u0434\\u0435\\u0434\\u043a\\u0438\\u043d\\u043e\\u0439 \\u0434\\u0430\\u0446\\u043d\\u0435 \\u0431\\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442: \\u00ab\\u043f\\u0430\\u0439\\u0434\\u0435\\u043d\\u0438\\u0435 \\u0437\\u0430 \\u043c\\u0430\\u0432\\u043e\\u0441 \\u043d\\u0430 \\u0437\\u0430\\u043c\\u0443\\u0433\\u0438? \\u00bb \\u00ab\\u0445\\u043e\\u0441\\u043f\\u0430\\u0434\\u0438, \\u043a\\u0430\\u043a \\u044f \\u043f\\u043e\\u0439 68. \\u0443 \\u043c\\u043e\\u043d\\u044f \\u0440\\u0443\\u0431\\u0430\\u0448\\u043a\\u0438 \\u043d\\u0435\\u0442, \\u043f\\u043b\\u0430\\u0442\\u044c\\u0435\\u0432 \\u043d\\u0435\\u0442 \\u0438 \\u043d\\u0438\\u0447\\u0430\\u0432\\u043e \\u043d\\u0435\\u0442. \\u0442\\u0430\\u0433\\u0434\\u0430 \\u0432\\u043e\\u043b\\u0430 \\u0432\\u0438\\u0442 \\u00ab\\u0431\\u044f\\u0438\\u0441\\u044f \\u0441\\u044b\\u043d \\u043f\\u0430\\u0431\\u044f\\u0433\\u0430\\u0439, \\u0431\\u0443\\u0435 \\u0438\\u0441\\u0430\\u043d\\u0430 \\u043c\\u0430\\u043b\\u0430\\u0434\\u0430\\u044f, \\u043f\\u0440\\u0438\\u043d\\u044f\\u0441\\u0438 \\u0432\\u0430\\u0435 \\u0447\\u0433\\u0430\\u0442\\u044c\\u0435, \\u043a\\u0430\\u0442\\u043e\\u0440\\u0430 \\u0432\\u0447\\u0435\\u0440\\u0430 \\u0441\\u0430 \\u0441\\u0432\\u0430\\u0434\\u044c\\u0431\\u044b \\u043f\\u0430\\u043f\\u0430\\u043b\\u043e\\u0435. \\u0430 \\u0432\\u0440\\u0435\\u043c\\u044f \\u0443\\u0436 \\u043a \\u043f\\u044f\\u0442\\u0446\\u043d\\u0430\\u043c \\u043f\\u0440\\u0438\\u0431\\u043b\\u0438\\u0436\\u0430\\u043b\\u0430\\u0441\\u044c. \\u043f\\u0440\\u0438\\u043d\\u0435\\u0435 \\u0441\\u044b\\u0445 \\u043f\\u043b\\u0430\\u0442\\u044c\\u044f \\u0430 \\u0432\\u043e\\u043b\\u043a \\u0438 \\u0441\\u043f\\u0440\\u0430\\u0448\\u0438\\u0432\\u043e\\u0435\\u0435\\u0442 \\u0430\\u043f\\u044f\\u0442\\u044c: 1 \\u0434\\u0435\\u0448\\u0435 \\u0437\\u043e \\u043c\\u0430\\u0432\\u043e \\u0441\\u044b\\u043d\\u0430 \\u0437\\u0430\\u043b\\u0443\\u0448\\u0435 \\u044f \\u044f\\u043d\\u0430 \\u0430\\u043f\\u044f\\u0442\\u044c \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442\\u044a, \\u0445\\u043e\\u0441\\u043f\\u0430\\u0434\\u0438, 8 \\u043a\\u0430\\u043a \\u0436\\u0435\\u0435 \\u044f \\u043f\\u0430\\u0439\\u0434\\u0443 \\u0443 \\u043c\\u044f\\u043d\\u044f \\u043d\\u0438 \\u043f\\u043e\\u043c \\u0442\\u0430 \\u043d\\u0430 \\u043d\\u0435\\u0443\\u0431\\u044b \\u043d\\u0435\\u0442 \\u0438 \\u043f\\u0438\\u043a\\u0430\\u043a\\u043e\\u0432\\u0430 \\u043f\\u0440\\u0438 \\u0437\\u0430\\u043d\\u0430\\u0432\\u0430 \\u0442\\u0430\\u0433\\u0434\\u0430 \\u0432\\u043e\\u043b\\u0445 \\u043e\\u043f\\u044f\\u0442\\u044c \\u043d\\u0430\\u0447 \\u0432\\u0430\\u044f \\u0441\\u044b\\u043d\\u0430 \\u0438 \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b: \\u0431\\u044f\\u043d\\u0441\\u0438, \\u0441\\u044b\\u043d\\u044a \\u043f\\u0430\\u0431\\u044f\\u0433\\u043e\\u0439, \\u0431\\u0443\\u0434\\u0435 \\u0436\\u0430\\u043d\\u0430 \\u043c\\u0430\\u043b\\u0430\\u0434\\u0430\\u044f, \\u043a\\u0440\\u043e \\u043d\\u044f\\u0441\\u0438 \\u0435\\u0439 \\u0448\\u0443\\u0431 \\u0438 \\u043f\\u0440\\u0438\\u0434\\u0430\\u043d\\u0430\\u0432\\u0430\\u0432\\u0441\\u044f \\u043a\\u0430\\u0432\\u0430. \\u0442\\u043a\\u0430\\u0433\\u0434\\u0430 \\u0432\\u043e\\u043b\\u043a \\u0441\\u043a\\u0440\\u0430\\u0448\\u0438\\u0432\\u0430\\u0435\\u0442 \\u201c\\u043f\\u0430\\u0439\\u0437\\u0435\\u0448\\u044c \\u0437\\u0430\\u043b\\u0438\\u0438\\u0438 \\u0437\\u0430 \\u043c\\u0430\\u043b\\u043e \\u0441\\u044b \\u043d\\u0430\\u00bb \\u0442\\u0430\\u0433\\u0434\\u0430 \\u0434\\u0435\\u0432\\u043a\\u0430 \\u0441\\u0430\\u043c\\u0430\\u0441\\u0438\\u043b\\u0430\\u044f \\u043a\\u043e\\u0433\\u0434\\u0430 \\u043f\\u0430\\u0448\\u043b\\u0438 \\u0447\\u0435\\u0440\\u0435\\u0437 \\u043f\\u043e\\u0440\\u043e\\u0433 \\u0442\\u0430\\u043d\\u0438 \\u0441\\u043a\\u0430\\u0447\\u0430\\u043b\\u0430: \\u201c\\u043b\\u044f\\u0442\\u0443\\u043d\\u044b \\u0437\\u0430\\u043f\\u043e\\u0439\\u0442\\u0435, \\u043a\\u043e\\u043d\\u0438 \\u0437\\u0430\\u0440\\u0436\\u044b\\u0442\\u0435, \\u0437\\u044f\\u043b\\u0438\\u044f \\u0440\\u0430\\u0441\\u043a\\u0430\\u043b\\u0438\\u0441\\u044f \\u0438 \\u0446 \\u0441\\u0441\\u044b\\u043d\\u043e\\u0439 \\u043d\\u0440\\u0430\\u0432\\u0430\\u043b\\u0438\\u0441\\u044f! \\u043f\\u044f\\u0442\\u0443\\u043d\\u044b \\u043f\\u0435\\u043b\\u0438 \\u0438 \\u0446\\u043e\\u0440\\u0442 \\u0435 \\u0441\\u043an\\u043e\\u043b \\u0438 \\u043f\\u0440\\u0430\\u0432\\u0435 \\u043b\\u0438\\u043b\\u0438\\u0441\\u044f \\u0438 \\u0442\\u0430\\u043d\\u0435 \\u0432\\u0441\\u0435 \\u0430\\u0441\\u0442\\u0430\\u043b\\u0430\\u0441\\u044f. \\u0442\\u0430\\u043d\\u044f \\u043f\\u0440\\u0438\\u0448\\u043b\\u0430 \\u0434\\u0430\\u043c\\u043e\\u0439 \\u0438 \\u043b\\u044f\\u0433\\u043b\\u0430 \\u043a \\u0441\\u043f\\u0430\\u0441\\u0442\\u044c. \\u0430 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u0437\\u0430\\u0441\\u043c\\u0430\\u0442 \\u0441\\u0430\\u043b\\u0430\\u0441\\u044c, \\u0447\\u0442\\u043e \\u043f\\u043b\\u0430\\u0442\\u044c\\u0435 \\u0442\\u0430\\u043b\\u043a\\u043e\\u0432\\u0430 \\u043d\\u0430 \\u0447\\u0442\\u0430. \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0430 \\u0438 \\u0435\\u0432\\u0430\\u044e \\u0434\\u0430\\u0446\\u043a\\u0443 \\u0432\\u0437\\u0430\\u0439 \\u043d\\u044e \\u043d\\u0430\\u0441\\u044b\\u043b\\u0430\\u0442\\u044c. \\u043f\\u0430\\u0448\\u043b\\u0430 \\u0438 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0441\\u0438\\u043d\\u0430 \\u0434\\u043e\\u0447\\u0434\\u043a\\u0430 \\u0432 \\u0431\\u0430\\u0439\\u043d\\u044e. \\u043f\\u0440\\u0438\\u0445\\u043e\\u0434\\u0438\\u0442 \\u0435\\u0439 \\u0432\\u043e\\u043b\\u043a \\u0438 \\u043f\\u0440\\u043e\\u0441\\u0438\\u0442\\u0446\\u0430 \\u043d\\u0430\\u0447\\u0430\\u0432\\u0430\\u0442\\u044c. \\u0440\\u0430\\u0431\\u0438\\u043a\\u0430 \\u0434\\u0430\\u0446\\u043a\\u0430 \\u0432\\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0430 \\u044f\\u0433\\u043e. \\u0431\\u043e\\u043b\\u0435 \\u0441\\u0442\\u0430\\u044f \\u0441\\u043f\\u0440\\u0430\\u0448\\u0438\\u0432\\u0430\\u0442\\u044c: \\u00ab\\u043f\\u0430\\u0439\\u0437\\u0435\\u0448\\u0435 \\u0441\\u043e \\u043c\\u0430\\u0432 \\u0441\\u044b\\u043d\\u0430 \\u0437\\u0430\\u043a\\u0443\\u043b\\u0438\\u00bb. \\u0430 \\u044f\\u043d\\u0430 \\u0438 \\u0441\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442: \\u00ab\\u043a\\u0430\\u043a \\u044f \\u043f\\u0430\\u0441\\u0438\\u0434\\u0443, \\u0443 \\u043c\\u044f\\u043d\\u044f \\u043d\\u0438\\u0446\\u0430\\u0432\\u0430 \\u043d\\u0435\\u0442. \\u0432\\u043e\\u043b\\u043a \\u043f\\u0430\\u0441\\u043b\\u0430\\u044f \\u0441\\u044b\\u043d\\u0430 \\u043d\\u043e \\u043f\\u0440\\u0438\\u0437\\u0430\\u043d\\u044b\\u043c. \\u0442\\u0435\\u0433\\u0433\\u0434\\u0430 \\u0441\\u043f\\u0440\\u0430\\u0448\\u044b \\u043d\\u0430\\u0441\\u0442 \\u0430\\u043f\\u044f\\u0442\\u044c: \\u201c\\u043f\\u0430\\u0439\\u0434\\u0435\\u0448\\u044c \\u0437\\u0430\\u043c\\u0443\\u0448. \\u044f\\u043d\\u0430 \\u0441\\u0430\\u0433\\u043b\\u0430\\u0441\\u0438\\u043b\\u0430\\u0441\\u044c. \\u043a\\u0430\\u043a \\u043f\\u0430\\u0448\\u043b\\u0438 \\u0432\\u0440\\u0435\\u044f\\u043f\\u0430\\u0440\\u044b, \\u044f\\u043d\\u0430 \\u043d\\u0435 \\u0443\\u043c\\u0435\\u043b\\u0430\\u043d\\u0438 \\u043e\\u0432 \\u0441\\u043a\\u0430\\u0437\\u0430\\u0442\\u044c \\u0438 \\u0432\\u043e\\u043b\\u043a \\u0435\\u0435 \\u0441\\u0447\\u0435\\u043b \\u043a \\u0441\\u0430\\u043d\\u043a\\u0438 (\\u0437\\u0443\\u0431\\u044b) \\u043d\\u0430 \\u0430\\u043a\\u043d\\u043e \\u043f\\u0430\\u043b\\u0430 \\u043d\\u044b\\u043b. \\u0441\\u0442\\u0430\\u0440\\u0446\\u043a\\u0430 \\u043f\\u0430\\u0434\\u0435\\u0442, \\u0434\\u0430\\u0446\\u043a\\u0438 \\u043d\\u0435 \\u0437\\u0430\\u043f\\u043e\\u0437\\u0430\\u0442\\u0446\\u0430. \\u0438\\u0434\\u0435 \\u043f\\u0430\\u0448\\u0438\\u043c\\u0430 \\u0430\\u043a\\u043e\\u043c\\u0438 \\u0438 \\u0432\\u0438\\u0434\\u0438\\u0442 \\u0447\\u0443\\u0431\\u044b \\u0438 \\u0433\\u0430\\u0432\\u0430\\u0440\\u0438\\u0442: \\u043f, \\u0432\\u0438\\u0434\\u043d\\u044f \\u0441\\u043c\\u0435\\u0441\\u0442\\u0446\\u0430, \\u0447\\u0442\\u043e \\u0434\\u0430\\u0431\\u0440\\u0430 \\u043c\\u043d\\u043e\\u0433\\u0430 \\u043f\\u0430\\u043a\\u0443\\u0446\\u0438\\u043b\\u0430. \\u0432\\u0430\\u0448\\u043b\\u0430 \\u0432 \\u0437\\u0430\\u0439\\u043d\\u044e, \\u0430 \\u0442\\u0430\\u043c \\u0430\\u0434\\u043d\\u0438 \\u0445\\u043e\\u0441\\u0442\\u0430\\u0446\\u043a\\u0438 \\u0438 \\u0437\\u0430\\u043f\\u043b\\u0430\\u043a\\u0430\\u043b\\u0430 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u0437\\u0430 \\u043f\\u043e\\u0437\\u043d\\u0430\",\n          \"30. \\u0436\\u0438\\u043b\\u0438 \\u0434\\u0432\\u0430 \\u043c\\u043e\\u043b\\u044c\\u0446\\u0430, \\u0434\\u044e\\u0436\\u0430 \\u043e\\u043d\\u044b \\u0441\\u0434\\u0440\\u0443\\u0436\\u0438\\u0432\\u0448\\u0438 \\u0431\\u044b\\u043b\\u0438. \\u0443\\u0431\\u043b\\u0438\\u0448\\u0430\\u043c\\u0441\\u044f \\u0434\\u0440\\u0443\\u0433 \\u0434\\u0440\\u0443\\u0436\\u043a\\u0438 \\u043a\\u043e\\u0433\\u0434\\u044b \\u0436\\u0430\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f \\u0441\\u0442\\u0430\\u043d\\u0443\\u0442\\u044c \\u2014 \\u043f\\u043e\\u0437\\u0432\\u0430\\u0442\\u044c \\u0434\\u0440\\u0443\\u0433 \\u0434\\u0440\\u0443\\u0433\\u0441\\u043a\\u0443 \\u043d\\u0430 \\u0441\\u0432\\u0430\\u0434\\u044c\\u0431\\u0443 \\u0436\\u0438\\u043b\\u0438 \\u043c\\u044b \\u0430\\u0438\\u043b\\u0438, \\u0432\\u0434\\u0440\\u0443\\u0433 \\u043e\\u0434\\u0438\\u043d \\u0438\\u043d\\u0438\\u0445 \\u0437\\u0430\\u0431\\u043e\\u043b\\u0435\\u044f \\u0438 \\u043f\\u043e\\u043c\\u0435\\u0440. \\u0437\\u0430\\u0434\\u0443\\u043c\\u0430\\u044f \\u0434\\u0440\\u0443\\u0433\\u043e\\u0439 \\u0436\\u0430\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f. \\u0441 \\u0441\\u0432\\u0430\\u0448\\u0430\\u044f \\u043c\\u043d\\u043d\\u0443\\u044e \\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0438. \\u0437\\u0434\\u0443\\u0442 \\u043f\\u043e\\u0432\\u0435\\u043d\\u0447\\u0430\\u0448\\u044c\\u0441\\u044f. \\u0430 \\u0445\\u0430\\u0442\\u044c \\u0432\\u0446\\u0435\\u0440\\u043a\\u0432\\u0443 \\u043d\\u0430\\u0434\\u043e \\u0431\\u044b\\u043b\\u043e \\u043a\\u0443\\u043d \\u0445\\u043b\\u0430\\u0434\\u0431\\u0438\\u0448\\u0448\\u0430 \\u0441\\u043a\\u0430\\u043c\\u0438\\u0445 \\u0438 \\u0441\\u043f\\u043e\\u043b\\u0435\\u043d\\u0438\\u0435\\u043f\\u0440\\u043e \\u0448\\u0435\\u0432\\u0430 \\u0434\\u0440\\u0443\\u0433\\u0430 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0448\\u044c \\u0441\\u0432\\u043e\\u0435\\u0439 \\u0442\\u0435\\u0432\\u0435\\u0441\\u0442\\u044b: \\u043f\\u043e\\u0441\\u0434\\u0438 \\u0442\\u0443\\u0442\\u0430 \\u043c\\u0430\\u043b\\u0435\\u043d\\u044c \\u043a\\u043e, \\u044f \\u0441\\u043a\\u0430\\u043f\\u0443 \\u043a \\u0442\\u043e\\u0432\\u0430\\u0440\\u0438\\u0448\\u043c\\u0443 \\u043c\\u043e\\u0433\\u044b\\u043b\\u0443, \\u043f\\u043e\\u043f\\u0440\\u0430\\u0448\\u043c\\u0430\\u044e\\u0441\\u044f \\u0441 \\u043d\\u043c. \\u0441\\u043a\\u0430\\u0437\\u0430\\u043b \\u0442\\u043e\\u0439 \\u044d\\u0442\\u043e\\u0435, \\u0441\\u043b\\u0435\\u0433 \\u0441 \\u043d\\u044f\\u0438 \\u043f\\u043e\\u0448\\u0435\\u043b \\u043d\\u0430 \\u043a\\u043b\\u0430\\u0434\\u044c\\u0438\\u0448 \\u0448\\u0435. \\u0438\\u0434\\u0435 \\u043a \\u043c\\u0430\\u043b\\u044b\\u043b\\u044b \\u0438 \\u0432\\u0438\\u0434\\u044f: \\u0441\\u0438\\u0434\\u0438\\u0442\\u044c \\u044f\\u0432\\u043e\\u043d\\u043e\\u0432 \\u0434\\u0440\\u0443\\u0433 \\u043d\\u0430\\u043c \\u044b\\u043b\\u044b \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c: : \\u201c\\u0437\\u043d\\u0430\\u044e, \\u0437\\u043d\\u0430\\u044e, \\u0448\\u0442\\u043e \\u0442\\u044b \\u0436\\u0435\\u043d\\u0438\\u0448\\u044c\\u0441\\u044f. \\u043c\\u043e\\u043b\\u043e\\u0434\\u0435\\u043d, \\u0448\\u0442\\u043e \\u043f\\u0440\\u0438\\u0448\\u0435\\u043b \\u043d\\u0430 \\u0432\\u0435\\u0434\\u044b\\u0442\\u044c \\u043c\\u0435\\u043d\\u044f. \\u043d\\u043e\\u0441\\u0438\\u0434\\u0435 \\u0434\\u043e\\u0463 \\u043c\\u0430\\u043b\\u0435\\u043d\\u044c\\u043a\\u043e, \\u043f\\u043e\\u043f\\u0440\\u043e\\u0448\\u0430\\u043b\\u0441\\u044f \\u0441 \\u0434\\u0440\\u0443\\u0433\\u043e\\u043c \\u0438 \\u043e\\u043f\\u044f\\u0442\\u044c \\u043f\\u043e\\u0448\\u0435\\u043b \\u043d\\u0430 \\u0434\\u0430\\u0440\\u043e\\u0433\\u0443, \\u0433\\u0434\\u0435 \\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b \\u0441\\u0432\\u0430\\u044e \\u0448\\u0435\\u0432\\u0435\\u0441\\u0442\\u0443 \\u0438 \\u0432\\u0435\\u0441\\u044c \\u0432\\u0430\\u0434\\u0435\\u0431\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0435\\u0437\\u0430. \\u0432\\u044b\\u0445\\u043e\\u0434\\u044f \\u043d\\u0430 \\u0434\\u0430\\u0440\\u043e\\u0433\\u0443: \\u043d\\u0430, \\u0448\\u0442\\u043e \\u044d\\u0442\\u043e, \\u043d\\u0435\\u0442\\u0443\\u0442\\u0438 \\u043d\\u0438 \\u0448\\u0435\\u0432\\u0435\\u0441\\u0442\\u044b, \\u043d\\u0438 \\u0442\\u043e\\u0435\\u0437\\u0434\\u0430 \\u0441\\u0432\\u0430\\u0434\\u0435\\u0439\\u043d\\u043e\\u0432\\u0430. \\u0448\\u0441\\u0442\\u043e \\u0442\\u0430\\u043a\\u043e \\u043a\\u0443\\u0434\\u044b \\u043d\\u0435 \\u043c\\u044b \\u0434\\u0430\\u043c\\u0430\\u0435! \\u043f\\u043e\\u0448\\u0435\\u043b \\u0442\\u043e\\u0439 \\u0432 \\u0441\\u0432\\u0430\\u044e \\u0434\\u0435\\u0440\\u0435\\u0432\\u043d\\u044e, \\u043f\\u0440\\u0438\\u0445\\u043e\\u0434\\u044f \\u043a \\u043e\\u043d\\u043d\\u043e\\u043c \\u0434\\u043e\\u043c\\u0443, \\u0430 \\u0442\\u0430\\u043c\\u0430 \\u043d\\u0430 \\u0437\\u0430\\u0432\\u043e\\u043b\\u0438\\u043d\\u043a\\u0438 \\u043d\\u0430\\u0440\\u043e\\u0434 \\u0441\\u043e\\u0431\\u0440\\u0430\\u0432\\u0448\\u0438 \\u0431\\u044b\\u043b \\u0438 \\u0441\\u043f\\u0440\\u0430\\u0441\\u044b\\u0432\\u0430\\u043b \\u0438\\u0445: \\u201c\\u0433\\u0434\\u0435 \\u043c\\u0430\\u044f \\u0442\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430, \\u043d\\u0435 \\u0432\\u0438\\u0434\\u0430\\u043b \\u0445\\u0442\\u043e! \\u0430 \\u043d\\u0430\\u0440\\u043e\\u0434 \\u043a\\u0440\\u0443\\u0433\\u043e\\u043c \\u043a\\u0430\\u043a \\u0437\\u0430\\u0441\\u043d\\u044f\\u0435\\u0442\\u0441\\u044f: \\u201c\\u043a\\u0430\\u043a\\u0430 \\u0442\\u0430\\u043a\\u0430 \\u0442\\u0432\\u0430\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0442\\u0430, \\u0441\\u0430\\u043c \\u0432 \\u043c\\u0430\\u0433\\u044b\\u043b\\u0443 \\u0433\\u043b\\u043e\\u0434\\u0438\\u0448\\u044c, \\u0434\\u0435\\u0440\\u0443\\u0448\\u043a\\u0430, \\u0430 \\u0436\\u0430\\u043d\\u0438\\u0442\\u044c\\u0441\\u044f \\u0445\\u043e\\u0447\\u0438\\u0448\\u044c? \\u043d\\u0438\\u0447\\u0430\\u0432\\u043e \\u0442\\u043e\\u0433 \\u043d\\u0435\\u043e \\u0441\\u0442\\u0430\\u043b \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0442\\u044c \\u043a\\u0430\\u043a \\u0442\\u043e\\u0439 \\u0435\\u0430\\u043b \\u0432\\u043e\\u043d\\u0447\\u0430\\u0442\\u044c\\u0441\\u044f \\u0438 \\u043f\\u043e \\u0434\\u043e\\u0440\\u043e\\u0433\\u0438 \\u0437\\u0430\\u0435\\u0445\\u0430\\u044f \\u043d\\u0430 \\u043a\\u043b\\u0430\\u0434\\u0431\\u0438\\u0448\\u0448\\u0435, \\u0430 \\u0442\\u0435\\u0432\\u0435\\u0441\\u0442\\u0443 \\u043d\\u0430 \\u0434\\u0430\\u0440\\u043e\\u0433\\u0438 \\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b \\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u0437\\u043e\\u0439 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b, \\u043a\\u0430\\u043a \\u043f\\u043e\\u0434 \\u0445\\u043e\\u0434\\u044f \\u043a \\u0435\\u043c\\u0443 \\u0441\\u0442\\u0430\\u0440\\u0443\\u0445\\u0430 \\u2014 \\u043b\\u0435\\u0442 80 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0448\\u044c: \\u0430\\u0445, \\u0434\\u0435\\u0434\\u0443\\u0448\\u043a\\u0430, \\u0430 \\u0432\\u0435\\u0434\\u044c \\u044d\\u0442\\u043e \\u044f \\u0442\\u0432\\u0430\\u044f \\u043d\\u044f\\u0432\\u0435\\u0441\\u0442\\u0430. \\u043d\\u0435 10 \\u043c\\u0438\\u043d\\u0443\\u0442 \\u0442\\u044b \\u0431\\u044b\\u043b \\u043d\\u0430 \\u043a\\u043b\\u0430\\u0434\\u0431\\u0438\\u0448\\u043c\\u0438, \\u0430 60 \\u0433\\u043e\\u0434. \\u0442\\u0443\\u0442 \\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u0437\\u043e\\u043d \\u0437\\u0430\\u043c\\u0435\\u0442\\u0438\\u043b, \\u0448\\u0442\\u043e \\u0441\\u0442\\u0430\\u0440\\u0438\\u043a, \\u0432\\u0435\\u0441\\u044c \\u043f\\u043e\\u0441\\u044f\\u0434\\u0435\\u0432\\u0448\\u0438\\u0438 \\u0438 \\u0441\\u0433\\u043e\\u0440\\u044c\\u0438\\u0432\\u0448\\u0438. \\u043f\\u0435\\u0440\\u0435\\u043d\\u0443\\u0436\\u0430\\u043b\\u0441\\u044f \\u0442 \\u0438 \\u0442\\u0433\\u0438 \\u0436\\u0430 \\u043f\\u043e\\u043c\\u0435\\u0440.\",\n          \"6. \\u0448\\u0438\\u0441 \\u0446\\u0430\\u0440\\u044c. \\u0431\\u044b\\u043b\\u043e \\u0432\\u043d\\u0438\\u0432\\u043e \\u0442\\u0440\\u0438 \\u0441\\u044b\\u043d\\u0430, \\u0438\\u0437\\u0432\\u0430\\u043b\\u0438 \\u043d\\u0435 \\u0432\\u0441\\u0438\\u0435: \\u0432\\u0430\\u043d\\u043e\\u0448\\u043a\\u0430\\u043c\\u0438. \\u0437\\u0430\\u0431\\u043e\\u043b\\u0435\\u043b \\u0446\\u0430\\u0440\\u044c \\u0438 \\u0441\\u0435\\u043c\\u044c \\u0433\\u043e\\u0434 \\u043e\\u0436\\u0435 \\u0431\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0438 \\u043d\\u0438\\u0441\\u0442\\u043e \\u043d\\u0435 \\u043c\\u043e\\u0433 \\u0435\\u0433\\u043e \\u0432\\u044b\\u043b\\u044b\\u0447\\u0438\\u0442\\u044c. \\u0440\\u0430\\u0437 \\u0441\\u0430\\u0441\\u043d\\u0438\\u043b\\u0441\\u044f \\u044f\\u0448\\u0443 \\u0441\\u043e\\u043d: \\u043a\\u0430\\u043d\\u043e\\u0439 \\u0442\\u043e \\u0433\\u043e\\u043b\\u043e\\u0435 \\u0433\\u043e\\u0432\\u0430\\u0440\\u0438\\u0442\\u044c \\u0435\\u043c\\u0443: \\u201c\\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u043f\\u0442\\u0438\\u0446\\u0430 \\u0444\\u0438\\u043d\\u0438\\u043a\\u0435 \\u043c\\u043e\\u0433\\u044f \\u0442\\u043e\\u0431\\u0435, \\u043a\\u0430\\u043b\\u0438 \\u0443\\u0441\\u043b\\u044b\\u0448\\u0438\\u0448\\u044c \\u043a\\u0430\\u043a \\u043d\\u043e\\u0435, \\u0442\\u043e\\u0433\\u0434\\u044b \\u0438 \\u043d\\u0430\\u043f\\u0440\\u0430\\u0432\\u0438\\u0448\\u044c\\u0441\\u044f! \\u043f\\u0430\\u0441\\u043b\\u0430\\u043b \\u0446\\u0430\\u0440\\u044c \\u0441\\u0432\\u0430\\u0432\\u043e \\u0441\\u0442\\u043e\\u0440\\u0448\\u043e\\u0432\\u043e \\u0441\\u044b\\u043d\\u0430 \\u0437\\u0430 \\u0442\\u0438\\u0435\\u0434\\u043d\\u043e\\u0439 \\u0444\\u0438\\u043d\\u0438\\u043d\\u0441\\u043e\\u0439. \\u0432\\u0437\\u043b\\u0438 \\u0435\\u043d \\u0440\\u0443\\u0436\\u044c\\u0435 \\u0438 \\u043d\\u043e\\u0448\\u0435\\u043b. \\u0448\\u0435\\u043b, \\u0448\\u0430\\u0435 \\u0438 \\u0441\\u0438 \\u0434\\u043e \\u0441\\u043e\\u0440\\u043e\\u043d\\u043e\\u0432\\u043e\\u0432\\u0430 \\u0431\\u043e\\u0440\\u0430. \\u0432\\u0434\\u0440\\u0443\\u0433 \\u0431\\u044f\\u0442\\u0438\\u0448\\u044c \\u043d\\u0430\\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0443 \\u0435\\u043c\\u0443 \\u043c\\u043d\\u0438\\u0446\\u0430 \\u0438 \\u043f\\u0440\\u044b\\u0447\\u044b\\u0442\\u044c \\u0447\\u0438\\u043b\\u0430\\u0432\\u0435\\u0447\\u044c\\u0438\\u043c \\u0433\\u043e\\u043b\\u043e\\u0441\\u043e\\u043c: \\u0442\\u044b \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0437\\u0430\\u0447\\u0438\\u043c \\u0438\\u0434\\u0435\\u0448\\u044c? \\u0443\\u0431\\u0430\\u0437\\u043b\\u0438\\u043b\\u0441\\u044f \\u0435\\u043d\\u0443 \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c: \\u0430 \\u0442\\u0435\\u0431\\u0435 \\u043d\\u0430\\u043a\\u043e \\u0434\\u0435\\u043b\\u043e, \\u0438 \\u0431\\u0430\\u043b \\u0438 \\u0432\\u044b\\u0441\\u0442\\u0440\\u0430 \\u0432 \\u0435\\u043d\\u0443, \\u0430 \\u043b\\u0438\\u0448\\u0438\\u0446\\u0430, \\u0442\\u043e \\u0432\\u0435\\u0440\\u0442\\u044c \\u043a\\u0432\\u043e\\u0441\\u0442\\u043e\\u044f \\u0438 \\u0443\\u0431\\u0435\\u0433\\u043b\\u0430. \\u0443\\u0441\\u043b\\u044b\\u0448\\u0430\\u043b\\u0438 \\u044f\\u0432\\u043e\\u043d\\u0441\\u044c \\u0432\\u044b\\u0441\\u0442\\u0440\\u0435\\u043b \\u0440\\u0430\\u0431\\u043e\\u0442\\u043d\\u0438\\u043a\\u0438, \\u043a\\u043e\\u0442\\u043e \\u0441\\u0442\\u043e\\u0440\\u043e\\u043f\\u043b\\u0438 \\u044d\\u0442\\u043e\\u0442 \\u0431\\u043e\\u0440, \\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0438 \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430 \\u0438 \\u043f\\u043e\\u0441\\u0430\\u0434\\u0438\\u043b\\u0438 \\u0432 \\u0434\\u044b\\u0440\\u043a\\u0443 6 \\u0434\\u0435\\u0440\\u0435\\u0432\\u043e. \\u0446\\u0430\\u0440\\u044c \\u043f\\u0435\\u0434\\u0430\\u043b, \\u0436\\u0434\\u0430\\u043b \\u0441\\u044b\\u043d\\u0430, \\u043d\\u0435 \\u0438\\u0434\\u0435 \\u0435\\u0439, \\u043f\\u043e\\u0441\\u043b\\u0430\\u043b \\u043e\\u0433\\u043e \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430 \\u0434\\u043e\\u0441\\u0442\\u0430\\u043c\\u0435\\u0442\\u044c \\u043f\\u0442\\u0438 \\u043f\\u043e\\u0448\\u0435\\u0439 \\u0431\\u044b, \\u0434\\u043e\\u0448\\u0435\\u0435 \\u0434\\u043e \\u0441\\u043e\\u0440\\u043e\\u043d\\u043e\\u0432\\u043e\\u0432\\u0430 \\u0431\\u043e\\u0440\\u0443, \\u0441\\u0442\\u0440\\u044f\\u0447\\u0430\\u044f \\u043b\\u0438\\u0441\\u0443, \\u0430 \\u0435\\u043d\\u0430 \\u043e\\u043d\\u044f\\u0442, \\u043a\\u0430\\u0432\\u043e, \\u0442\\u044b \\u0446\\u0430\\u0440\\u0435\\u0432\\u043d\\u0447, \\u0445\\u043e\\u0442\\u044c \\u0437\\u0430\\u0441\\u0442\\u0440\\u0435\\u0435\\u043b\\u0438\\u0442\\u044c \\u0430 \\u0435\\u0439 \\u0435\\u0439 \\u043d\\u0435 \\u0448\\u0432\\u0430\\u0432\\u043e \\u0447\\u0442\\u043e \\u0443\\u0436\\u0435 \\u0434\\u0435\\u043b\\u043e, \\u043d\\u043e \\u0448\\u0442\\u043e \\u0448\\u0435\\u0431\\u0435 \\u044d\\u0442\\u043e\\u0435 \\u0437\\u043d\\u0430\\u0442\\u044c, \\u0443\\u0431\\u0438\\u0440\\u0430\\u043b\\u0441\\u044f. \\u0432\\u043d\\u0435\\u043b \\u0434\\u0430 \\u0438 \\u0432\\u044b\\u0441\\u0442\\u0440\\u0438\\u043b\\u0438\\u0441\\u044c \\u0432 \\u0435\\u043d\\u0443. \\u0438 \\u0435\\u0432\\u043e\\u0448\\u0438\\u043b\\u0438 \\u0440\\u0430\\u0431\\u043e\\u0442\\u043d\\u0438\\u043a\\u0438. \\u043d\\u0430\\u0441\\u0442\\u0430\\u043b \\u0447\\u0435 \\u0440\\u0435\\u0434 \\u043d\\u0430\\u0441\\u043b\\u0435\\u0434\\u043d\\u0435\\u0432\\u0430 \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430 \\u0434\\u043e\\u0441\\u0442\\u043e \\u0442\\u043d\\u0438\\u0446\\u0443 \\u0444\\u0435\\u043d\\u0435\\u043a\\u0443. \\u043f \\u0448\\u0435\\u0435 \\u0432\\u0430\\u043d\\u0433\\u043e\\u0448\\u043d\\u043e-\\u0434\\u0443\\u0440\\u0430\\u0447\\u043e\\u043a. \\u043f\\u043e\\u0434\\u0445\\u043e \\u0434\\u044f \\u043a \\u0442\\u043e\\u043c\\u0443 \\u043d\\u0435 \\u0441\\u043e\\u0440\\u043e\\u043d\\u043e\\u0432\\u043e\\u043c\\u0443 \\u0431\\u043e\\u0440\\u0443, \\u0432 \\u0432\\u0435\\u0433\\u0430\\u044f \\u0438 \\u0435\\u043c\\u0443 \\u043b\\u0438\\u0441\\u0446\\u0430 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c. \\u0446\\u0430\\u0440\\u0435\\u0432 \\u0441\\u044b\\u043d, \\u043a\\u0443\\u0434\\u044b \\u0438 \\u0437\\u0430\\u0447\\u0438\\u043c \\u043d\\u0443\\u0442\\u044c \\u0434\\u0435\\u0440\\u0436\\u0438\\u0448\\u044c. \\u0430 \\u0432\\u0430\\u043d\\u044e\\u0448\\u043d\\u0430- \\u0434\\u0443\\u0440\\u0430\\u0447\\u043e\\u043d \\u0438 \\u0443\\u0442\\u0438\\u0432\\u044f\\u0447\\u0430\\u044f \\u0435\\u0439 \\u201c\\u0430\\u043a \\u043b\\u0438\\u0441\\u044b\\u043d\\u044c\\u043a\\u0430, \\u0430\\u0442\\u0435\\u0446 \\u043c\\u043e\\u0439 \\u0434\\u044e\\u043e\\u0436\\u0430 \\u0431\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439, \\u043d\\u0438\\u0441\\u0442\\u043e \\u043d\\u0435\\u043c\\u043e \\u0438\\u044f \\u044f\\u0432\\u043e \\u043f\\u0430\\u0437\\u0430\\u043b\\u0438\\u0442\\u044c. \\u0441\\u0430\\u0441\\u043d\\u0438\\u043b\\u0441\\u044f \\u0435\\u043c\\u0443 \\u0441\\u043e\\u043d, \\u043a\\u0430\\u043c \\u0443\\u0441\\u043b\\u044b\\u0448\\u0430 \\u0435\\u0439 \\u0442\\u0442\\u0438\\u0434\\u0443 \\u0438\\u043d\\u0438\\u043d\\u0441\\u0443 - \\u043f\\u043e\\u043d\\u0440\\u0430\\u0432\\u0438\\u0442\\u0441\\u044f. \\u0442\\u0430\\u0439 \\u0432\\u043e\\u0439 \\u044f \\u0438 \\u0438\\u0434\\u0443 \\u0434\\u043e\\u0441\\u0442\\u0430\\u043c\\u0435\\u0442\\u044c \\u044d\\u0442\\u0443\\u044e \\u043f\\u0442\\u0438\\u0446\\u043a\\u0443. \\u0430, \\u0432\\u0430\\u0448\\u043e\\u043b\\u0435\\u043d\\u0430, \\u0442\\u0440\\u0443\\u043d\\u043d\\u043e \\u0442\\u0435\\u0431\\u0435 \\u0430\\u043d\\u043d\\u0430\\u043c\\u0438 \\u0434\\u043e\\u0441\\u0442\\u0430\\u0442\\u044c \\u043e\\u043d\\u0443, \\u0441\\u0438\\u0434\\u0438\\u0442\\u044c \\u043e\\u043d\\u0430 \\u0437\\u0430 9\\u043c \\u043c\\u043e\\u0440\\u044f\\u043c, \\u0437\\u0430 9 \\u0442\\u0438\\u043c \\u0437\\u0430\\u043c\\u043b\\u044f\\u043c \\u0432 \\u0434\\u0435\\u0441\\u044f\\u0442\\u043e\\u043c \\u0434\\u0430\\u0440\\u044c\\u0441\\u0442\\u0432\\u0438. \\u044f \\u043f\\u043b\\u0435\\u0431\\u0435 \\u043c\\u043e\\u0433\\u0443: \\u201c\\u0438\\u0445, \\u043b\\u0438\\u0441\\u044b\\u043d\\u044c\\u043a\\u0430, \\u0432\\u0441\\u0435 \\u0448\\u0442\\u043e \\u044e\\u0442\\u044c \\u0432\\u0430\\u0442\\u044c\\u043c \\u043f\\u0442\\u0438 \\u043c\\u0435\\u043d\\u044f, \\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u0441\\u0432\\u044f\\u0434\\u0438 \\u043c\\u043b\\u044b\\u044f \\u0438 \\u044d\\u0442\\u043e\\u0439 \\u0442\\u0438\\u0438\\u0446\\u044b. \\u0432\\u043e\\u0442 \\u0438 \\u043f\\u043e\\u0448\\u043b\\u0438 \\u0435\\u043d\\u044b; \\u0448\\u043b\\u0438, \\u0448\\u043b\\u0438 \\u0438 \\u043f\\u0440\\u0438\\u0448\\u043b\\u0438. \\u0430 6 \\u044d\\u0442\\u044b\\u0438\\u043c \\u0446\\u0430\\u0440\\u044c\\u0441\\u0442\\u0432\\u0438 \\u043e\\u0448\\u043b\\u0438 \\u0442\\u0440\\u0438 \\u0442\\u043d\\u0438\\u0446\\u044b. \\u0438\\u0442\\u0438\\u0446\\u0430 \\u0436\\u0430\\u0440, \\u0445\\u0430\\u043b\\u0443\\u044f\\u043d \\u0438 \\u0442\\u043d\\u0438\\u0446\\u0430 \\u0444\\u0438\\u043d\\u0438\\u043a\\u0441\\u0430 \\u043f\\u0442\\u0438\\u0446\\u0430 \\u0436\\u0430\\u0440 \\u0435\\u0439 \\u0434\\u0438\\u0448\\u044c \\u0432 \\u0437\\u043e\\u043b\\u043e\\u0442\\u043e\\u0439 \\u043a\\u043b\\u0435\\u0448\\u043a\\u0438, \\u0442\\u043f\\u0438\\u0446\\u0430 \\u043a\\u0430\\u043c\\u043d\\u0435\\u043a \\u0432 \\u0441\\u0435\\u0440\\u0435\\u0431\\u0432\\u0438\\u043d\\u044b\\u0435, \\u0430 \\u0442\\u043f\\u0438\\u0446\\u0430 \\u0440\\u0438\\u043d\\u0438\\u043d\\u0441\\u0430 \\u0432 \\u0443\\u0433\\u0430\\u0440\\u044b\\u0448\\u043d\\u043e\\u0439. \\u0432\\u043e\\u0442 \\u043b\\u0438 \\u0441\\u0438 \\u0438 \\u043d\\u0430\\u0441\\u0442\\u0430\\u043b\\u0441\\u044f \\u0432\\u0430\\u0442\\u043e\\u0448\\u043a\\u0443 \\u043d\\u0430\\u0439 \\u0441\\u044f \\u0442\\u044b, \\u0437\\u0430\\u043d\\u044f, \\u0432 \\u0438\\u0442\\u0438\\u0435\\u043d\\u0438\\u043a\\u0438, \\u043a\\u0430\\u0440 \\u043c\\u0438\\u044c \\u0438\\u0445! \\u043d\\u0430\\u043d\\u044f\\u043b\\u0441\\u044f, \\u0432\\u043d\\u0435\\u043b\\u0438 \\u0435\\u0432\\u043e. \\u043f\\u043e \\u0448\\u0435\\u0435 \\u0434\\u0438 \\u043a\\u0430\\u0440\\u043c\\u0438\\u0442\\u044c \\u0448\\u043f\\u0438\\u0445. \\u0437\\u0430\\u0445\\u043e \\u043f\\u043e\\u0442\\u0435\\u043b\\u044c\\u0441\\u044f \\u0435\\u043c\\u0443 \\u043f\\u0438\\u0440\\u0438\\u043c\\u0435\\u043d\\u0438\\u0442\\u044c \\u0432 \\u0438\\u0442\\u043a\\u043b\\u0435\\u0448\\u043a\\u0438: \\u0445\\u043e\\u0442\\u0435\\u0439 \\u043f\\u0442\\u0438\\u0446\\u0443 \\u0444\\u0438 \\u043d\\u0438\\u043d\\u0441\\u0443 \\u043f\\u043e\\u0441\\u0430\\u0434\\u0438\\u0442\\u044c \\u0432 \\u0437\\u043e\\u043b\\u043e\\u0442\\u0443\\u044e \\u043a\\u043b\\u0435\\u0434\\u043a \\u0438 \\u0432\\u043e\\u0440\\u0443\\u0433 \\u043a\\u0430\\u043a \\u0437\\u0430\\u0432\\u0446\\u0435, \\u0433\\u0430\\u0432\\u043e\\u043d\\u044f \\u0432\\u0435\\u0437\\u0434\\u0435 \\u043f\\u0440\\u0438\\u0431\\u0435\\u0433\\u043b\\u0438 \\u043b\\u044e\\u0434\\u0438, \\u0441\\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0438 \\u044f\\u0432\\u043e \\u0438 \\u043f\\u043e\\u0441\\u0430\\u0434\\u0438\\u043b\\u0438 \\u0432 \\u0442\\u0435\\u043c\\u043d\\u0438\\u0446\\u0443. \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0434\\u043e\\u043f\\u0440\\u0430\\u0448\\u0438\\u0432\\u0430\\u0442\\u044c: \\u0437\\u0430\\u0447\\u0438\\u043c \\u0432\\u0430\\u0440\\u0443\\u0435\\u0448\\u044c \\u0447\\u0443\\u0442\\u0438\\u0445 \\u0448\\u0442\\u0443. \\u0430\\u0435\\u0439 \\u043d\\u0438 \\u0441\\u0440\\u0430\\u0431\\u0435\\u043b \\u0438 \\u043e\\u0440\\u044f\\u043a; \\u043f\\u044f\\u0442\\u0438\\u043d\\u044c\\u043a\\u0430 \\u0432 \\u043c\\u043d\\u044f \\u0434\\u0433\\u043e\\u0436\\u0430 \\u0431\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439, \\u043d\\u0438\\u0441\\u0442\\u043e \\u043d\\u0435 \\u043c\\u043e\\u0433\\u044f \\u0432\\u044b\\u043b\\u0438\\u0447\\u0438\\u0442 \\u0441\\u0430\\u0441\\u043d\\u0438\\u043b\\u0441\\u044f \\u0435\\u043c\\u0443 \\u0441\\u043e\\u043d \\u0438\\u0447\\u0442\\u043e \\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u043f\\u0442\\u0438\\u0446\\u0430 \\u0444\\u0438\\u043d\\u0438\\u043a\\u0441\\u044f \\u0441\\u043d\\u0430\\u0441\\u0435 \\u044f\\u0432\\u043e. \\u0432\\u043e\\u0442 \\u044f \\u0438 \\u0437\\u0430\\u0434\\u0443\\u043c\\u0430\\u0435 \\u0434\\u0430\\u0441\\u0442\\u0430\\u0442\\u044c \\u044d\\u0442\\u0443\\u044e \\u0438\\u0446\\u0443. \\u043f\\u0430\\u0434\\u0438\\u043c\\u0430\\u043b\\u0438, \\u043d\\u0430\\u0434\\u0443\\u043c\\u0430\\u043b\\u0438 \\u0435\\u043d\\u044b \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u044f: \\u0443\\u0436\\u0434\\u0430\\u0434\\u0438\\u043c\\u044a \\u043f\\u0438\\u0435\\u0431\\u0435 \\u044d\\u0442\\u0443\\u044e\\u043e \\u0444\\u0438\\u043d\\u0438\\u043a\\u0441\\u0443, \\u043a\\u043e\\u043b\\u044c \\u0434\\u043e\\u0441\\u0442\\u0430\\u043d\\u0435\\u0448\\u044c \\u043d\\u0430\\u043c \\u0432\\u0443-\\u043d\\u0435\\u0441\\u0442\\u0432\\u0443\\u044e \\u0445\\u043e\\u0431\\u044b\\u0435\\u043a\\u0443\\u00bb \\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u0438\\u043b\\u0441\\u044f \\u0432\\u0430\\u0442\\u043e\\u043c\\u043a\\u0430 \\u0438 \\u0432\\u044b\\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0438 \\u0435\\u0432\\u043e \\u043d\\u0430 \\u0432\\u043e \\u043b\\u044e. \\u043f\\u043e\\u0448\\u0435\\u0435 \\u0432\\u0430\\u043f\\u044e\\u0448\\u043a\\u0430 \\u0438 \\u0441\\u0432\\u043e\\u0435\\u0439 \\u043c \\u0441\\u0438\\u0447\\u043a\\u0438 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b \\u0435\\u0439 \\u043f\\u0440\\u043e \\u0441\\u0432\\u043e\\u044e \\u0437\\u0430 \\u0434\\u0430\\u0447\\u0443. \\u201c\\u043d\\u0438\\u0447\\u0430\\u0432\\u043e, \\u0431\\u0430\\u0442\\u043e\\u0448\\u043a\\u0430, \\u043d\\u0438 \\u0433\\u0430\\u0440\\u0433\\u043e\\u0439, \\u0434\\u0430\\u0441\\u0442\\u0430\\u043d\\u0438\\u043c \\u044d\\u0442\\u0443\\u0433 \\u043a\\u0430\\u0431\\u044b\\u043b\\u0443. \\u0442\\u044b \\u043e\\u043d\\u0430\\u0439\\u043c\\u0438\\u0441\\u044f \\u043b\\u043e\\u0448\\u0430\\u0434\\u043d\\u0438\\u043a\\u043e\\u043c \\u2014 \\u043a\\u043e\\u0440\\u043c\\u0438\\u0442\\u044c \\u043b\\u043e\\u0448\\u0430\\u0434\\u0435\\u0439, \\u0430 \\u0442\\u0430\\u043c \\u0432\\u0438\\u043d\\u043d\\u043e \\u0431\\u0443\\u0434\\u044f \\u0448\\u0442\\u043e \\u0435\\u043b\\u0430\\u0442\\u044c \\u0434\\u0430\\u043b\\u0435\\u0439. \\u043f\\u043e\\u0431\\u0435\\u043b\\u0438 \\u043e\\u043d\\u044b \\u0432\\u043c\\u0448\\u0435\\u0441\\u0442\\u0435\\u0439, \\u0431\\u0435\\u0433\\u043b\\u0438, \\u0431\\u0435\\u0433\\u043b\\u0438\\u0432\\u0438 \\u043f\\u0440\\u0438\\u0431\\u0435\\u043b\\u0438. \\u043d\\u0430\\u043d\\u0435\\u043b\\u0441\\u044f \\u043d\\u044f \\u043a\\u043e\\u043d\\u044e\\u0445\\u043e\\u043c. \\u0432\\u0430\\u0448\\u0435\\u043b \\u0432 \\u043a\\u0430\\u0442\\u043e\\u043c\\u043d\\u044e \\u0438 \\u0432\\u0438\\u0434\\u044f \\u0441\\u0442\\u0430\\u0438\\u0442\\u044c\\u0442\\u0440\\u0438 \\u043a\\u0430\\u043d\\u044f\\u0435. \\u0434\\u0432\\u0430 \\u043d\\u044f \\u0441\\u0442\\u0430\\u044f \\u0432 \\u0437\\u043e\\u043b\\u043e\\u043a\\u0430\\u0445 \\u0443\\u0437\\u0434\\u0435\\u0447\\u043d\\u0430\\u0445, \\u0430 \\u043e\\u0440\\u0430\\u0442\\u044c\\u044f\\u0441\\u0438\\u0432\\u0430 \\u043d\\u0435\\u0441\\u0442\\u0440\\u0430 \\u0432 \\u043f\\u0440\\u043e\\u0441\\u0442\\u043e\\u043c \\u0440\\u0435\\u043c\\u044f\\u043d\\u043d\\u043e\\u043c. \\u043f \\u0432\\u0430\\u043d\\u044f \\u0438 \\u0434\\u0443\\u043c\\u0430\\u044f: \\u201c\\u0438\\u043d\\u044c\\u044e \\u043d\\u0435 \\u044f \\u0431\\u0443 \\u0445\\u0430\\u0440\\u043e\\u0448\\u0435\\u0439 \\u0432\\u043e\\u0440\\u043e\\u0432\\u0430\\u0442\\u044c, \\u0434\\u0430\\u0439 \\u043a\\u0430 \\u043f\\u0435\\u0440\\u0435\\u043c\\u044f\\u043d\\u044e \\u0438 \\u0438 \\u0443\\u0437\\u0434\\u044b, \\u043d\\u0430\\u0434\\u0435\\u043d\\u044f \\u0435\\u0439 \\u0437\\u043e\\u043b\\u043e\\u0448\\u0443\\u044e! \\u0445\\u0432\\u0430\\u0447\\u0438\\u044f \\u0435\\u0439 \\u0437\\u0430 \\u0434\\u043e\\u043b\\u043e\\u0448\\u0443\\u044e \\u0443\\u0437\\u043b\\u044f \\u043a\\u0430\\u0439 \\u043d\\u0430\\u0434\\u044b\\u043c\\u0438\\u0442\\u0441\\u044f \\u0432\\u0434\\u0440\\u0443\\u0433 \\u0437\\u0432\\u043e\\u0439, \\u0448\\u0446\\u0431 \\u0437\\u0430 \\u0433\\u0430\\u043c, \\u043a\\u0430\\u043a \\u043f\\u043e\\u043d\\u0430\\u0431\\u0435\\u0433\\u043b\\u043e \\u043b\\u044e\\u0434\\u0435\\u0439 \\u0441\\u043e \\u0432\\u0441\\u0438\\u0445 \\u0443\\u0433\\u043b\\u043e\\u0432. \\u0441\\u0445\\u0432\\u0430\\u0442\\u0438\\u043b\\u0438 \\u044f\\u043d\\u044b \\u0431\\u0430\\u0442\\u043e\\u0448\\u043a\\u0443 \\u043f\\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0434\\u0430\\u043f\\u0440\\u0430\\u0445\\u044b\\u0432\\u0430\\u0442\\u044c, \\u0435\\u043d \\u0432\\u0441\\u0435 \\u0438\\u043c \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b. \\u0434\\u043b\\u044f \\u0447\\u0430\\u0432\\u043e \\u043a\\u0430\\u043d\\u044f \\u043a\\u0440\\u0430\\u043b\\u0435. \\u0430 \\u0435\\u043c\\u0443 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u044f: \\u201c\\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0438 \\u043d\\u0430\\u043c \\u0430\\u043b\\u0435\\u043a\\u0443 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441 \\u043d\\u0443\\u0442\\u043e\\u0433\\u0434\\u044b \\u0438 \\u0443\\u0436\\u0434\\u0430\\u0434\\u0438\\u043c \\u0442\\u0435\\u0431\\u0435 \\u043a\\u0430 \\u043d\\u044f. \\u043e\\u043f\\u044f\\u0442\\u044c \\u043f\\u043e\\u0431\\u043e\\u0433\\u043b\\u0438 \\u0435\\u043d\\u044b \\u0435 \\u043b\\u0438\\u0441\\u0438\\u0446\\u0435\\u0439 \\u0434\\u043e\\u0441\\u0442\\u0430\\u043b\\u044f\\u0442\\u044c \\u044f\\u043b\\u0435\\u043d\\u0443 \\u043f\\u0440\\u0430\\u043a\\u0440\\u0430\\u0441\\u043d\\u0443\\u044e. \\u0442\\u0443\\u0436 \\u0442\\u043e\\u043b\\u0438\\u0441\\u0430 \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c: \\u044f\\u043b\\u0435\\u043d\\u0430 \\u043f\\u0440\\u044f\\u043a\\u043d\\u0430\\u043b \\u043c\\u0430\\u044f \\u0441\\u044f\\u0441\\u0442\\u0440\\u0430, \\u043c\\u0435\\u043d\\u044f \\u0438 \\u0441\\u0435\\u0442\\u0440 \\u043e\\u0442\\u0441\\u0443\\u0435 \\u043c\\u0430\\u0442\\u0438\\u0446\\u0435\\u0439 \\u043f\\u0440\\u043e\\u043a\\u043b\\u044f\\u043d\\u0443\\u043b\\u0438. \\u043c\\u044f \\u043d\\u044f \\u0443\\u0431\\u0430\\u0440\\u0430\\u0442\\u0438\\u043b\\u0438 \\u043b\\u0438\\u0441\\u0438\\u0446\\u043a\\u043e\\u0439, \\u0430 \\u0441\\u043b\\u0435\\u0442\\u0443 \\u0437\\u043e\\u0440\\u0433\\u0438 \\u0443\\u0436\\u0435. \\u044f \\u0437\\u043d\\u0430\\u044e \\u0433\\u0434\\u0435 \\u043f\\u0440\\u043e\\u0436\\u0438\\u0432\\u0430\\u044f \\u043c\\u0430\\u044f \\u0441\\u043e\\u0441\\u0442\\u0440\\u0430, \\u043d\\u0430\\u0439\\u0434\\u0435\\u043c. \\u043f\\u0430\\u0448\\u043b\\u0438. \\u043f\\u043e\\u0434\\u0445\\u043e\\u0434\\u044e\\u0442 \\u0438 \\u043a\\u0440\\u0430\\u0441\\u0438\\u0432\\u043e\\u043c\\u0443 \\u043d\\u0430\\u0434\\u0443, \\u0432\\u0438\\u0434\\u044e\\u0442\\u044c \\u043b\\u043b\\u0435\\u043d\\u0430 \\u043f\\u0440\\u043e\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0430\\u044f \\u0433\\u0443\\u043b\\u044f\\u044f \\u043f\\u043e \\u0441\\u0430\\u0434\\u0443 \\u0441\\u043e \\u0441\\u0432\\u043e\\u0438\\u043c \\u043f\\u043e\\u0434\\u043d\\u0443\\u0442\\u0435\\u043d\\u044c\\u043a\\u0430\\u043c. \\u0445\\u0430\\u0434\\u0438\\u043b\\u0430 \\u0435\\u0430 \\u0445\\u0430\\u0434\\u0438\\u043b\\u0430 \\u043f\\u043e \\u0441\\u0430\\u0434\\u043e\\u0446\\u043a\\u0443, \\u0437\\u0430\\u043c\\u0443\\u0449\\u0438\\u043b\\u0430\\u0441\\u044f, \\u0441\\u0435\\u043b\\u0430 \\u043d\\u0435 \\u043b\\u0430\\u0432\\u043e\\u0446 \\u0443\\u0443\\u0436\\u0440\\u0430\\u0441\\u043d\\u0443\\u0442\\u044c, \\u0430 \\u043d\\u0430\\u0434\\u0440\\u0443\\u0436\\u0435\\u043d\\u044c\\u043a\\u0438 \\u0441\\u0430\\u0442\\u044c \\u043e\\u0434 \\u043f\\u0443\\u0441\\u0442\\u043e\\u043a \\u043c\\u0435\\u0433\\u043b\\u0438. \\u0442\\u044b\\u043c \\u0432\\u0440\\u0435\\u043c\\u0435\\u043d\\u0435\\u043c \\u043d\\u0430\\u0434\\u043a\\u0440\\u0430\\u043b\\u0441\\u044f \\u0434\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0438 \\u0445\\u043b\\u0435\\u043d\\u044b \\u043f\\u0440 \\u0440\\u0430\\u043c\\u043e\\u0439 \\u043f\\u043e\\u0434\\u0445\\u0432\\u0430\\u0448\\u0438\\u043b \\u044f\\u043d\\u0443 \\u0438 \\u043d\\u0430\\u0431\\u0435\\u0433\\u0438 \\u043c\\u0438\\u043d\\u044b. \\u043b\\u0438\\u0441\\u0438\\u0446\\u0430 \\u0434\\u0430\\u043b\\u0430 \\u0435\\u043c\\u0443 \\u0448\\u0435\\u0440\\u0435\\u0442\\u044c \\u0438 \\u043a\\u043e\\u043b\\u044c\\u0448\\u043e\\u0446\\u043a\\u0443 \\u0438 \\u043d\\u0430\\u0431\\u0435\\u0433\\u0438 \\u044f\\u043d\\u043e \\u0434\\u0430\\u043b\\u0435\\u0439. \\u0442\\u044b\\u043c \\u0432\\u0440\\u0435\\u043c\\u0438\\u043d\\u0438\\u043c \\u043a\\u0440\\u0430\\u0441\\u043d\\u0443\\u043b\\u0441\\u044f \\u043d\\u0430\\u0434\\u0440\\u0443\\u0436 \\u043d\\u0438\\u0445\\u0432\\u0430\\u0442\\u0438\\u043c\\u0441\\u044f \\u0430 \\u044f\\u043b\\u0435\\u043d\\u044b \\u0442\\u043e \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430 \\u043d\\u0438 \\u043d\\u0435\\u0442\\u0443\\u0442\\u0438. \\u043f\\u0430\\u0431\\u0435\\u0433\\u043b\\u0438 \\u043c\\u044b \\u0443 \\u0434\\u0430\\u0433\\u043e\\u043d\\u044f\\u0442\\u044c \\u043d\\u0445, \\u0441\\u0430\\u0432\\u0441\\u0438\\u043c \\u0431\\u043b\\u0438\\u0437\\u043a\\u043e, \\u0443 \\u043d\\u0435 \\u0434\\u0430\\u0433\\u043e\\u043d\\u044f\\u044e\\u0442\\u044c, \\u0448\\u043e\\u0433\\u0434\\u044b \\u0432\\u0430\\u043d\\u0433\\u043e\\u0448\\u0430. \\u0432\\u0438\\u043d\\u0443\\u0438 \\u0448\\u0435\\u0440\\u0435\\u0448\\u044c \\u0438 \\u0441\\u0442\\u0430\\u043b\\u0435 \\u0434\\u0440\\u0438\\u043c\\u0443 \\u043b\\u0435\\u0435. \\u043d\\u0430\\u0434\\u0440\\u0443\\u0436\\u0441\\u043a\\u0438 \\u0443\\u0431\\u0435\\u0440\\u043d\\u0443\\u043b\\u0438\\u0441\\u044f 6 \\u0448\\u0430\\u043a\\u0430\\u0440\\u044b \\u0438 \\u0434\\u0430\\u0432\\u0430\\u0439 \\u0440\\u0443\\u0431\\u0438\\u0448\\u044c \\u044d\\u0442\\u043e\\u0433 \\u043b\\u0435\\u0435. \\u0431\\u0443\\u0431\\u0438\\u043b\\u0438 \\u0440\\u0443\\u0431\\u0438\\u043b\\u0438 \\u0438 \\u0432\\u044b\\u0440\\u0435\\u0437\\u0431\\u0438\\u043b\\u0438, \\u0438 \\u0430\\u043f\\u044f\\u0442\\u044c \\u043f\\u043e\\u0431\\u0435\\u0433\\u043b\\u0438 \\u0441\\u0437\\u0430\\u0434\\u0443. \\u0442\\u0430\\u0433\\u0434\\u044b \\u0431\\u0440\\u043e\\u0441\\u0438\\u043b \\u0432\\u0430\\u043d\\u044f \\u043a\\u0430\\u0441\\u044b\\u043f\\u043e\\u0446\\u043a\\u0443 \\u0438 \\u0440\\u0430\\u0437\\u043b\\u0438 \\u043b\\u043e\\u0441\\u044f \\u043c\\u043e\\u0440\\u0435, \\u0433\\u043b\\u0443\\u0431\\u043e\\u043a\\u043e\\u0435, \\u043c\\u0438\\u043d\\u0435\\u0435. \\u0443\\u0431\\u0435\\u0440\\u043d\\u0443\\u043b\\u0438\\u0441\\u044f \\u043d\\u0430\\u0434\\u0440\\u0443\\u0436\\u043a\\u044b \\u0432 \\u0447\\u0430\\u043b\\u043d\\u044b \\u0438 \\u0434\\u0430\\u0432\\u0430\\u0439 \\u043f\\u0435\\u0440\\u0435\\u043f\\u043b\\u044b \\u0432\\u0430\\u0448\\u044c \\u043c\\u043e\\u0440\\u0435. \\u0434\\u0430 \\u043d\\u0435 \\u0442\\u0438\\u0437\\u0438\\u0438 \\u0442\\u043e \\u0431\\u044b\\u043b\\u043e, \\u043d\\u0435 \\u043f\\u0435\\u0440\\u0435\\u0438\\u043b\\u044b\\u0448\\u044c \\u0438\\u043c \\u0442\\u0430\\u043a\\u043e \\u0431\\u0430\\u043b\\u044c\\u0448\\u043e \\u043c\\u043e\\u0440\\u0436\\u0438\\u0438 \\u0438 \\u0434\\u043e \\u043c\\u0435 \\u043f\\u043e\\u0442 \\u0430\\u043b\\u0438\\u0448\\u0435 \\u0435\\u0432\\u043e \\u043f\\u0435\\u0440\\u0435\\u043f\\u043b\\u044b\\u0432\\u0430\\u044e \\u0438 \\u0432\\u0430\\u043d\\u0433\\u043e\\u0448\\u0430 \\u0441 \\u0435\\u043c\\u043d\\u043e\\u0439 \\u0438 \\u043c\\u0438\\u0441\\u043e\\u0439 \\u0443\\u0431\\u0435\\u0433\\u043b\\u0438 \\u043f\\u0440\\u0438\\u0431\\u0435\\u0433\\u043b\\u0438 \\u0442\\u0443\\u0434\\u044b, \\u0433\\u0434\\u0435 \\u043a\\u043e\\u043d\\u044c \\u0431\\u044b\\u043b \\u043f\\u0435\\u0441\\u0442\\u0440\\u0430 \\u043d\\u0430\\u0431\\u044b\\u043b\\u043a\\u0430. \\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u0438 \\u0438\\u0432\\u0430\\u043d-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0430\\u043b\\u0435\\u043a\\u0443 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0443\\u044e \\u0432 \\u0441\\u0430\\u0441\\u0435\\u043d\\u043d\\u0435\\u043c \\u043c\\u0435\\u0441\\u043a\\u0443 \\u043f\\u043e\\u0448\\u0435\\u0441 \\u043e\\u0434\\u0438\\u043d \\u0438 \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c: \\u201c\\u043d\\u0440\\u0438\\u0432\\u0435\\u0447, \\u044f \\u0432\\u0430\\u043c \\u044f\\u043b\\u0435\\u043d\\u0443 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0443\\u044e, \\u0434\\u0430 \\u0434\\u0438\\u043e\\u0436\\u0430 \\u0437\\u0430\\u043c\\u043e\\u0440\\u0438\\u043b\\u0438\\u0441\\u044c \\u043c\\u043d\\u0430, \\u043d\\u0435 \\u0437\\u0434\\u043e\\u043c\\u044f\\u044f \\u0431\\u043e\\u043b\\u044c\\u0448\\u0438 \\u0438\\u0442\\u0442\\u0438\\u0448\\u044c, \\u0434\\u0430\\u0439\\u0448\\u0435 \\u0435\\u0439 \\u043a\\u043e\\u043d\\u044c\\u043a\\u0430, \\u043d\\u0430\\u0435\\u043b\\u0438 \\u044f\\u043d\\u0430 \\u0438 \\u043f\\u0440\\u0438\\u0441\\u0434\\u044f \\u0438 \\u0432\\u0430\\u043c\\u201d \\u043f\\u043e\\u0432\\u0435\\u0440\\u0438\\u043b\\u0438 \\u0435\\u043c\\u0443, \\u0434\\u0430\\u043b\\u0438 \\u0441\\u0438\\u0432\\u0443 \\u2014 \\u043f\\u0435\\u0441\\u0442\\u0440\\u0443 \\u043d\\u0430\\u0431\\u044b\\u043b\\u0443 \\u0438 \\u043d\\u043e\\u0432\\u0435\\u043b \\u0438\\u0432\\u0430\\u043d-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u044d\\u0442\\u0443\\u0433 \\u043d\\u0430 \\u0431\\u044b\\u043c\\u0443 \\u0432 \\u043b\\u0435\\u0441\\u043e\\u043a, \\u0433\\u0434\\u0435 \\u043c\\u043b\\u0435\\u043d\\u044f \\u0434\\u043e\\u0436\\u0438 \\u043f\\u0434\\u0430\\u043b\\u0430\\u0441\\u044f. \\u043f\\u043e\\u0441\\u0430\\u0434\\u043d\\u043e\\u0435 \\u044f\\u043d\\u0443 \\u043d\\u0435 \\u043b\\u043e\\u0448\\u0430\\u0434\\u043d\\u044b \\u0441\\u0435\\u0435 \\u0441\\u0430\\u043c \\u0435 \\u0435\\u0439 \\u0438 \\u043f\\u043e\\u0435\\u0445\\u0430\\u043b\\u0438 \\u043c\\u044b \\u0434\\u043e\\u0441\\u0442\\u0430\\u043c\\u0435\\u0442\\u044c \\u043f\\u0438\\u043b\\u0438\\u0437\\u0443 \\u0444\\u0438\\u043d\\u0438\\u043d\\u0441\\u0446 \\u043f\\u043e\\u0434\\u044a\\u0435\\u0445\\u0430\\u043b\\u0438 \\u0438 \\u043e \\u0434\\u0432\\u043e\\u0440\\u0446\\u0443 \\u043f\\u043e\\u0434\\u043a\\u0440\\u0430\\u043b\\u0441\\u044f \\u0438\\u0432\\u0430\\u043d-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u0438 \\u043e\\u043a\\u043d\\u0443 \\u0438 \\u0432\\u0438\\u0434\\u044f: \\u043a\\u0443\\u043b \\u0441\\u0430\\u043c\\u043e\\u0432\\u043e \\u043e\\u0447\\u043d\\u0430 \\u0432\\u0438\\u0441\\u0438\\u0442\\u044c \\u0437\\u043e\\u043b\\u043e\\u0448\\u0430\\u044f \\u0438\\u043b\\u0435\\u0436\\u043a\\u0430, \\u0430 \\u0432 \\u0435\\u0439 \\u0432\\u0438\\u043d\\u0438\\u043a\\u0435. \\u0441\\u0445\\u0432\\u0430\\u0442\\u0438\\u043b \\u0435\\u0439 \\u044d\\u0442\\u0443\\u0433\\u043e \\u043f\\u043b\\u0435\\u0442\\u043a\\u0443 \\u043d \\u0438 \\u0433\\u0440\\u0430\\u0431\\u043d\\u0438\\u0438 \\u0431\\u0435\\u0436\\u0430\\u0442\\u044c. \\u0441\\u0435\\u0439 \\u043d\\u0430 \\u0441\\u0438\\u0432\\u0443 \\u043d\\u0435\\u0441\\u0442\\u0440\\u0443 \\u043d\\u0430\\u0431\\u044b\\u043b\\u043a\\u0443 \\u0438 \\u043d\\u0430\\u0441\\u0445\\u0430\\u043b\\u0438 \\u043c\\u044b \\u0441\\u0445\\u043b\\u0435\\u043d\\u043e\\u0439 \\u043f\\u0440\\u0435\\u043f\\u0440\\u0430\\u0441\\u043d\\u043e\\u0439 \\u0438 \\u0441 \\u043b\\u0438\\u0441\\u043e\\u0439 \\u0434\\u0430\\u043b\\u0435\\u0439. \\u043e\\u0434\\u0443\\u0442\\u044c \\u043c\\u043d\\u044b \\u0435\\u0434\\u0443\\u0442\\u044c \\u0441\\u0442\\u0440\\u043e\\u0447\\u0430\\u044e\\u0442\\u044c \\u0431\\u0440\\u0430\\u0448\\u0435\\u0439\\u043d\\u0438\\u043a\\u043e\\u0432 \\u0438\\u0432\\u0430\\u043d\\u0430 \\u0434\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430. \\u0438\\u043b\\u0438 \\u043c\\u043d, \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b \\u0438\\u0432\\u0430\\u043d \\u0434\\u043e\\u0440\\u0435\\u0432\\u0438\\u0447 \\u043d\\u043e\\u0439 \\u0435\\u0439 \\u043f\\u043e\\u043d\\u0438\\u0443 \\u0440\\u0438\\u043f\\u0438\\u043d\\u0441\\u0430 \\u0434\\u043e\\u0441\\u0442\\u0430\\u043b, \\u043f\\u043e\\u0434\\u0438\\u0432\\u0438\\u043b\\u0438\\u0441\\u044f \\u0431\\u0440\\u0430\\u0442\\u044c\\u044f. \\u043c\\u0435\\u0433\\u043b\\u0438 \\u0441\\u043d\\u0430\\u0442\\u044c \\u043d\\u043e\\u0447\\u044c\\u044e \\u0431\\u0440\\u0430\\u0442\\u044c\\u044f \\u0438 \\u0443\\u0431\\u0438\\u043b\\u0438 \\u0438\\u0432\\u0430\\u043d\\u0430 \\u044f\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430, \\u043f\\u043e\\u043b\\u043e\\u0436\\u0438\\u043b\\u0438 \\u044f\\u0432\\u043e \\u043f\\u043e\\u0434\\u043a \\u0437\\u0438\\u043d\\u043a\\u0443, \\u0432\\u0437\\u0435\\u043c \\u044f\\u043b\\u0435\\u043c\\u0443 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0443\\u044e, \\u043c\\u044c\\u044f \\u2014 \\u043f\\u0441\\u0442\\u0440\\u0435\\u0442 \\u043a\\u0430\\u0431\\u044b\\u043b\\u043a\\u0443, \\u0438\\u0433\\u0438\\u0446\\u043a\\u0438 \\u0444\\u0438\\u043d\\u0438\\u043d\\u0441\\u044f \\u0438 \\u043f\\u0435\\u0441\\u0430\\u043b\\u0438. \\u0432 \\u043b\\u0438\\u0441\\u0438\\u0435\\u043a\\u0430 \\u0442\\u043e \\u0441\\u043f\\u0440\\u044f\\u0442\\u0430\\u0432\\u0448\\u0438\\u0441\\u044c \\u0431\\u044b\\u043b\\u0430, \\u0432\\u0441\\u0435 \\u0438 \\u0432\\u0438\\u0434\\u043b\\u0430 \\u043f\\u043e\\u0434\\u0431\\u0435\\u0433\\u043b\\u0430 \\u043e\\u043d\\u0430 \\u043a \\u043a\\u043e\\u043b\\u043e\\u0434\\u0438\\u043d\\u043a\\u0438. \\u0432\\u044b \\u0442\\u0430\\u0448\\u0448\\u0438\\u043b\\u0430 \\u0430\\u0442\\u0442\\u0443\\u043b\\u044c \\u0438\\u0432\\u0430\\u043d\\u0438\\u0435-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430, \\u0432\\u044b\\u043d\\u0443\\u043b\\u0430 \\u0435 \\u043d\\u0430\\u0434\\u0443\\u0445\\u0438 \\u0448\\u043b\\u0435\\u043d\\u043a\\u0443 \\u0441 \\u0432\\u0430\\u0434\\u043e\\u0439, \\u043f\\u043e\\u043f\\u0440\\u044b\\u0441\\u043a\\u0430\\u043b\\u0430 \\u043d\\u043e \\u0438\\u0432\\u0430\\u043d\\u0438\\u0435 \\u0434\\u0433\\u0440\\u0435\\u0432\\u0438\\u0447\\u0430 \\u0438 \\u0430\\u043f\\u0441\\u0438\\u043b\\u0441\\u044f \\u0435\\u0439. \\u043f\\u043e\\u0431\\u0435\\u0448\\u0438 \\u043c\\u044b \\u0434\\u043e\\u0433\\u043e\\u043d\\u0435\\u0448 \\u0431\\u0440\\u0430\\u0448\\u0435\\u0439\\u043d\\u0438\\u043a\\u043e\\u0432 \\u043f\\u043e \\u0441\\u043b\\u0435\\u0434\\u0430\\u043c. \\u0438 \\u043f\\u0440\\u0438\\u0432\\u0435\\u043b\\u0438 \\u0441\\u043b\\u043e\\u0434\\u044b \\u043a \\u0430\\u043d\\u0438\\u0437\\u043e\\u0432\\u0441\\u043a\\u043e\\u043c\\u0443 \\u0434\\u043e\\u043c\\u0443 \\u043d\\u0445 \\u0430\\u0433\\u043d\\u0441\\u0443. \\u0430 \\u044f\\u043b\\u0435\\u043d\\u0430 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u0430\\u044f \\u043d\\u0435\\u0432\\u0435\\u0441\\u0435\\u043b\\u0430\\u044f \\u0441\\u0438\\u0434\\u0438\\u0442\\u044c, \\u043f\\u0442\\u0438\\u0446\\u0430 \\u0444\\u0438\\u043d\\u0438\\u043a \\u0441\\u0430\\u0432\\u0438\\u043c \\u043d\\u0435 \\u043d\\u043e\\u0435, \\u0441\\u0430\\u0432\\u0441\\u0435\\u043c \\u043a\\u0430\\u043a \\u0431\\u0435\\u0448\\u044b\\u0446\\u0440\\u0435\\u043a \\u0441\\u0434\\u0435\\u043b\\u0430\\u0432\\u0448\\u0438 \\u0438 \\u0445\\u043e\\u043d\\u044c \\u043c \\u0437\\u0434\\u044b\\u0445\\u0430\\u044f. \\u043a\\u0430\\u043a \\u0442\\u043e\\u043b\\u044c\\u043a\\u0438 \\u0438\\u0432\\u0430\\u043d \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u044f \\u0432\\u043e\\u0448\\u0435\\u043b \\u0432\\u043e \\u0434\\u0432\\u043e\\u0440 \\u044f\\u043b\\u0435\\u043d\\u0430 \\u043f\\u0440\\u043e\\u043a\\u0440\\u0430\\u0441\\u043d\\u0430\\u044f \\u0440\\u0430\\u0437\\u0432\\u043d\\u0430\\u044f\\u043b\\u0438\\u043b\\u0430\\u0441\\u044f, \\u0444\\u0430\\u043d\\u0438\\u043a\\u0441\\u0430 \\u0437\\u0430\\u043d\\u0435\\u043b\\u0430, \\u043a\\u043e\\u043d\\u044c \\u0437\\u0430\\u0440\\u0436\\u0430\\u043b. \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b \\u0432\\u0435\\u0435 \\u0438\\u0432\\u0430\\u043d-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0447 \\u043e\\u0442\\u0446\\u0443: \\u043a\\u0430\\u043a \\u0435\\u044e \\u043e\\u0441\\u0442\\u0430\\u043b\\u0441\\u044f \\u0444\\u0438\\u0448\\u0435\\u043a\\u0443 \\u0438 \\u043a\\u0430\\u043f \\u0431\\u0440\\u0430\\u0442\\u0435\\u0439 \\u043d\\u0438\\u043a\\u0438\\u043e\\u0432\\u043e \\u0443\\u0431\\u0438\\u043b\\u0438 \\u0438, \\u043a\\u0430\\u043a \\u0435\\u0432\\u043e \\u043b\\u0438\\u0441\\u0438\\u0446\\u043a\\u0430 \\u0443\\u0436\\u0438\\u0432\\u0438\\u043b\\u0430. \\u0442\\u0443\\u0433\\u0438 \\u0441\\u0442\\u0430\\u043b\\u0438 \\u0432\\u0441\\u0435 \\u0437\\u0430 \\u043b\\u0438\\u0441\\u0438\\u0446\\u043a\\u043e\\u0439 \\u0443\\u0441\\u0430\\u0436\\u0438\\u0432\\u0430\\u0442\\u044c, \\u0430 \\u043c\\u0430 \\u0442\\u043e\\u043d\\u0446\\u0446\\u0430 \\u0438\\u0432\\u0430\\u043d\\u0430-\\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0446\\u0443 \\u0443\\u0442\\u0440\\u0443\\u0431\\u0438 \\u043c\\u043d\\u0435 \\u0433\\u0430\\u043b\\u043e\\u0432\\u043a\\u0443 \\u00ab\\u043d\\u0435, \\u043b\\u0438\\u0441\\u044c\\u043d\\u044c\\u043a\\u043e, \\u0437\\u0430 \\u0448\\u0442\\u043e \\u2014 \\u043d\\u0435 \\u044f \\u0442\\u043e\\u0431\\u044f \\u0438\\u0437\\u0431\\u0438\\u0442\\u044c \\u0442\\u043e \\u0442\\u044b \\u0442\\u0430\\u0439 \\u043c\\u043d\\u043e\\u0433\\u043e \\u043c\\u043d\\u0435 \\u0434\\u0430\\u0431\\u0440\\u0430 \\u0441\\u0434\\u0435\\u043b\\u0430\\u043c\\u0430\\u00bb. \\u0438 \\u044f\\u043d\\u0430 \\u0432\\u0441\\u0435 \\u043f\\u0440\\u0438\\u0441\\u0442\\u043e\\u0435, \\u0443\\u0442 \\u0438 \\u0434\\u0430 \\u0443\\u0442\\u0440\\u0443\\u0431\\u0438. \\u043d\\u0443 \\u0438 \\u0443\\u0442\\u0440\\u0443\\u0431\\u0438\\u0438 \\u0435\\u0439 \\u0438\\u0432\\u0430\\u043d-\\u0446\\u0430\\u0440\\u0435\\u0432\\u043d\\u0438 \\u0433\\u0430\\u043b\\u043e\\u0432\\u043a\\u0443 \\u0438 \\u0432\\u0434\\u0440\\u0443\\u0433 \\u0441\\u043c\\u043e\\u0442\\u0440\\u044f: \\u0437\\u0430\\u0430\\u043c\\u0435\\u0435\\u0442 \\u043b\\u0438\\u0441\\u044b-\\u0442\\u043e \\u0446\\u0438\\u043b\\u0430\\u0432\\u0435\\u043a \\u0443\\u0431\\u0440\\u0430\\u0437\\u0430\\u0432\\u0430\\u0432\\u0448\\u0438. \\u0438 \\u0441\\u0442\\u0430\\u043b \\u044d\\u0442\\u043e\\u0442\\u0446\\u0438 \\u043b\\u0430\\u0432\\u0435 \\u0432\\u0435\\u0440\\u043d\\u044b\\u043c \\u0441\\u043b\\u0443\\u0433\\u043e\\u0439 \\u0438\\u0432\\u0430\\u043d\\u0443 \\u0446\\u0430\\u0440\\u0435\\u0432\\u0438\\u0446\\u044f.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_parent\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = train_df.copy()\n",
        "test_df = test_df.copy()\n",
        "\n",
        "train_df[\"labels\"] = train_df[\"labels\"].apply(clean_label_list)\n",
        "test_df[\"labels\"]  = test_df[\"labels\"].apply(clean_label_list)\n",
        "\n",
        "TEXT_COLS = [c for c in [\"summary_norm\", \"text_norm\"] if c in train_df.columns]\n",
        "\n",
        "X_train = train_df[TEXT_COLS].copy()\n",
        "X_test  = test_df[TEXT_COLS].copy()\n",
        "\n",
        "y_train = mlb.transform(train_df[\"labels\"])\n",
        "y_test  = mlb.transform(test_df[\"labels\"])\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test :\", X_test.shape,  \"y_test :\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbk_UAr1AS5C",
        "outputId": "28dc570e-6d45-4bd4-c82c-c43549e8d0d1"
      },
      "id": "dbk_UAr1AS5C",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (40, 2) y_train: (40, 37)\n",
            "X_test : (10, 2) y_test : (10, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = set(l for labs in train_df[\"labels\"] for l in labs)\n",
        "test_labels  = set(l for labs in test_df[\"labels\"] for l in labs)\n",
        "unknown_in_test = sorted(test_labels - train_labels)\n",
        "\n",
        "print(\"Labels only in test (will be ignored by mlb):\", len(unknown_in_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvLaCCYKAaxt",
        "outputId": "8697e57b-8ea3-4378-8eb2-4fb455e23a6e"
      },
      "id": "rvLaCCYKAaxt",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels only in test (will be ignored by mlb): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature extraction and multi-label classifier (TF-IDF + One-vs-Rest Logistic Regression)\n",
        "\n",
        "This block defines the **final text-based baseline model** as a single scikit-learn `Pipeline` that (i) converts textual inputs into numerical features and (ii) trains a **multi-label** classifier over ATU types.\n",
        "\n",
        "**1) Character-level TF-IDF on OCR/HTR text (`text_norm`).**  \n",
        "We build a TF-IDF representation using **character n-grams (3–5)**. Character n-grams are a common and effective choice for noisy OCR/HTR corpora because they remain informative even when word boundaries or spellings are corrupted. We enable `sublinear_tf=True` (log-scaled term frequency) and cap the vocabulary with `max_features=50,000` to control dimensionality on a small dataset.\n",
        "\n",
        "**2) Word-level TF-IDF on summaries (`summary_norm`).**  \n",
        "In parallel, we build a TF-IDF representation using **word n-grams (1–2)** from the tale summary. Summaries typically contain less OCR noise and capture higher-level semantics, which complements the robustness of character n-grams. We similarly apply log-scaled TF and cap the vocabulary at `max_features=20,000`.\n",
        "\n",
        "**3) Feature concatenation via `ColumnTransformer`.**  \n",
        "The `ColumnTransformer` applies each vectorizer to its corresponding dataframe column and **concatenates** the resulting sparse vectors into a single feature space. All other dataframe columns are dropped (`remainder=\"drop\"`), ensuring that only text-derived signals enter the model.\n",
        "\n",
        "**4) Multi-label classification with One-vs-Rest Logistic Regression.**  \n",
        "Because a tale can legitimately have **multiple ATU assignments**, we use a `OneVsRestClassifier(LogisticRegression)` scheme: a separate binary logistic regression is trained for each ATU label, producing a score per label. Logistic regression is fast, stable on sparse TF-IDF features, and provides well-behaved ranking scores for Top-k recommendation.\n",
        "\n",
        "**5) End-to-end pipeline.**  \n",
        "Finally, we wrap preprocessing and classification into a single `Pipeline` so that the same transformations are consistently applied at training and inference time. This also simplifies serialization and deployment (e.g., saving the pipeline as a single artifact for the Streamlit application).\n"
      ],
      "metadata": {
        "id": "Q2Qnef2wwikl"
      },
      "id": "Q2Qnef2wwikl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline: (ColumnTransformer: char TF-IDF on text_norm + optional word TF-IDF on summary_norm/text_norm)\n",
        "#        -> OneVsRest(LogisticRegression)\n",
        "#\n",
        "# Notes:\n",
        "# - ID columns are safe as long as you pass ONLY [\"text_norm\",\"summary_norm\"] to fit/predict (see build_X_text_only below).\n",
        "# - Uses sparse output from ColumnTransformer (TF-IDF) into OvR logistic regression.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "def build_model(\n",
        "    use_word_summary: bool = True,\n",
        "    use_word_text: bool = False,\n",
        "    char_analyzer: str = \"char\",          # \"char\" or \"char_wb\"\n",
        "    char_ngram: Tuple[int, int] = (3, 5),\n",
        "    word_ngram: Tuple[int, int] = (1, 2),\n",
        "    char_max_features: int = 50000,\n",
        "    word_max_features: int = 20000,\n",
        "    C: float = 2.0,\n",
        "    class_weight: Optional[str] = None,   # e.g. \"balanced\" if you want, usually None for multi-label\n",
        "    random_state: int = 42,\n",
        ") -> Pipeline:\n",
        "    transformers = []\n",
        "\n",
        "    # --- char TF-IDF on text_norm (robust to OCR noise) ---\n",
        "    transformers.append((\n",
        "        \"char_tfidf\",\n",
        "        TfidfVectorizer(\n",
        "            analyzer=char_analyzer,\n",
        "            ngram_range=char_ngram,\n",
        "            min_df=1,\n",
        "            max_features=char_max_features,\n",
        "            sublinear_tf=True,\n",
        "            lowercase=False,   # you already normalized; keep as-is\n",
        "        ),\n",
        "        \"text_norm\"\n",
        "    ))\n",
        "\n",
        "    # --- word TF-IDF on summary_norm (if available) ---\n",
        "    if use_word_summary:\n",
        "        transformers.append((\n",
        "            \"sum_word\",\n",
        "            TfidfVectorizer(\n",
        "                analyzer=\"word\",\n",
        "                ngram_range=word_ngram,\n",
        "                min_df=1,\n",
        "                max_features=word_max_features,\n",
        "                sublinear_tf=True,\n",
        "                lowercase=False,\n",
        "            ),\n",
        "            \"summary_norm\"\n",
        "        ))\n",
        "\n",
        "    # --- word TF-IDF on text_norm (optional; can help if summary is short/empty) ---\n",
        "    if use_word_text:\n",
        "        transformers.append((\n",
        "            \"text_word\",\n",
        "            TfidfVectorizer(\n",
        "                analyzer=\"word\",\n",
        "                ngram_range=word_ngram,\n",
        "                min_df=1,\n",
        "                max_features=word_max_features,\n",
        "                sublinear_tf=True,\n",
        "                lowercase=False,\n",
        "            ),\n",
        "            \"text_norm\"\n",
        "        ))\n",
        "\n",
        "    preprocess = ColumnTransformer(transformers=transformers, remainder=\"drop\", sparse_threshold=0.3)\n",
        "\n",
        "    # OvR Logistic Regression (stable for small data)\n",
        "    base_lr = LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        solver=\"liblinear\",\n",
        "        C=C,\n",
        "        class_weight=class_weight,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    clf = OneVsRestClassifier(base_lr, n_jobs=-1)\n",
        "\n",
        "    return Pipeline([\n",
        "        (\"features\", preprocess),\n",
        "        (\"clf\", clf),\n",
        "    ])\n",
        "\n",
        "\n",
        "# SAFE helper: pass ONLY these columns to the model (prevents ID leakage)\n",
        "def build_X_text_only(df: pd.DataFrame, text_cols=(\"summary_norm\", \"text_norm\")) -> pd.DataFrame:\n",
        "    cols = [c for c in text_cols if c in df.columns]\n",
        "    if not cols:\n",
        "        raise ValueError(f\"None of text_cols {text_cols} found in df\")\n",
        "    return df[cols].copy()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# model = build_model(use_word_summary=True, use_word_text=False, char_analyzer=\"char\", char_ngram=(3,5))\n",
        "# X_train = build_X_text_only(train_df, text_cols=(\"summary_norm\",\"text_norm\"))\n",
        "# model.fit(X_train, y_train)\n",
        "# proba = model.predict_proba(build_X_text_only(test_df))\n"
      ],
      "metadata": {
        "id": "8YAktY2cG2YF"
      },
      "id": "8YAktY2cG2YF",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Repeated hold-out eval for YOUR model + YOUR metric:\n",
        "# Metric = Parent-Hit@k computed exactly as in your model:\n",
        "#   top-k FINE labels (by model scores) -> map to PARENTS -> any-match with gold parents\n",
        "#\n",
        "# Uses:\n",
        "# - text_norm (always) for char TF-IDF\n",
        "# - summary_fallback for word TF-IDF (summary_norm if present, else fallback to text_norm[:N])\n",
        "# - your parent_hit_at_k_from_proba(...) + atu_parent(...) (must be defined already)\n",
        "#\n",
        "# IMPORTANT:\n",
        "# - X passed to model = only columns needed by ColumnTransformer (no IDs, no metadata)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 0) Robust label cleaning\n",
        "# -------------------------\n",
        "def _is_nan(x) -> bool:\n",
        "    return isinstance(x, float) and pd.isna(x)\n",
        "\n",
        "def clean_label_list(labels) -> list[str]:\n",
        "    \"\"\"Ensure labels is list[str] (no NaN/None/empty).\"\"\"\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "    if isinstance(labels, str):\n",
        "        s = labels.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    # unique, stable order\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 1) Ensure summary_fallback for word TF-IDF\n",
        "# -----------------------------------------\n",
        "def ensure_summary_fallback(\n",
        "    df_in: pd.DataFrame,\n",
        "    summary_col: str = \"summary_norm\",\n",
        "    text_col: str = \"text_norm\",\n",
        "    out_col: str = \"summary_fallback\",\n",
        "    n_fallback_chars: int = 800\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Creates/cleans df[out_col]:\n",
        "      - if summary_col exists and is non-empty => use it\n",
        "      - else fallback to text_norm[:n_fallback_chars]\n",
        "    \"\"\"\n",
        "    df = df_in.copy()\n",
        "\n",
        "    # Ensure text column exists as string\n",
        "    if text_col not in df.columns:\n",
        "        raise ValueError(f\"Missing required text column: {text_col}\")\n",
        "    df[text_col] = df[text_col].fillna(\"\").astype(str)\n",
        "\n",
        "    # If summary exists, use it, else fallback from text\n",
        "    if summary_col in df.columns:\n",
        "        df[summary_col] = df[summary_col].fillna(\"\").astype(str)\n",
        "        df[out_col] = df[summary_col].where(\n",
        "            df[summary_col].str.strip().ne(\"\"),\n",
        "            df[text_col].str.slice(0, n_fallback_chars)\n",
        "        )\n",
        "    else:\n",
        "        df[out_col] = df[text_col].str.slice(0, n_fallback_chars)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# 2) Parent labels (gold) must be list[str]\n",
        "# --------------------------------------------\n",
        "def _clean_parent_list(x) -> list[str]:\n",
        "    if x is None or _is_nan(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for lab in x:\n",
        "        if lab is None or _is_nan(lab):\n",
        "            continue\n",
        "        s = str(lab).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    # unique\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Stratified-ish split by parent (safe, best-effort)\n",
        "# ---------------------------------------------------------\n",
        "def stratified_multilabel_split_by_parent(\n",
        "    df: pd.DataFrame,\n",
        "    label_col: str = \"labels_parent\",\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    min_train_count_per_label: int = 1,\n",
        "):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    df = df.reset_index(drop=True).copy()\n",
        "\n",
        "    if not (0.0 < test_size < 1.0):\n",
        "        raise ValueError(\"test_size must be in (0, 1)\")\n",
        "\n",
        "    # clean gold parent lists\n",
        "    df[label_col] = df[label_col].apply(_clean_parent_list)\n",
        "\n",
        "    n = len(df)\n",
        "    n_test = int(round(n * test_size))\n",
        "    n_test = max(1, min(n - 1, n_test))\n",
        "\n",
        "    all_counts = Counter(lab for labs in df[label_col] for lab in labs)\n",
        "    remaining = Counter(all_counts)\n",
        "\n",
        "    test_idx = []\n",
        "    covered_test = set()\n",
        "\n",
        "    candidates = list(range(n))\n",
        "    rng.shuffle(candidates)\n",
        "\n",
        "    def is_safe(i: int) -> bool:\n",
        "        labs = df.at[i, label_col]\n",
        "        if not labs:\n",
        "            return True\n",
        "        return all((remaining[lab] - 1) >= min_train_count_per_label for lab in labs)\n",
        "\n",
        "    def gain(i: int) -> int:\n",
        "        labs = set(df.at[i, label_col])\n",
        "        return len(labs - covered_test)\n",
        "\n",
        "    while len(test_idx) < n_test:\n",
        "        safe = [i for i in candidates if (i not in test_idx and is_safe(i))]\n",
        "        if not safe:\n",
        "            break\n",
        "\n",
        "        gains = np.array([gain(i) for i in safe], dtype=int)\n",
        "        best_gain = gains.max()\n",
        "        best = [safe[j] for j in np.where(gains == best_gain)[0]]\n",
        "        chosen = int(rng.choice(best))\n",
        "\n",
        "        test_idx.append(chosen)\n",
        "        for lab in df.at[chosen, label_col]:\n",
        "            remaining[lab] -= 1\n",
        "            covered_test.add(lab)\n",
        "\n",
        "    # backfill safely, then last resort random\n",
        "    if len(test_idx) < n_test:\n",
        "        safe_rest = [i for i in range(n) if (i not in test_idx and is_safe(i))]\n",
        "        rng.shuffle(safe_rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(safe_rest[:need])\n",
        "\n",
        "    if len(test_idx) < n_test:\n",
        "        rest = [i for i in range(n) if i not in test_idx]\n",
        "        rng.shuffle(rest)\n",
        "        need = n_test - len(test_idx)\n",
        "        test_idx.extend(rest[:need])\n",
        "\n",
        "    test_idx = sorted(set(test_idx))\n",
        "    if len(test_idx) >= n:\n",
        "        test_idx = test_idx[: n - 1]\n",
        "\n",
        "    train_idx = [i for i in range(n) if i not in test_idx]\n",
        "    return df.iloc[train_idx].reset_index(drop=True), df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) YOUR model builder (char + optional word channels)\n",
        "# ---------------------------------------------------------\n",
        "def build_model(\n",
        "    use_word_summary: bool = True,\n",
        "    use_word_text: bool = False,\n",
        "    char_analyzer: str = \"char\",         # \"char\" or \"char_wb\"\n",
        "    char_ngram=(3, 5),\n",
        "    word_ngram=(1, 2),\n",
        "    char_max_features: int = 50000,\n",
        "    word_max_features: int = 20000,\n",
        "    summary_col: str = \"summary_fallback\",\n",
        "    C: float = 2.0,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    transformers = []\n",
        "\n",
        "    transformers.append((\n",
        "        \"char_tfidf\",\n",
        "        TfidfVectorizer(\n",
        "            analyzer=char_analyzer,\n",
        "            ngram_range=char_ngram,\n",
        "            min_df=1,\n",
        "            max_features=char_max_features,\n",
        "            sublinear_tf=True,\n",
        "            lowercase=False,\n",
        "        ),\n",
        "        \"text_norm\"\n",
        "    ))\n",
        "\n",
        "    if use_word_summary:\n",
        "        transformers.append((\n",
        "            \"sum_word\",\n",
        "            TfidfVectorizer(\n",
        "                analyzer=\"word\",\n",
        "                ngram_range=word_ngram,\n",
        "                min_df=1,\n",
        "                max_features=word_max_features,\n",
        "                sublinear_tf=True,\n",
        "                lowercase=False,\n",
        "            ),\n",
        "            summary_col\n",
        "        ))\n",
        "\n",
        "    if use_word_text:\n",
        "        transformers.append((\n",
        "            \"text_word\",\n",
        "            TfidfVectorizer(\n",
        "                analyzer=\"word\",\n",
        "                ngram_range=word_ngram,\n",
        "                min_df=1,\n",
        "                max_features=word_max_features,\n",
        "                sublinear_tf=True,\n",
        "                lowercase=False,\n",
        "            ),\n",
        "            \"text_norm\"\n",
        "        ))\n",
        "\n",
        "    preprocess = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
        "\n",
        "    clf = OneVsRestClassifier(\n",
        "        LogisticRegression(max_iter=2000, solver=\"liblinear\", C=C, random_state=random_state),\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    return Pipeline([(\"features\", preprocess), (\"clf\", clf)])\n",
        "\n",
        "\n",
        "def build_X_for_model(df: pd.DataFrame, summary_col: str = \"summary_fallback\") -> pd.DataFrame:\n",
        "    \"\"\"Pass ONLY the columns the ColumnTransformer expects.\"\"\"\n",
        "    cols = [\"text_norm\"]\n",
        "    if summary_col in df.columns:\n",
        "        cols.append(summary_col)\n",
        "    return df[cols].copy()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5) Repeated hold-out evaluation with YOUR metric\n",
        "#    (parent_hit_at_k_from_proba must be defined already)\n",
        "# ---------------------------------------------------------\n",
        "def repeated_holdout_parent_hit_k(\n",
        "    df_in: pd.DataFrame,\n",
        "    seeds,\n",
        "    model_builder,\n",
        "    test_size: float = 0.2,\n",
        "    k: int = 3,\n",
        "    summary_col: str = \"summary_fallback\",\n",
        "    min_train_count_per_label: int = 1,\n",
        "):\n",
        "    # prepare text + labels\n",
        "    df = ensure_summary_fallback(df_in, summary_col=\"summary_norm\", out_col=summary_col)\n",
        "    df = df.copy()\n",
        "    df[\"labels\"] = df[\"labels\"].apply(clean_label_list)\n",
        "    df[\"labels_parent\"] = df[\"labels_parent\"].apply(_clean_parent_list)\n",
        "\n",
        "    # IMPORTANT: fix label universe ONCE (consistent scoring across seeds)\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    mlb.fit(df[\"labels\"])\n",
        "\n",
        "    scores = []\n",
        "    for rs in seeds:\n",
        "        tr_df, te_df = stratified_multilabel_split_by_parent(\n",
        "            df, label_col=\"labels_parent\", test_size=test_size, random_state=rs,\n",
        "            min_train_count_per_label=min_train_count_per_label\n",
        "        )\n",
        "\n",
        "        X_train = build_X_for_model(tr_df, summary_col=summary_col)\n",
        "        X_test  = build_X_for_model(te_df, summary_col=summary_col)\n",
        "\n",
        "        y_train = mlb.transform(tr_df[\"labels\"])\n",
        "\n",
        "        model = model_builder()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        proba = model.predict_proba(X_test)\n",
        "\n",
        "        score = parent_hit_at_k_from_proba(\n",
        "            y_true_parent_lists=te_df[\"labels_parent\"].tolist(),\n",
        "            proba=proba,\n",
        "            classes=mlb.classes_,\n",
        "            k=k\n",
        "        )\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.array(scores, dtype=float)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# RUN EXPERIMENTS A/B/C/D\n",
        "# =========================\n",
        "\n",
        "seeds = [41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
        "\n",
        "experiments = {\n",
        "    \"A_char + word_summary_fallback\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char\"),\n",
        "    \"B_char + word_summary_fallback + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char\"),\n",
        "    \"C_charWB + word_summary_fallback\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char_wb\"),\n",
        "    \"D_charWB + word_summary_fallback + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char_wb\"),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, builder in experiments.items():\n",
        "    scores = repeated_holdout_parent_hit_k(\n",
        "        df, seeds=seeds, model_builder=builder,\n",
        "        test_size=0.2, k=3, summary_col=\"summary_fallback\",\n",
        "        min_train_count_per_label=1\n",
        "    )\n",
        "    results[name] = scores\n",
        "    print(f\"{name}: mean={scores.mean():.4f} std={scores.std(ddof=0):.4f} \"\n",
        "          f\"min={scores.min():.3f} max={scores.max():.3f} scores={scores}\")\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"model\": list(results.keys()),\n",
        "    \"mean\": [results[m].mean() for m in results],\n",
        "    \"std\":  [results[m].std(ddof=0) for m in results],\n",
        "    \"min\":  [results[m].min() for m in results],\n",
        "    \"max\":  [results[m].max() for m in results],\n",
        "}).sort_values(\"mean\", ascending=False)\n",
        "\n",
        "display(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Qg_GOWI7IAsH",
        "outputId": "d8e5f341-9d97-4442-b8ec-2448f5743d77"
      },
      "id": "Qg_GOWI7IAsH",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_char + word_summary_fallback: mean=0.4300 std=0.1187 min=0.300 max=0.700 scores=[0.4 0.4 0.5 0.3 0.7 0.4 0.5 0.3 0.3 0.5]\n",
            "B_char + word_summary_fallback + word_text: mean=0.4600 std=0.0917 min=0.400 max=0.700 scores=[0.4 0.4 0.5 0.4 0.7 0.4 0.5 0.4 0.4 0.5]\n",
            "C_charWB + word_summary_fallback: mean=0.4500 std=0.1025 min=0.300 max=0.700 scores=[0.4 0.4 0.5 0.3 0.7 0.4 0.5 0.4 0.4 0.5]\n",
            "D_charWB + word_summary_fallback + word_text: mean=0.4600 std=0.0917 min=0.400 max=0.700 scores=[0.4 0.4 0.5 0.4 0.7 0.4 0.5 0.4 0.4 0.5]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          model  mean       std  min  max\n",
              "1    B_char + word_summary_fallback + word_text  0.46  0.091652  0.4  0.7\n",
              "3  D_charWB + word_summary_fallback + word_text  0.46  0.091652  0.4  0.7\n",
              "2              C_charWB + word_summary_fallback  0.45  0.102470  0.3  0.7\n",
              "0                A_char + word_summary_fallback  0.43  0.118743  0.3  0.7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adf8ff5f-7843-489e-ac41-df48b8df4f1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B_char + word_summary_fallback + word_text</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.091652</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D_charWB + word_summary_fallback + word_text</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.091652</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C_charWB + word_summary_fallback</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.102470</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A_char + word_summary_fallback</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.118743</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adf8ff5f-7843-489e-ac41-df48b8df4f1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adf8ff5f-7843-489e-ac41-df48b8df4f1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adf8ff5f-7843-489e-ac41-df48b8df4f1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-932b1d5f-c61d-43d5-b266-08cc73802ccd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-932b1d5f-c61d-43d5-b266-08cc73802ccd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-932b1d5f-c61d-43d5-b266-08cc73802ccd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_20d8703a-0137-4d7f-9788-5ee5a67bf632\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_20d8703a-0137-4d7f-9788-5ee5a67bf632 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"D_charWB + word_summary_fallback + word_text\",\n          \"A_char + word_summary_fallback\",\n          \"B_char + word_summary_fallback + word_text\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014142135623730989,\n        \"min\": 0.43,\n        \"max\": 0.4600000000000001,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4600000000000001,\n          0.45,\n          0.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012802477220817815,\n        \"min\": 0.09165151389911677,\n        \"max\": 0.11874342087037916,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.09165151389911677,\n          0.10246950765959598,\n          0.11874342087037916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057735026918962595,\n        \"min\": 0.3,\n        \"max\": 0.4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a repeated hold-out evaluation (10 random seeds; 80/20 split using the parent-aware multi-label splitter), the TF-IDF + OvR Logistic Regression classifier substantially outperformed the naïve frequency baseline under the project’s primary metric, Parent-Hit@3 (success if at least one gold ATU parent code appears among the parents of the model’s Top-3 predicted fine-grained types). The frequency baseline reaches only ~0.15 Parent-Hit@3 (≈1–2 hits per 10 tales), whereas the proposed text-based models achieve 0.43–0.46 on average (≈4–5 hits per 10 tales), indicating that textual features provide strong predictive signal beyond label priors. Across ablations, combining character TF-IDF on text_norm with word TF-IDF on the summary fallback is already effective (mean 0.43–0.45), while adding word TF-IDF on text_norm yields a small but consistent improvement and better stability (mean 0.46, minimum 0.40 across seeds). Using char_wb instead of char did not materially change performance in this setting. Based on these results, the mixed vector representation (char + word summary + optional word text) is retained as the default baseline model for subsequent experiments and UI integration."
      ],
      "metadata": {
        "id": "8BPas2eww620"
      },
      "id": "8BPas2eww620"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model"
      ],
      "metadata": {
        "id": "uYc5zM622p7n"
      },
      "id": "uYc5zM622p7n"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Baseline (frequency) evaluated with THE SAME repeated hold-out\n",
        "# protocol as your model (same seeds, same splitter, same metric).\n",
        "#\n",
        "# Baseline logic is aligned with your model-eval logic:\n",
        "# - Baseline predicts Top-k FINE labels (constant) from TRAIN fold frequencies\n",
        "# - Evaluation uses your Parent-Hit@k:\n",
        "#     top-k fine -> map to parents -> any-match with gold parents\n",
        "#\n",
        "# Prereqs:\n",
        "# - df has: labels (list[str] or convertible), labels_parent (list[str]),\n",
        "#          text_norm (str), summary_norm (optional)\n",
        "# - you already defined: atu_parent(), parent_hit_at_k_from_proba()\n",
        "# - you have (or paste) the same splitter: stratified_multilabel_split_by_parent()\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Robust cleaning helpers\n",
        "# -------------------------\n",
        "def _is_nan(x) -> bool:\n",
        "    return isinstance(x, float) and pd.isna(x)\n",
        "\n",
        "def clean_label_list(labels) -> list[str]:\n",
        "    \"\"\"Ensure labels is list[str] (no NaN/None/empty).\"\"\"\n",
        "    if labels is None or _is_nan(labels):\n",
        "        return []\n",
        "    if isinstance(labels, str):\n",
        "        s = labels.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for x in labels:\n",
        "        if x is None or _is_nan(x):\n",
        "            continue\n",
        "        s = str(x).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    # unique, stable order\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "def _clean_parent_list(x) -> list[str]:\n",
        "    if x is None or _is_nan(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip()\n",
        "        return [s] if s else []\n",
        "    out = []\n",
        "    for lab in x:\n",
        "        if lab is None or _is_nan(lab):\n",
        "            continue\n",
        "        s = str(lab).strip()\n",
        "        if s:\n",
        "            out.append(s)\n",
        "    # unique, stable order\n",
        "    seen = set()\n",
        "    dedup = []\n",
        "    for s in out:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            dedup.append(s)\n",
        "    return dedup\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Baseline: Top-k FINE by doc frequency (TRAIN only)\n",
        "# -------------------------\n",
        "def topk_fine_labels_by_freq(labels_lists, k=3) -> list[str]:\n",
        "    cnt = Counter()\n",
        "    for labs in labels_lists:\n",
        "        labs = clean_label_list(labs)\n",
        "        for lab in set(labs):   # doc-level counting\n",
        "            cnt[lab] += 1\n",
        "    return [lab for lab, _ in cnt.most_common(k)]\n",
        "\n",
        "\n",
        "def constant_score_matrix_from_topk_fine(\n",
        "    topk_fine: list[str],\n",
        "    classes: np.ndarray,\n",
        "    n_rows: int\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build an (n_rows, n_classes) score matrix that yields exactly `topk_fine`\n",
        "    as the top-k predicted labels (ranking only; not calibrated probabilities).\n",
        "    \"\"\"\n",
        "    classes = np.asarray(classes)\n",
        "    row = np.zeros((1, len(classes)), dtype=float)\n",
        "\n",
        "    score = float(len(topk_fine))\n",
        "    for lab in topk_fine:\n",
        "        idx = np.where(classes == lab)[0]\n",
        "        if len(idx) == 0:\n",
        "            continue\n",
        "        row[0, idx[0]] = score\n",
        "        score -= 1.0\n",
        "\n",
        "    return np.repeat(row, repeats=n_rows, axis=0)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Repeated hold-out baseline with same protocol\n",
        "# -------------------------\n",
        "def repeated_holdout_freq_baseline_parent_hit_k(\n",
        "    df_in: pd.DataFrame,\n",
        "    seeds,\n",
        "    test_size: float = 0.2,\n",
        "    k: int = 3,\n",
        "    min_train_count_per_label: int = 1,\n",
        "    verbose: bool = True\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Uses the SAME repeated hold-out protocol as your model:\n",
        "      - split with stratified_multilabel_split_by_parent(..., random_state=seed)\n",
        "      - baseline top-k computed from TRAIN fold only\n",
        "      - evaluate with parent_hit_at_k_from_proba (same as model)\n",
        "    \"\"\"\n",
        "    df = df_in.copy()\n",
        "    df[\"labels\"] = df[\"labels\"].apply(clean_label_list)\n",
        "    df[\"labels_parent\"] = df[\"labels_parent\"].apply(_clean_parent_list)\n",
        "\n",
        "    # Fix label universe ONCE (consistent across seeds)\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    mlb.fit(df[\"labels\"])\n",
        "    classes = np.asarray(mlb.classes_)\n",
        "\n",
        "    scores = []\n",
        "    for rs in seeds:\n",
        "        tr_df, te_df = stratified_multilabel_split_by_parent(\n",
        "            df,\n",
        "            label_col=\"labels_parent\",\n",
        "            test_size=test_size,\n",
        "            random_state=rs,\n",
        "            min_train_count_per_label=min_train_count_per_label\n",
        "        )\n",
        "\n",
        "        # TRAIN-only: choose constant top-k fine labels by frequency\n",
        "        topk_fine = topk_fine_labels_by_freq(tr_df[\"labels\"].tolist(), k=k)\n",
        "\n",
        "        # Build constant score matrix for TEST fold (size = len(te_df))\n",
        "        proba_te = constant_score_matrix_from_topk_fine(\n",
        "            topk_fine=topk_fine,\n",
        "            classes=classes,\n",
        "            n_rows=len(te_df)\n",
        "        )\n",
        "\n",
        "        # SAME metric as model eval (fine top-k -> parent any-match)\n",
        "        score = parent_hit_at_k_from_proba(\n",
        "            y_true_parent_lists=te_df[\"labels_parent\"].tolist(),\n",
        "            proba=proba_te,\n",
        "            classes=classes,\n",
        "            k=k\n",
        "        )\n",
        "        scores.append(score)\n",
        "\n",
        "        if verbose:\n",
        "            pred_parents = sorted({atu_parent(x) for x in topk_fine if str(x).strip()})\n",
        "            print(f\"seed={rs}: Top{k} fine={topk_fine} | parents={pred_parents} | Parent-Hit@{k}={score:.3f}\")\n",
        "\n",
        "    scores = np.array(scores, dtype=float)\n",
        "    if verbose:\n",
        "        print(f\"Repeated hold-out freq-baseline Parent-Hit@{k}: mean={scores.mean():.4f} std={scores.std(ddof=0):.4f} \"\n",
        "              f\"min={scores.min():.3f} max={scores.max():.3f} scores={scores}\")\n",
        "    return scores\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Example run (same seeds as your A/B/C/D)\n",
        "# -------------------------\n",
        "seeds = [41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
        "\n",
        "baseline_scores = repeated_holdout_freq_baseline_parent_hit_k(\n",
        "    df,\n",
        "    seeds=seeds,\n",
        "    test_size=0.2,\n",
        "    k=3,\n",
        "    min_train_count_per_label=1,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MoujK5vJ-uE",
        "outputId": "eb8be9bc-eaed-42c6-c0f9-b8b3d1e57ee2"
      },
      "id": "9MoujK5vJ-uE",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed=41: Top3 fine=['480D*', '707', '552'] | parents=['480', '552', '707'] | Parent-Hit@3=0.200\n",
            "seed=42: Top3 fine=['707', '480D*', '402'] | parents=['402', '480', '707'] | Parent-Hit@3=0.200\n",
            "seed=43: Top3 fine=['707', '480D*', '552'] | parents=['480', '552', '707'] | Parent-Hit@3=0.200\n",
            "seed=44: Top3 fine=['707', '480D*', '530'] | parents=['480', '530', '707'] | Parent-Hit@3=0.200\n",
            "seed=45: Top3 fine=['480D*', '707', '402'] | parents=['402', '480', '707'] | Parent-Hit@3=0.200\n",
            "seed=46: Top3 fine=['480D*', '707', '650A'] | parents=['480', '650', '707'] | Parent-Hit@3=0.200\n",
            "seed=47: Top3 fine=['480D*', '707', '650A'] | parents=['480', '650', '707'] | Parent-Hit@3=0.200\n",
            "seed=48: Top3 fine=['480D*', '707', '402'] | parents=['402', '480', '707'] | Parent-Hit@3=0.200\n",
            "seed=49: Top3 fine=['707', '480D*', '650A'] | parents=['480', '650', '707'] | Parent-Hit@3=0.200\n",
            "seed=50: Top3 fine=['707', '480D*', '552'] | parents=['480', '552', '707'] | Parent-Hit@3=0.200\n",
            "Repeated hold-out freq-baseline Parent-Hit@3: mean=0.2000 std=0.0000 min=0.200 max=0.200 scores=[0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under the same repeated hold-out protocol (10 random seeds; 80/20 split with the parent-aware multi-label splitter) and the same evaluation rule (Parent-Hit@3, computed by taking the model’s Top-3 fine-grained ATU predictions, mapping them to parent codes, and counting a hit if any gold parent is present), the TF-IDF + OvR Logistic Regression models consistently outperform a naïve frequency baseline. The frequency baseline—implemented as a constant predictor that always outputs the Top-3 most frequent fine labels from the training split—achieves Parent-Hit@3 = 0.20 (std = 0.00), i.e., about 2 hits per 10 tales. In contrast, the text-based classifiers reach 0.43–0.46 on average (A: 0.43, B: 0.46, C: 0.45, D: 0.46), corresponding to roughly 4–5 hits per 10 tales, i.e., an absolute improvement of +0.23 to +0.26 over the baseline. Adding a word-level TF-IDF channel on text_norm (B/D) provides a small but consistent gain and improves stability (minimum 0.40 across seeds), while switching from char to char_wb does not materially change performance in this setting. Based on this comparison, the mixed TF-IDF representation (char TF-IDF on text_norm + word TF-IDF on the summary fallback, optionally augmented with word TF-IDF on text_norm) is retained as the default baseline model for subsequent experiments and UI integration."
      ],
      "metadata": {
        "id": "r-JgS7LWK8Mn"
      },
      "id": "r-JgS7LWK8Mn"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ly_aeJkmoGGW"
      },
      "id": "ly_aeJkmoGGW"
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 0) Prepare df (text + labels)\n",
        "# ----------------------------\n",
        "df_all = ensure_summary_fallback(df, summary_col=\"summary_norm\", out_col=\"summary_fallback\").copy()\n",
        "df_all[\"labels\"] = df_all[\"labels\"].apply(clean_label_list)\n",
        "df_all[\"labels_parent\"] = df_all[\"labels_parent\"].apply(_clean_parent_list)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Freeze ONE test split\n",
        "# ----------------------------\n",
        "SPLIT_SEED = 42\n",
        "train_df, test_df = stratified_multilabel_split_by_parent(\n",
        "    df_all,\n",
        "    label_col=\"labels_parent\",\n",
        "    test_size=0.2,\n",
        "    random_state=SPLIT_SEED,\n",
        "    min_train_count_per_label=1\n",
        ")\n",
        "print(\"Train:\", train_df.shape, \"| Test:\", test_df.shape)"
      ],
      "metadata": {
        "id": "tjq90b4ZoEdE",
        "outputId": "7e593461-182b-416c-eca7-377e8e04a8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tjq90b4ZoEdE",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (40, 6) | Test: (10, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 3) CV evaluation on TRAIN ONLY\n",
        "#    metric = Parent-Hit@3 exactly like your model\n",
        "# ----------------------------\n",
        "def cv_parent_hit_at_k(\n",
        "    train_df: pd.DataFrame,\n",
        "    mlb: MultiLabelBinarizer,\n",
        "    model_builder,\n",
        "    k: int = 3,\n",
        "    n_splits: int = 5,\n",
        "    random_state: int = 42,\n",
        "    summary_col: str = \"summary_fallback\"\n",
        "):\n",
        "    X = build_X_for_model(train_df, summary_col=summary_col)\n",
        "    y = mlb.transform(train_df[\"labels\"])  # uses fixed label space from TRAIN\n",
        "    y_parent = train_df[\"labels_parent\"].tolist()\n",
        "\n",
        "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(cv.split(train_df), start=1):\n",
        "        model = model_builder()\n",
        "        model.fit(X.iloc[tr], y[tr])\n",
        "\n",
        "        proba = model.predict_proba(X.iloc[va])\n",
        "        score = parent_hit_at_k_from_proba(\n",
        "            y_true_parent_lists=[y_parent[i] for i in va],\n",
        "            proba=proba,\n",
        "            classes=mlb.classes_,\n",
        "            k=k\n",
        "        )\n",
        "        scores.append(score)\n",
        "        print(f\"Fold {fold}: Parent-Hit@{k}={score:.3f}\")\n",
        "\n",
        "    scores = np.array(scores, dtype=float)\n",
        "    print(f\"CV mean={scores.mean():.4f} std={scores.std(ddof=0):.4f} scores={scores}\")\n",
        "    return scores\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Define A/B/C/D builders\n",
        "# ----------------------------\n",
        "experiments = {\n",
        "    \"A_char + word_summary_fallback\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char\"),\n",
        "    \"B_char + word_summary_fallback + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char\"),\n",
        "    \"C_charWB + word_summary_fallback\": lambda: build_model(use_word_summary=True,  use_word_text=False, char_analyzer=\"char_wb\"),\n",
        "    \"D_charWB + word_summary_fallback + word_text\": lambda: build_model(use_word_summary=True,  use_word_text=True,  char_analyzer=\"char_wb\"),\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Run CV on train, pick best\n",
        "# ----------------------------\n",
        "cv_results = {}\n",
        "for name, builder in experiments.items():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(name)\n",
        "    scores = cv_parent_hit_at_k(\n",
        "        train_df=train_df,\n",
        "        mlb=mlb,\n",
        "        model_builder=builder,\n",
        "        k=3,\n",
        "        n_splits=5,\n",
        "        random_state=123,   # seed for CV shuffling\n",
        "        summary_col=\"summary_fallback\"\n",
        "    )\n",
        "    cv_results[name] = scores\n",
        "\n",
        "cv_summary = pd.DataFrame({\n",
        "    \"model\": list(cv_results.keys()),\n",
        "    \"mean\": [cv_results[m].mean() for m in cv_results],\n",
        "    \"std\":  [cv_results[m].std(ddof=0) for m in cv_results],\n",
        "}).sort_values(\"mean\", ascending=False)\n",
        "\n",
        "display(cv_summary)\n",
        "\n",
        "best_name = cv_summary.iloc[0][\"model\"]\n",
        "best_builder = experiments[best_name]\n",
        "print(\"\\nBEST by CV:\", best_name)"
      ],
      "metadata": {
        "id": "XyUTR9cpoNnu",
        "outputId": "22475cad-04ed-4316-8dab-3e7a9b43ea28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "id": "XyUTR9cpoNnu",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "A_char + word_summary_fallback\n",
            "Fold 1: Parent-Hit@3=0.375\n",
            "Fold 2: Parent-Hit@3=0.500\n",
            "Fold 3: Parent-Hit@3=0.125\n",
            "Fold 4: Parent-Hit@3=0.625\n",
            "Fold 5: Parent-Hit@3=0.625\n",
            "CV mean=0.4500 std=0.1871 scores=[0.375 0.5   0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "B_char + word_summary_fallback + word_text\n",
            "Fold 1: Parent-Hit@3=0.375\n",
            "Fold 2: Parent-Hit@3=0.250\n",
            "Fold 3: Parent-Hit@3=0.125\n",
            "Fold 4: Parent-Hit@3=0.625\n",
            "Fold 5: Parent-Hit@3=0.625\n",
            "CV mean=0.4000 std=0.2000 scores=[0.375 0.25  0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "C_charWB + word_summary_fallback\n",
            "Fold 1: Parent-Hit@3=0.375\n",
            "Fold 2: Parent-Hit@3=0.500\n",
            "Fold 3: Parent-Hit@3=0.125\n",
            "Fold 4: Parent-Hit@3=0.625\n",
            "Fold 5: Parent-Hit@3=0.625\n",
            "CV mean=0.4500 std=0.1871 scores=[0.375 0.5   0.125 0.625 0.625]\n",
            "\n",
            "======================================================================\n",
            "D_charWB + word_summary_fallback + word_text\n",
            "Fold 1: Parent-Hit@3=0.375\n",
            "Fold 2: Parent-Hit@3=0.250\n",
            "Fold 3: Parent-Hit@3=0.125\n",
            "Fold 4: Parent-Hit@3=0.625\n",
            "Fold 5: Parent-Hit@3=0.625\n",
            "CV mean=0.4000 std=0.2000 scores=[0.375 0.25  0.125 0.625 0.625]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          model  mean       std\n",
              "0                A_char + word_summary_fallback  0.45  0.187083\n",
              "2              C_charWB + word_summary_fallback  0.45  0.187083\n",
              "1    B_char + word_summary_fallback + word_text  0.40  0.200000\n",
              "3  D_charWB + word_summary_fallback + word_text  0.40  0.200000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e2eaeeb-0ee6-40d3-bb92-6ea12ce068bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A_char + word_summary_fallback</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C_charWB + word_summary_fallback</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.187083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B_char + word_summary_fallback + word_text</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D_charWB + word_summary_fallback + word_text</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e2eaeeb-0ee6-40d3-bb92-6ea12ce068bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e2eaeeb-0ee6-40d3-bb92-6ea12ce068bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e2eaeeb-0ee6-40d3-bb92-6ea12ce068bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-07896fb0-5c8c-49c4-9da3-edf4b1e22a3a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07896fb0-5c8c-49c4-9da3-edf4b1e22a3a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-07896fb0-5c8c-49c4-9da3-edf4b1e22a3a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9802724f-9de6-4ba3-b393-b4c6f7e524ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cv_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9802724f-9de6-4ba3-b393-b4c6f7e524ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cv_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cv_summary",
              "summary": "{\n  \"name\": \"cv_summary\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"C_charWB + word_summary_fallback\",\n          \"D_charWB + word_summary_fallback + word_text\",\n          \"A_char + word_summary_fallback\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02886751345948128,\n        \"min\": 0.4,\n        \"max\": 0.45,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4,\n          0.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007457708864460831,\n        \"min\": 0.18708286933869706,\n        \"max\": 0.2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.2,\n          0.18708286933869706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BEST by CV: A_char + word_summary_fallback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 6) Train best model on FULL TRAIN and evaluate on TEST\n",
        "# ----------------------------\n",
        "X_train = build_X_for_model(train_df, summary_col=\"summary_fallback\")\n",
        "X_test  = build_X_for_model(test_df,  summary_col=\"summary_fallback\")\n",
        "\n",
        "best_model = best_builder()\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "proba_test = best_model.predict_proba(X_test)\n",
        "test_score = parent_hit_at_k_from_proba(\n",
        "    y_true_parent_lists=test_df[\"labels_parent\"].tolist(),\n",
        "    proba=proba_test,\n",
        "    classes=mlb.classes_,\n",
        "    k=3\n",
        ")\n",
        "print(f\"\\nTEST Parent-Hit@3 for BEST ({best_name}): {test_score:.3f}\")"
      ],
      "metadata": {
        "id": "4U_-hw2NoqJy",
        "outputId": "ca7d99d7-dd5e-4fdf-f438-06e7ea2bf0a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4U_-hw2NoqJy",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST Parent-Hit@3 for BEST (A_char + word_summary_fallback): 0.400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def topk_fine_labels_by_freq(labels_lists, k=3) -> list[str]:\n",
        "    cnt = Counter()\n",
        "    for labs in labels_lists:\n",
        "        labs = clean_label_list(labs)\n",
        "        for lab in set(labs):\n",
        "            cnt[lab] += 1\n",
        "    return [lab for lab, _ in cnt.most_common(k)]\n",
        "\n",
        "def constant_score_matrix_from_topk_fine(topk_fine, classes, n_rows):\n",
        "    classes = np.asarray(classes)\n",
        "    row = np.zeros((1, len(classes)), dtype=float)\n",
        "    score = float(len(topk_fine))\n",
        "    for lab in topk_fine:\n",
        "        idx = np.where(classes == lab)[0]\n",
        "        if len(idx) == 0:\n",
        "            continue\n",
        "        row[0, idx[0]] = score\n",
        "        score -= 1.0\n",
        "    return np.repeat(row, repeats=n_rows, axis=0)\n",
        "\n",
        "topk_fine = topk_fine_labels_by_freq(train_df[\"labels\"].tolist(), k=3)\n",
        "proba_base = constant_score_matrix_from_topk_fine(topk_fine, mlb.classes_, n_rows=len(test_df))\n",
        "\n",
        "baseline_test = parent_hit_at_k_from_proba(\n",
        "    y_true_parent_lists=test_df[\"labels_parent\"].tolist(),\n",
        "    proba=proba_base,\n",
        "    classes=mlb.classes_,\n",
        "    k=3\n",
        ")\n",
        "print(f\"TEST Parent-Hit@3 frequency baseline (Top3={topk_fine}): {baseline_test:.3f}\")\n",
        "print(f\"Absolute gain vs baseline: {test_score - baseline_test:+.3f}\")"
      ],
      "metadata": {
        "id": "vfm7hhOspFKx",
        "outputId": "87602cf7-2462-4488-d892-c718c40caa6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vfm7hhOspFKx",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST Parent-Hit@3 frequency baseline (Top3=['707', '480D*', '402']): 0.200\n",
            "Absolute gain vs baseline: +0.200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"models/atu_ovr_tfidf.joblib\"\n",
        "LABELS_PATH = \"models/labels.json\"\n",
        "META_PATH = \"models/meta.json\"\n",
        "\n",
        "# model: ваш sklearn Pipeline\n",
        "# mlb: MultiLabelBinarizer (fitted)\n",
        "\n",
        "joblib.dump(model, MODEL_PATH)\n",
        "\n",
        "with open(LABELS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(list(mlb.classes_), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "meta = {\n",
        "    \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"model_type\": \"TFIDF(char+word) + OvR LogisticRegression\",\n",
        "    \"top_k\": 3,\n",
        "    \"input_columns\": [\"text_norm\", \"summary_fallback\"],\n",
        "    \"notes\": \"Config B/D; trained on ERA magic tales; Parent-Hit@3 target metric.\"\n",
        "}\n",
        "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved:\", MODEL_PATH, LABELS_PATH, META_PATH)\n"
      ],
      "metadata": {
        "id": "PbUqg3JMmFs8"
      },
      "id": "PbUqg3JMmFs8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}